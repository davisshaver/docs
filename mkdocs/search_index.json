{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to the Coral Project documentation!\n\n\nThis site aims to familiarize you with the Coral Project, how it works, and how you can help.\n\n\n \n\n\nWhat is the Coral Project?\n\n\nThe Coral Project is an open source project to help publishers of all sizes build better communities around their journalism. We\nre creating tools that allow everyone feel safe, respected, and heard. It consists of three products: \nAsk\n, \nTrust\n and \nTalk\n. \n\n\nSign up for the \nCoral Project newsletter\n to stay tuned for announcements, software updates and the on community engagement \nGuides\n for newsrooms. Our \nproduct roadmap\n.\n\n\nIf you\nd like to learn more about the Coral Project from a high-level perspective, please visit our \n Coral Project website\n. You can find information there about the project, our goals, and the individual products. \n\n\nWho Can Benefit?\n\n\nWe\u2019ve designed our products to meet essential needs of journalism through effective online communities.\n\n\nPublishers\n\n\n\n\nIncrease engagement, loyalty and user satisfaction\n\n\n\n\nEditors\n\n\n\n\nCustom comment moderation dashboards, find great contributors and reduce spam submissions\n\n\n\n\nJournalists\n\n\n\n\nFind potential story sources, high quality interactions and curate audience engagement\n\n\n\n\nCommunity Members\n\n\n\n\nControl your commenting experience, interact with journalists and avoid harassment\n\n\n\n\nHow the docs are organized\n\n\nThe documentation is organized into sections based on what you want to do with Coral.\n\n\n\n\nThe \nDeveloper Guide\n section contains information geared towards a technical audience: those who want to install Coral, those who want to learn about how the various components of Coral fit together,\n\n\nThe \nUser Guide\n section contains information geared towards a less-technical audience. It has overviews and tutorials for those who want to use the Coral products like Trust, Ask, and Talk. If you\nre a publisher, moderator, journalist, or reader who wants to learn how to use Coral, this section is for you.\n\n\nThe \nContribute\n section contains information for those who want to contribute to the Coral Project. You don\nt have to be a developer to contribute! There are a number of ways you can help out, which are outlined on the \nIntroduction\n page.\n\n\n\n\nGuides\n\n\nStrong community is about more than software. Our guides will help everyone in the newsroom be intentional about their community choices, whatever technology you use. We are currently covering these issues on our \nblog\n; the complete guides will be released in Q1 2017.\n\n\nHow can I contribute?\n\n\nWe want your ideas, your requests, your experiences, your bug reports, your skills, your code. \nJoin our community of contributors\n.\n\n\nLearn more\n\n\nFor more information about us and to see our blog, please visit \nour website\n and \nsign up to our newsletter\n. We are also on \nTwitter\n.\n\n\nThe Coral Project is a collaboration between \nThe Mozilla Foundation\n, \nThe New York Times\n, and \nThe Washington Post\n, and is funded by a grant from \nThe John S. and James L. Knight Foundation\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-the-coral-project-documentation", 
            "text": "This site aims to familiarize you with the Coral Project, how it works, and how you can help.", 
            "title": "Welcome to the Coral Project documentation!"
        }, 
        {
            "location": "/#what-is-the-coral-project", 
            "text": "The Coral Project is an open source project to help publishers of all sizes build better communities around their journalism. We re creating tools that allow everyone feel safe, respected, and heard. It consists of three products:  Ask ,  Trust  and  Talk .   Sign up for the  Coral Project newsletter  to stay tuned for announcements, software updates and the on community engagement  Guides  for newsrooms. Our  product roadmap .  If you d like to learn more about the Coral Project from a high-level perspective, please visit our   Coral Project website . You can find information there about the project, our goals, and the individual products.", 
            "title": "What is the Coral Project?"
        }, 
        {
            "location": "/#who-can-benefit", 
            "text": "We\u2019ve designed our products to meet essential needs of journalism through effective online communities.  Publishers   Increase engagement, loyalty and user satisfaction   Editors   Custom comment moderation dashboards, find great contributors and reduce spam submissions   Journalists   Find potential story sources, high quality interactions and curate audience engagement   Community Members   Control your commenting experience, interact with journalists and avoid harassment", 
            "title": "Who Can Benefit?"
        }, 
        {
            "location": "/#how-the-docs-are-organized", 
            "text": "The documentation is organized into sections based on what you want to do with Coral.   The  Developer Guide  section contains information geared towards a technical audience: those who want to install Coral, those who want to learn about how the various components of Coral fit together,  The  User Guide  section contains information geared towards a less-technical audience. It has overviews and tutorials for those who want to use the Coral products like Trust, Ask, and Talk. If you re a publisher, moderator, journalist, or reader who wants to learn how to use Coral, this section is for you.  The  Contribute  section contains information for those who want to contribute to the Coral Project. You don t have to be a developer to contribute! There are a number of ways you can help out, which are outlined on the  Introduction  page.", 
            "title": "How the docs are organized"
        }, 
        {
            "location": "/#guides", 
            "text": "Strong community is about more than software. Our guides will help everyone in the newsroom be intentional about their community choices, whatever technology you use. We are currently covering these issues on our  blog ; the complete guides will be released in Q1 2017.", 
            "title": "Guides"
        }, 
        {
            "location": "/#how-can-i-contribute", 
            "text": "We want your ideas, your requests, your experiences, your bug reports, your skills, your code.  Join our community of contributors .", 
            "title": "How can I contribute?"
        }, 
        {
            "location": "/#learn-more", 
            "text": "For more information about us and to see our blog, please visit  our website  and  sign up to our newsletter . We are also on  Twitter .  The Coral Project is a collaboration between  The Mozilla Foundation ,  The New York Times , and  The Washington Post , and is funded by a grant from  The John S. and James L. Knight Foundation .", 
            "title": "Learn more"
        }, 
        {
            "location": "/products/", 
            "text": "Introduction\n\n\nWelcome! This is the place to be if you want to learn more about Coral as a user. We\nll guide you through the different products and show you tutorials on how to make the best use of the tools.\n\n\nCan you think of a tutorial or how-to guide that we\nre missing? We\nd love for you to create and share it! You can read more about contributing to our documentation in our \nContribute\n section.\n\n\nIf you are looking for information on how to install Coral, check out the \nDeveloper Guide\n section.\n\n\nHow the User Guide section is organized\n\n\nWe have a User Guide for each Coral product (Trust, Ask, and Talk).\n\n\n\n\nEach product has an \noverview section\n to tell you a little about the product, the goals for that product, and a high level explanation of its functionality.\n\n\nEach product has an \ninstallation section\n that shows you how to install the product on your system.\n\n\nEach product also has a set of \ntutorials\n that show you how you can accomplish certain goals using that product.\n\n\n\n\nTrust\n\n\n\n\nTrust overview\n\n\n\n\nAsk\n\n\n\n\nAsk overview\n\n\nAsk installation\n\n\n\n\nTalk\n\n\nTalk is still in development. Find out more about our \nproduct timelines\n on the documentation homepage under the \nproduct roadmap\n section.", 
            "title": "User Guide"
        }, 
        {
            "location": "/products/#introduction", 
            "text": "Welcome! This is the place to be if you want to learn more about Coral as a user. We ll guide you through the different products and show you tutorials on how to make the best use of the tools.  Can you think of a tutorial or how-to guide that we re missing? We d love for you to create and share it! You can read more about contributing to our documentation in our  Contribute  section.  If you are looking for information on how to install Coral, check out the  Developer Guide  section.", 
            "title": "Introduction"
        }, 
        {
            "location": "/products/#how-the-user-guide-section-is-organized", 
            "text": "We have a User Guide for each Coral product (Trust, Ask, and Talk).   Each product has an  overview section  to tell you a little about the product, the goals for that product, and a high level explanation of its functionality.  Each product has an  installation section  that shows you how to install the product on your system.  Each product also has a set of  tutorials  that show you how you can accomplish certain goals using that product.", 
            "title": "How the User Guide section is organized"
        }, 
        {
            "location": "/products/#trust", 
            "text": "Trust overview", 
            "title": "Trust"
        }, 
        {
            "location": "/products/#ask", 
            "text": "Ask overview  Ask installation", 
            "title": "Ask"
        }, 
        {
            "location": "/products/#talk", 
            "text": "Talk is still in development. Find out more about our  product timelines  on the documentation homepage under the  product roadmap  section.", 
            "title": "Talk"
        }, 
        {
            "location": "/products/ask/", 
            "text": "Ask\n\n\nUpdated: 10/20/2016\n\n\nGreetings! We\nre revising our documents and the install package for Ask which is on-prem (Ask runs on your own cloud servers). If you have questions in the meantime, please email \njeff@mozillafoundation.org\n\n\nWhat is Ask?\n\n\nAsk is a tool that enables editors to create embeddable calls for contributions, including text, photo, video, and audio. The contributions can be connected to existing user profiles. Editors can manage high volumes of contributions, and display the best ones alongside the call. \nRead more about Ask here.\n\n\nWho is Ask for?\n\n\n\n\nEngagement editors and journalists\n: People who invite, manage, and publish user-generated content in order to improve the quality of the journalism.\n\n\nEnd users\n: People who consume content and contribute their own knowledge and experiences, in order to improve the quality of the coverage so that it is closer to their own needs and experiences.\n\n\nPublishers\n: People who want to understand the value of engaging more deeply with segments of the users, in order to better assess how and why to invest smartly in community.\n\n\n\n\nWe\nve created a guide on how to write a well-considered form. \nYou can read it here.\n\n\nArchitecture\n\n\n\n\nLatest Install\n\n\nPublic beta of Ask, 0.40, was released on 9/14/16. \n\n\nAsk components\n\n\nCreate form\n\n\nThe form builder is located under \nCreate Form.\n\n\nQuestion fields\n\n\nAsk allows for multiple input field types to be added to a form. All fields are validated, except for phone number. Each input field also has the option to add a description.\n\n\n\n\nShort Answer\n: Provides a single line text input area. You can set the character limits.\n\n\nLong Answer\n: Provides a paragraph text input area. You can set the character limits.\n\n\nNumbers\n: Only number characters can be entered in this field.\n\n\nMultiple Choice\n: Provides multiple choice answer options.\n\n\nEmail\n\n\nDate\n\n\nPhone number\n\n\n\n\nAdditional fields\n\n\nThe form also has options for:\n\n\n\n\nA customizable \nthank you\n message after submitting.\n\n\nAdding text without an entry field to the top of the form (a \nheadline\n and instructions or description).\n\n\nTerms and conditions that will appear as text at the bottom of the form.\n\n\n\n\nEmbedding the generated form\n\n\nOnce a form has been saved, an embed code is generated. You can then use this code to embed the form into your own page. Three options are presented for using the forms:\n\n\nEmbed code\n\n\nYou can render a form directly into a page, using a \nscript src\n tag. This offers the advantages of native CSS inheritance (as iframes won\nt inherit any CSS from the parent page). Note that the div-id does need to be \nask-form\n: the name is hardcoded.\n\n\ndiv id=\nask-form\n/div\nscript src=\n[filewritelocation]/[formid].js\n/script\n\n\n\n\n\nEmbed code (iframe)\n\n\nYou can take the standalone page link and use it in an iframe, which you can then embed directly into your page. You may have to tweak the width and height parameters.\n\n\niframe src=\nhttps://[elkhornserver]/iframe/[form_id]\n width=\n100%\n height=\n600px\n/iframe\n\n\n\n\n\nStandalone form\n\n\nThe \nStandalone Form\n button takes you to the form as a standalone page that you can link to.\n\n\nView forms\n\n\nThe \nView forms\n area allows you the create, edit, and view forms, as well as view the submissions made to your forms.\n\n\nYou can:\n\n\n\n\nsee which forms are currently active.\n\n\nsee the number of submissions.\n\n\nsort and search forms by creator/status/date created/words used in the questions.\n\n\n\n\nAsk installation\n\n\nYou can install the Ask product through a straightforward Docker Compose installation. This installs only the parts of Coral that are required for Ask.\n\n\nThere are two options currently available for installing Ask:\n\n\n\n\nBasic demo setup\n: The first option is an extremely simple demo setup: all variables are hardcoded, so all you have to do is run a few simple commands to get up and running on your laptop.\n\n\nProbably best for you if:\n you just want to install and demo Ask.\n\n\n\n\n\n\nAdvanced setup\n: The second option is still simple, but has a few more steps where you can set some variables and customize your setup (for instance, set up your own S3 bucket instead of using our hardcoded demo S3 bucket).\n\n\nProbably best for you if:\n you want to do more with Ask than just a basic demo.\n\n\n\n\n\n\n\n\nAsk installation: basic demo setup\n\n\nWe currently support Mac, Linux, and Windows. Choose your operating system to view installation instructions.\n\n\n\n\nMac OS X\n: We support OS X El Capitan (10.11) or newer.\n\n\nLinux\n: We support Ubuntu 15.10 or newer.\n\n\nWindows\n: We support Windows 7 or newer.\n\n\n\n\nBasic demo setup: Mac OS X\n\n\nBefore you begin\n\n\nYou must have the following items installed:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nDocker Toolbox\n: You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you already have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose --version\n.\n\n\n\n\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space: 4GB\n\n\n\n\nBrowser requirements\n\n\nWe currently support Chrome.\n\n\nGet the source code\n\n\nClone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/ask.git\n\n\n\n\nThen cd into the \nask/docker\n directory.\n\n\ncd ask/docker\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type \ndocker quickstart\n into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\n\n\nTroubleshooting\n\n\n\n\nYou may have to use the command \neval $(docker-machine env)\n before proceeding to get Docker to work.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\nIf you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).\n\n\n\n\n(default) Check network to re-create if needed...\n(default) Waiting for an IP...\n\n\n\n\nSpin up the Docker container\n\n\nEnsure you are in the \nask/docker\n directory.\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f ask-basic-local.yaml up -d\n\n\n\n\nThe \nask-basic-local.yaml\n file contained in the \nask/docker\n directory contains all the instructions that Docker Compose needs to set up the Ask product.\n\n\nTroubleshooting note\n: If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command \ndocker-compose --version\n.\n\n\nUnsupported config option for services service: 'mongodata'\n\n\n\n\n2. Docker will now download and install a number of Docker images. This may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating network \ndocker_default\n with the default driver\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1\n\n\n\n\n4. If this is your first time installing Ask, you\nll now have to shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f ask-basic-local.yaml down\n\n\n\n\n5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).\n\n\ndocker-compose -f ask-basic-local.yaml up -d\n\n\n\n\nAccess Ask\n\n\nYou can now use Ask by accessing the front end URL in your browser.\n\n\n\n\nOn Mac, the default Docker Machine IP for local machines is \n192.168.99.100\n: \nhttp://192.168.99.100\n\n\n\n\nBasic demo setup: Linux\n\n\nBefore you begin\n\n\nYou must have the following items installed:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nDocker Toolbox\n: You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you already have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose --version\n.\n\n\n\n\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space: 4GB\n\n\n\n\nBrowser requirements\n\n\nWe currently support Chrome.\n\n\nGet the source code\n\n\nClone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/ask.git\n\n\n\n\nThen cd into the \nask/docker\n directory.\n\n\ncd ask/docker\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\n\n\nTroubleshooting\n\n\n\n\nYou may have to use the command \neval $(docker-machine env)\n before proceeding to get Docker to work.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\nIf you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).\n\n\n\n\n(default) Check network to re-create if needed...\n(default) Waiting for an IP...\n\n\n\n\nSet frontend URL variables\n\n\nOn Linux, you will have to manually edit a few variables in the \nask-basic-local.yaml\n file. This is because the current basic demo setup is geared toward Macs, and the Docker Machine IP for local installations on Mac is different from the IP for Linux machines.\n\n\nBasically, anywhere that you see \n192.168.99.100\n in the \nask-basic-local.yaml\n file, you want to change it to \n127.0.0.1\n.\n\n\nOpen up your \nask-basic-local.yaml\n file and set these variables:\n\n\n\n\nPILLAR_URL\n (under \ncayapp\n): Set to \nhttp://127.0.0.1:8080\n.\n\n\nELKHORN_URL\n (under \ncayapp\n): Set to \nhttp://127.0.0.1:4444\n.\n\n\nPILLAR_URL\n (under \nelkhorn\n): Set to \nhttp://127.0.0.1:8080\n.\n\n\n\n\nSpin up the Docker container\n\n\nEnsure you are in the \nask/docker\n directory.\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f ask-basic-local.yaml up -d\n\n\n\n\nThe \nask-basic-local.yaml\n file contained in the \nask/docker\n directory contains all the instructions that Docker Compose needs to set up the Ask product.\n\n\nTroubleshooting note\n: If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command \ndocker-compose --version\n.\n\n\nUnsupported config option for services service: 'mongodata'\n\n\n\n\n2. Docker will now download and install a number of Docker images. This may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating network \ndocker_default\n with the default driver\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1\n\n\n\n\n4. If this is your first time installing Ask, you\nll now have to shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f ask-basic-local.yaml down\n\n\n\n\n5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).\n\n\ndocker-compose -f ask-basic-local.yaml up -d\n\n\n\n\nAccess Ask\n\n\nYou can now use Ask by accessing the front end URL in your browser.\n\n\n\n\nOn Linux, this should be set to \n127.0.0.1\n (the URL we set back in the \nsetting frontend URL variables\n step): \nhttp://127.0.0.1\n\n\n\n\nBasic demo setup: Windows\n\n\nBefore you begin\n\n\nYou must have the following items installed:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nDocker Toolbox\n: You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you already have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose --version\n.\n\n\n\n\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space: 4GB\n\n\n\n\nBrowser requirements\n\n\nWe currently support Chrome.\n\n\nGet the source code\n\n\nClone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/ask.git\n\n\n\n\nThen cd into the \nask/docker\n directory.\n\n\ncd ask/docker\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\n\n\nTroubleshooting\n\n\n\n\nYou may have to use the command \neval $(docker-machine env)\n before proceeding to get Docker to work.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\nIf you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).\n\n\n\n\n(default) Check network to re-create if needed...\n(default) Waiting for an IP...\n\n\n\n\nSpin up the Docker container\n\n\nEnsure you are in the \nask/docker\n directory.\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f ask-basic-local.yaml up -d\n\n\n\n\nThe \nask-basic-local.yaml\n file contained in the \nask/docker\n directory contains all the instructions that Docker Compose needs to set up the Ask product.\n\n\nTroubleshooting note\n: If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command \ndocker-compose --version\n.\n\n\nUnsupported config option for services service: 'mongodata'\n\n\n\n\n2. Docker will now download and install a number of Docker images. This may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating network \ndocker_default\n with the default driver\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1\n\n\n\n\n4. If this is your first time installing Ask, you\nll now have to shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f ask-basic-local.yaml down\n\n\n\n\n5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).\n\n\ndocker-compose -f ask-basic-local.yaml up -d\n\n\n\n\nAccess Ask\n\n\nYou can now use Ask by accessing the front end URL in your browser.\n\n\n\n\nOn Windows, this should be set to \n127.0.0.1\n by default: \nhttp://127.0.0.1\n\n\n\n\nAsk installation: advanced setup\n\n\nWe currently support Mac, Linux, and Windows. Choose your operating system to view installation instructions.\n\n\n\n\nMac OS X\n: We support OS X El Capitan (10.11) or newer.\n\n\nLinux\n: We support Ubuntu 15.10 or newer.\n\n\nWindows\n: We support Windows 7 or newer.\n\n\n\n\nAdvanced setup: Mac OS X\n\n\nBefore you begin\n\n\nYou must have the following items installed and running:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nDocker Toolbox\n: You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you already have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose --version\n.\n\n\n\n\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space: 4GB\n\n\n\n\nBrowser requirements\n\n\nWe currently support Chrome.\n\n\nSet up your external storage system (optional)\n\n\nAsk uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.\n\n\nThere are currently a couple of different options available for the external storage system you can use.\n\n\n\n\nAmazon S3\n: Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.\n\n\nLocal file system\n: If you don\nt set up an external storage system in the \nset environment variables\n step, Ask will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Ask for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.\n\n\n\n\nAmazon S3\n\n\nAmazon S3\n is a good option for your external storage system because it is fast, handles concurrency, and will scale well.\n\n\nThe setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon\ns instructions \nhere\n.\n\n\n\n\nFollow the directions for \nSign Up for Amazon S3\n and \nCreate a Bucket\n. There is no need to continue further to the demos for \nAdd an Object to a Bucket\n and beyond: those are simply examples showing you how to use S3.\n\n\n\n\n\n\nFor my example, I named my bucket \nask-bucket-test\n and chose region \nNorthern California\n (which corresponds to us-west-2).\n\n\nDuring the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).\n\n\n\n\n\n\n\n\nOnce you have signed up and set up a bucket, go to your \nS3 console\n to set up your permissions under \nSecurity Credentials.\n\n\n\n\n\n\nEnsure that under \nPermissions,\n the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).\n\n\n\n\n\n\nYou\nre all set! You can now use your AWS Access Key to connect Ask to your S3 bucket (you\nll set this up in the \nSet environment variables\n section below). If you didn\nt save your AWS Access Key during the set up process, you can go to the \nSecurity Credentials\n section and create a new one.\n\n\nGet the source code\n\n\nClone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/ask.git\n\n\n\n\nThen cd into the \nask/docker\n directory.\n\n\ncd ask/docker\n\n\n\n\nSet environment variables\n\n\nThe \nenv.conf\n file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral front end will have, as well as other information such as your MongoDB username and password.\n\n\nexport FRONTEND_HOST=192.168.99.100\n\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral\n\n\n\n\n\n\nFRONTEND_HOST\n: set to your desired IP address for the front end.\n\n\nOn Mac, the default Docker Machine IP for laptops is \n192.168.99.100\n.\n\n\n\n\n\n\n\n\nMongoDB:\n\n\n\n\nMONGO_USER\n: set to the username for your MongoDB\n\n\nMONGO_PASS\n: set to the password for your MongoDB\n\n\nMONGO_DB\n: set to the name of your MongoDB (in this instance, \ncoral\n)\n\n\nMONGO_AUTHDB\n: set to the admin user of your database\n\n\n\n\nAmazon S3 (optional):\n\n\n\n\nS3_BUCKET\n: set to the name of your S3 bucket (in this example, \nask-bucket-test\n)\n\n\nAWS_REGION\n: set to the AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In this example, it is \nus-west-2\n.\n\n\nAWS_ACCESS_KEY\n: set to your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\nAWS_ACCESS_KEY\n: set to your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type \ndocker quickstart\n into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\n\n\nTroubleshooting\n\n\n\n\nYou may have to use the command \neval $(docker-machine env)\n before proceeding to get Docker to work.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\nIf you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).\n\n\n\n\n(default) Check network to re-create if needed...\n(default) Waiting for an IP...\n\n\n\n\nSpin up the Docker container\n\n\nEnsure you are in the \nask/docker\n directory.\n\n\nFirst, run the following command to export your edited variables and set the environment variables.\n\n\nsource env.conf\n\n\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nThe \ndocker-compose.yml\n file contained in the \nask/docker\n directory contains all the instructions that Docker Compose needs to set up the Ask product.\n\n\nTroubleshooting note\n: If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command \ndocker-compose --version\n.\n\n\nUnsupported config option for services service: 'mongodata'\n\n\n\n\n2. Docker will now download and install a number of Docker images. This may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1\n\n\n\n\n4. If this is your first time installing Ask, you\nll now have to shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f docker-compose.yml down\n\n\n\n\n5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nAccess Ask\n\n\nYou can now use Ask by accessing the front end URL in your browser. This is the URL you specified as \nFRONTEND_HOST\n in the \nenv.conf\n setup above.\n\n\n\n\nOn Mac, the default Docker Machine IP for laptops is \n192.168.99.100\n: \nhttp://192.168.99.100\n\n\n\n\nAdvanced setup: Linux\n\n\nBefore you begin\n\n\nYou must have the following items installed and running:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nDocker Toolbox\n: You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you already have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose --version\n.\n\n\n\n\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space: 4GB\n\n\n\n\nBrowser requirements\n\n\nWe currently support Chrome.\n\n\nSet up your external storage system (optional)\n\n\nAsk uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.\n\n\nThere are currently a couple of different options available for the external storage system you can use.\n\n\n\n\nAmazon S3\n: Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.\n\n\nLocal file system\n: If you don\nt set up an external storage system in the \nset environment variables\n step, Ask will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Ask for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.\n\n\n\n\nAmazon S3\n\n\nAmazon S3\n is a good option for your external storage system because it is fast, handles concurrency, and will scale well.\n\n\nThe setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon\ns instructions \nhere\n.\n\n\n\n\nFollow the directions for \nSign Up for Amazon S3\n and \nCreate a Bucket\n. There is no need to continue further to the demos for \nAdd an Object to a Bucket\n and beyond: those are simply examples showing you how to use S3.\n\n\n\n\n\n\nFor my example, I named my bucket \nask-bucket-test\n and chose region \nNorthern California\n (which corresponds to us-west-2).\n\n\nDuring the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).\n\n\n\n\n\n\n\n\nOnce you have signed up and set up a bucket, go to your \nS3 console\n to set up your permissions under \nSecurity Credentials.\n\n\n\n\n\n\nEnsure that under \nPermissions,\n the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).\n\n\n\n\n\n\nYou\nre all set! You can now use your AWS Access Key to connect Ask to your S3 bucket (you\nll set this up in the \nSet environment variables\n section below). If you didn\nt save your AWS Access Key during the set up process, you can go to the \nSecurity Credentials\n section and create a new one.\n\n\nGet the source code\n\n\nClone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/ask.git\n\n\n\n\nThen cd into the \nask/docker\n directory.\n\n\ncd ask/docker\n\n\n\n\nSet environment variables\n\n\nThe \nenv.conf\n file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral front end will have, as well as other information such as your MongoDB username and password.\n\n\nexport FRONTEND_HOST=192.168.99.100\n\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral\n\n\n\n\n\n\nFRONTEND_HOST\n: set to your desired IP address for the front end.\n\n\nOn Linux, this should be set to \n127.0.0.1\n or a private IP address.\n\n\n\n\n\n\n\n\nMongoDB:\n\n\n\n\nMONGO_USER\n: set to the username for your MongoDB\n\n\nMONGO_PASS\n: set to the password for your MongoDB\n\n\nMONGO_DB\n: set to the name of your MongoDB (in this instance, \ncoral\n)\n\n\nMONGO_AUTHDB\n: set to the admin user of your database\n\n\n\n\nAmazon S3 (optional):\n\n\n\n\nS3_BUCKET\n: set to the name of your S3 bucket (in this example, \nask-bucket-test\n)\n\n\nAWS_REGION\n: set to the AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In this example, it is \nus-west-2\n.\n\n\nAWS_ACCESS_KEY\n: set to your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\nAWS_ACCESS_KEY\n: set to your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\n\n\nTroubleshooting\n\n\n\n\nYou may have to use the command \neval $(docker-machine env)\n before proceeding to get Docker to work.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\nIf you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).\n\n\n\n\n(default) Check network to re-create if needed...\n(default) Waiting for an IP...\n\n\n\n\nSpin up the Docker container\n\n\nEnsure you are in the \nask/docker\n directory.\n\n\nFirst, run the following command to export your edited variables and set the environment variables.\n\n\nsource env.conf\n\n\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nThe \ndocker-compose.yml\n file contained in the \nask/docker\n directory contains all the instructions that Docker Compose needs to set up the Ask product.\n\n\nTroubleshooting note\n: If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command \ndocker-compose --version\n.\n\n\nUnsupported config option for services service: 'mongodata'\n\n\n\n\n2. Docker will now download and install a number of Docker images. This may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1\n\n\n\n\n4. If this is your first time installing Ask, you\nll now have to shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f docker-compose.yml down\n\n\n\n\n5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nAccess Ask\n\n\nYou can now use Ask by accessing the front end URL in your browser. This is the URL you specified as \nFRONTEND_HOST\n in the \nenv.conf\n setup above.\n\n\n\n\nOn Linux, this should be set to \n127.0.0.1\n or a private IP address (the IP you set when \nsetting your environment variables\n): \nhttp://127.0.0.1\n\n\n\n\nAdvanced setup: Windows\n\n\nBefore you begin\n\n\nYou must have the following items installed and running:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nDocker Toolbox\n: You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you already have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose --version\n.\n\n\n\n\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space: 4GB\n\n\n\n\nBrowser requirements\n\n\nWe currently support Chrome.\n\n\nSet up your external storage system (optional)\n\n\nAsk uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.\n\n\nThere are currently a couple of different options available for the external storage system you can use.\n\n\n\n\nAmazon S3\n: Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.\n\n\nLocal file system\n: If you don\nt set up an external storage system in the \nset environment variables\n step, Ask will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Ask for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.\n\n\n\n\nAmazon S3\n\n\nAmazon S3\n is a good option for your external storage system because it is fast, handles concurrency, and will scale well.\n\n\nThe setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon\ns instructions \nhere\n.\n\n\n\n\nFollow the directions for \nSign Up for Amazon S3\n and \nCreate a Bucket\n. There is no need to continue further to the demos for \nAdd an Object to a Bucket\n and beyond: those are simply examples showing you how to use S3.\n\n\n\n\n\n\nFor my example, I named my bucket \nask-bucket-test\n and chose region \nNorthern California\n (which corresponds to us-west-2).\n\n\nDuring the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).\n\n\n\n\n\n\n\n\nOnce you have signed up and set up a bucket, go to your \nS3 console\n to set up your permissions under \nSecurity Credentials.\n\n\n\n\n\n\nEnsure that under \nPermissions,\n the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).\n\n\n\n\n\n\nYou\nre all set! You can now use your AWS Access Key to connect Ask to your S3 bucket (you\nll set this up in the \nSet environment variables\n section below). If you didn\nt save your AWS Access Key during the set up process, you can go to the \nSecurity Credentials\n section and create a new one.\n\n\nGet the source code\n\n\nClone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/ask.git\n\n\n\n\nThen cd into the \nask/docker\n directory.\n\n\ncd ask/docker\n\n\n\n\nSet environment variables\n\n\nThe \nenv.conf\n file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral front end will have, as well as other information such as your MongoDB username and password.\n\n\nexport FRONTEND_HOST=192.168.99.100\n\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral\n\n\n\n\n\n\nFRONTEND_HOST\n: set to your desired IP address for the front end.\n\n\nOn Windows, this should be set to \n127.0.0.1\n or a private IP address.\n\n\n\n\n\n\n\n\nMongoDB:\n\n\n\n\nMONGO_USER\n: set to the username for your MongoDB\n\n\nMONGO_PASS\n: set to the password for your MongoDB\n\n\nMONGO_DB\n: set to the name of your MongoDB (in this instance, \ncoral\n)\n\n\nMONGO_AUTHDB\n: set to the admin user of your database\n\n\n\n\nAmazon S3 (optional):\n\n\n\n\nS3_BUCKET\n: set to the name of your S3 bucket (in this example, \nask-bucket-test\n)\n\n\nAWS_REGION\n: set to the AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In this example, it is \nus-west-2\n.\n\n\nAWS_ACCESS_KEY\n: set to your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\nAWS_ACCESS_KEY\n: set to your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type \ndocker quickstart\n into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\n\n\nTroubleshooting\n\n\n\n\nYou may have to use the command \neval $(docker-machine env)\n before proceeding to get Docker to work.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\nIf you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).\n\n\n\n\n(default) Check network to re-create if needed...\n(default) Waiting for an IP...\n\n\n\n\nSpin up the Docker container\n\n\nEnsure you are in the \nask/docker\n directory.\n\n\nFirst, run the following command to export your edited variables and set the environment variables.\n\n\nsource env.conf\n\n\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nThe \ndocker-compose.yml\n file contained in the \nask/docker\n directory contains all the instructions that Docker Compose needs to set up the Ask product.\n\n\nTroubleshooting note\n: If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command \ndocker-compose --version\n.\n\n\nUnsupported config option for services service: 'mongodata'\n\n\n\n\n2. Docker will now download and install a number of Docker images. This may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1\n\n\n\n\n4. If this is your first time installing Ask, you\nll now have to shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f docker-compose.yml down\n\n\n\n\n5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nAccess Ask\n\n\nYou can now use Ask by accessing the front end URL in your browser. This is the URL you specified as \nFRONTEND_HOST\n in the \nenv.conf\n setup above.\n\n\n\n\nOn Windows, this should be set to \n127.0.0.1\n or a private IP address (the IP you set when \nsetting your environment variables\n): \nhttp://127.0.0.1\n\n\n\n\nTroubleshooting\n\n\nOld version of Docker\n\n\nIf you see an error while running the Docker Compose commands, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command \ndocker-compose --version\n.\nExample error:\n\n\nUnsupported config option for services service: 'mongodata'\n\n\n\n\nViewing running Docker containers\n\n\nTo see all of the Docker containers currently running, use the command \ndocker ps\n (you can read more about this command and its options at the \nDocker website\n).\n\n\ndocker ps\n\n\n\n\nYou should have all of the following containers running:\n\n\n\n\nnginx:stable-alpine\n\n\ncoralproject/cay:release\n\n\ncoralproject/elkhorn\n\n\ncoralproject/pillar:release\n\n\ncoralproject/mongodata\n\n\n\n\nViewing installed Docker images\n\n\nTo see all of the Docker images you have installed, use the command \ndocker images\n (you can read more about this command and its options at the \nDocker website\n).\n\n\ndocker images\n\n\n\n\nViewing Docker logs\n\n\nTo view Docker logs for a container, use the command \ndocker logs \ncontainer id\n (you can read more about this command and its options at the \nDocker website\n).\n\n\nFirst you have to find the container id:\n\n\ndocker ps\n\n\n\n\nThen use the container id to view the logs:\n\n\ndocker logs e0bbd7be19c7\n\n\n\n\nRemoving Docker images\n\n\nThere are a few reasons you might want to remove Docker images. You may wish to ensure that you are getting the latest build of the image. Or maybe something has gone awry with one or more of the images, and you just want to perform a fresh install of all images.\n\n\nTo remove all Docker images, use this command:\n\n\ndocker rmi $(docker images -q)\n\n\n\n\nRemoving old Docker machines\n\n\nAnother option for a \nfresh install\n is to remove old Docker machines. You could try this in combination with \nremoving Docker images\n and then reinstalling Ask to see if that fixes your issue.\n\n\ndocker rm -f $(docker ps -a -q)\n\n\n\n\nOther issues while installing\n\n\n\n\nYou may have to use the command \neval $(docker-machine env)\n after you\nve started Docker in order to get Docker to work.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\nIf you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).\n\n\n\n\n(default) Check network to re-create if needed...\n(default) Waiting for an IP...\n\n\n\n\nAsk tutorials\n\n\nWe are still developing our Ask tutorials. In the meantime, you can read our guide on \nhow to approach asking your readers for information.\n\n\nAsk Docker Compose Installation\n\n\nYou can install the Ask product through a straightforward Docker Compose installation. This installs only the parts of Coral that are required for Ask.\n\n\nBefore you begin\n\n\nYou must have the following items installed and running:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space: 4GB\n\n\n\n\nInstall Docker Toolbox\n\n\nIf you do not already have Docker installed, do that first. You can install Docker Toolbox using the Docker instructions \nlocated here\n.\n\n\nIf you do have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker version\n.\n\n\nSet up your external storage system (optional)\n\n\nAsk uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.\n\n\nThere are currently a couple of different options available for the external storage system you can use.\n\n\n\n\nAmazon S3\n: Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.\n\n\nLocal file system\n: If you don\nt set up an external storage system in the \nset environment variables\n step, Ask will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Ask for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.\n\n\n\n\nAmazon S3\n\n\nAmazon S3\n is a good option for your external storage system because it is fast, handles concurrency, and will scale well.\n\n\nThe setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon\ns instructions \nhere\n.\n\n\n\n\nFollow the directions for \nSign Up for Amazon S3\n and \nCreate a Bucket\n. There is no need to continue further to the demos for \nAdd an Object to a Bucket\n and beyond: those are simply examples showing you how to use S3.\n\n\n\n\n\n\nFor my example, I named my bucket \nask-bucket-test\n and chose region \nNorthern California\n (which corresponds to us-west-2).\n\n\nDuring the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).\n\n\n\n\n\n\n\n\nOnce you have signed up and set up a bucket, go to your \nS3 console\n to set up your permissions under \nSecurity Credentials.\n\n\n\n\n\n\nEnsure that under \nPermissions,\n the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).\n\n\n\n\n\n\nYou\nre all set! You can now use your AWS Access Key to connect Ask to your S3 bucket (you\nll set this up in the \nSet environment variables\n section below). If you didn\nt save your AWS Access Key during the set up process, you can go to the \nSecurity Credentials\n section and create a new one.\n\n\nGet the source code\n\n\nClone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/ask.git\n\n\n\n\nThen cd into the \nask/docker\n directory.\n\n\ncd ask/docker\n\n\n\n\nSet environment variables\n\n\nThe \nenv.conf\n file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral front end will have, as well as other information such as your MongoDB username and password.\n\n\nexport FRONTEND_HOST=xxx\n\nexport AUTH_TOKEN_VALUE='Basic xxx'\nexport GAID_VALUE=xxx\n\nexport MONGO_USER=xxx\nexport MONGO_PASS=xxx\nexport MONGO_DB=xxx\nexport MONGO_AUTHDB=xxx\n\nexport RABBIT_USER=xxx\nexport RABBIT_PASS=xxx\n\nexport S3_BUCKET=xxx\nexport AWS_REGION=xxx\nexport AWS_ACCESS_KEY_ID=xxx\nexport AWS_ACCESS_KEY=xxx\n\n\n\n\n\n\nFRONTEND_HOST\n: set to your desired IP address for the front end. For this example, we will use \n192.168.99.100\n.\n\n\n\n\nMongoDB:\n\n\n\n\nMONGO_USER\n: set to the username for your MongoDB\n\n\nMONGO_PASS\n: set to the password for your MongoDB\n\n\nMONGO_DB\n: set to the name of your MongoDB (in this instance, \ncoral\n)\n\n\nMONGO_AUTHDB\n: set to the admin user of your database\n\n\n\n\nAmazon S3:\n\n\n\n\nS3_BUCKET\n: set to the name of your S3 bucket (in this example, \nask-bucket-test\n)\n\n\nAWS_REGION\n: set to the AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In this example, it is \nus-west-2\n.\n\n\nAWS_ACCESS_KEY\n: set to your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\nAWS_ACCESS_KEY\n: set to your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\n\n\nOptional edits:\n\n\n\n\nGAID_VALUE=xxxx\n: If you\nre using Google Analytics, set your token at \nexport GAID_VALUE=xxxx\n. Otherwise, delete or comment out this line.\n\n\nexport AUTH_TOKEN_VALUE=xxxx\n: If you\nre using a custom auth token, set that at \nexport AUTH_TOKEN_VALUE=xxxx\n. Otherwise, delete or comment out this line.\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type \ndocker quickstart\n into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\n\n\n\n\n\n\nEnsure you are in the \nask/docker\n directory.\n\n\nSpin up the Docker container\n\n\nFirst, run the following command to export your edited variables and set the environment variables.\n\n\nsource env.conf\n\n\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nThe \ndocker-compose.yml\n file contained in the \nask/docker\n directory contains all the instructions that Docker Compose needs to set up the Ask product.\n\n\n2. Docker will now download and install a number of Docker images. This may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating network \ndocker_default\n with the default driver\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1\nCreating docker_proxy_1\n\n\n\n\n4. If this is your first time installing Ask, you\nll now have to shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f docker-compose.yml down\n\n\n\n\n5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nAccess Ask\n\n\nYou can now use Ask by accessing the front end URL in your browser. This is the URL you specified as \nFRONTEND_HOST\n in the \nenv.conf\n setup above. In this example, we set it to \nhttp://192.168.99.100\n.\n\n\nTroubleshooting\n\n\nViewing running Docker containers\n\n\nTo see all of the Docker containers currently running, use the command \ndocker ps\n (you can read more about this command and its options at the \nDocker website\n).\n\n\ndocker ps\n\n\n\n\nYou should have all of the following containers running:\n\n\n\n\nnginx:stable-alpine\n\n\ncoralproject/cay:release\n\n\ncoralproject/elkhorn\n\n\ncoralproject/pillar:release\n\n\ncoralproject/mongodata\n\n\n\n\nViewing installed Docker images\n\n\nTo see all of the Docker images you have installed, use the command \ndocker images\n (you can read more about this command and its options at the \nDocker website\n).\n\n\ndocker images\n\n\n\n\nViewing Docker logs\n\n\nTo view Docker logs for a container, use the command \ndocker logs \ncontainer id\n (you can read more about this command and its options at the \nDocker website\n).\n\n\nFirst you have to find the container id:\n\n\ndocker ps\n\n\n\n\nThen use the container id to view the logs:\n\n\ndocker logs e0bbd7be19c7\n\n\n\n\nOperating system requirements\n\n\nOn Mac, we support OS X El Capitan (10.11) or newer. If you are on an older OS, you may have to upgrade.\n\n\nUninstalling Docker images\n\n\nAsk tutorials\n\n\nThis page will get filled in as we unroll the Ask product. In the meantime, you can find out more on the Ask product on \nour website\n.", 
            "title": "Ask"
        }, 
        {
            "location": "/products/ask/#ask", 
            "text": "Updated: 10/20/2016  Greetings! We re revising our documents and the install package for Ask which is on-prem (Ask runs on your own cloud servers). If you have questions in the meantime, please email  jeff@mozillafoundation.org", 
            "title": "Ask"
        }, 
        {
            "location": "/products/ask/#what-is-ask", 
            "text": "Ask is a tool that enables editors to create embeddable calls for contributions, including text, photo, video, and audio. The contributions can be connected to existing user profiles. Editors can manage high volumes of contributions, and display the best ones alongside the call.  Read more about Ask here.", 
            "title": "What is Ask?"
        }, 
        {
            "location": "/products/ask/#who-is-ask-for", 
            "text": "Engagement editors and journalists : People who invite, manage, and publish user-generated content in order to improve the quality of the journalism.  End users : People who consume content and contribute their own knowledge and experiences, in order to improve the quality of the coverage so that it is closer to their own needs and experiences.  Publishers : People who want to understand the value of engaging more deeply with segments of the users, in order to better assess how and why to invest smartly in community.   We ve created a guide on how to write a well-considered form.  You can read it here.", 
            "title": "Who is Ask for?"
        }, 
        {
            "location": "/products/ask/#architecture", 
            "text": "", 
            "title": "Architecture"
        }, 
        {
            "location": "/products/ask/#latest-install", 
            "text": "Public beta of Ask, 0.40, was released on 9/14/16.", 
            "title": "Latest Install"
        }, 
        {
            "location": "/products/ask/#ask-components", 
            "text": "", 
            "title": "Ask components"
        }, 
        {
            "location": "/products/ask/#create-form", 
            "text": "The form builder is located under  Create Form.", 
            "title": "Create form"
        }, 
        {
            "location": "/products/ask/#question-fields", 
            "text": "Ask allows for multiple input field types to be added to a form. All fields are validated, except for phone number. Each input field also has the option to add a description.   Short Answer : Provides a single line text input area. You can set the character limits.  Long Answer : Provides a paragraph text input area. You can set the character limits.  Numbers : Only number characters can be entered in this field.  Multiple Choice : Provides multiple choice answer options.  Email  Date  Phone number", 
            "title": "Question fields"
        }, 
        {
            "location": "/products/ask/#additional-fields", 
            "text": "The form also has options for:   A customizable  thank you  message after submitting.  Adding text without an entry field to the top of the form (a  headline  and instructions or description).  Terms and conditions that will appear as text at the bottom of the form.", 
            "title": "Additional fields"
        }, 
        {
            "location": "/products/ask/#embedding-the-generated-form", 
            "text": "Once a form has been saved, an embed code is generated. You can then use this code to embed the form into your own page. Three options are presented for using the forms:", 
            "title": "Embedding the generated form"
        }, 
        {
            "location": "/products/ask/#embed-code", 
            "text": "You can render a form directly into a page, using a  script src  tag. This offers the advantages of native CSS inheritance (as iframes won t inherit any CSS from the parent page). Note that the div-id does need to be  ask-form : the name is hardcoded.  div id= ask-form /div script src= [filewritelocation]/[formid].js /script", 
            "title": "Embed code"
        }, 
        {
            "location": "/products/ask/#embed-code-iframe", 
            "text": "You can take the standalone page link and use it in an iframe, which you can then embed directly into your page. You may have to tweak the width and height parameters.  iframe src= https://[elkhornserver]/iframe/[form_id]  width= 100%  height= 600px /iframe", 
            "title": "Embed code (iframe)"
        }, 
        {
            "location": "/products/ask/#standalone-form", 
            "text": "The  Standalone Form  button takes you to the form as a standalone page that you can link to.", 
            "title": "Standalone form"
        }, 
        {
            "location": "/products/ask/#view-forms", 
            "text": "The  View forms  area allows you the create, edit, and view forms, as well as view the submissions made to your forms.  You can:   see which forms are currently active.  see the number of submissions.  sort and search forms by creator/status/date created/words used in the questions.", 
            "title": "View forms"
        }, 
        {
            "location": "/products/ask/#ask-installation", 
            "text": "You can install the Ask product through a straightforward Docker Compose installation. This installs only the parts of Coral that are required for Ask.  There are two options currently available for installing Ask:   Basic demo setup : The first option is an extremely simple demo setup: all variables are hardcoded, so all you have to do is run a few simple commands to get up and running on your laptop.  Probably best for you if:  you just want to install and demo Ask.    Advanced setup : The second option is still simple, but has a few more steps where you can set some variables and customize your setup (for instance, set up your own S3 bucket instead of using our hardcoded demo S3 bucket).  Probably best for you if:  you want to do more with Ask than just a basic demo.", 
            "title": "Ask installation"
        }, 
        {
            "location": "/products/ask/#ask-installation-basic-demo-setup", 
            "text": "We currently support Mac, Linux, and Windows. Choose your operating system to view installation instructions.   Mac OS X : We support OS X El Capitan (10.11) or newer.  Linux : We support Ubuntu 15.10 or newer.  Windows : We support Windows 7 or newer.", 
            "title": "Ask installation: basic demo setup"
        }, 
        {
            "location": "/products/ask/#basic-demo-setup-mac-os-x", 
            "text": "", 
            "title": "Basic demo setup: Mac OS X"
        }, 
        {
            "location": "/products/ask/#before-you-begin", 
            "text": "You must have the following items installed:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .  Docker Toolbox : You can install Docker Toolbox from the  Docker Toolbox product page .  If you already have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose --version .     You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/products/ask/#browser-requirements", 
            "text": "We currently support Chrome.", 
            "title": "Browser requirements"
        }, 
        {
            "location": "/products/ask/#get-the-source-code", 
            "text": "Clone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/ask.git  Then cd into the  ask/docker  directory.  cd ask/docker", 
            "title": "Get the source code"
        }, 
        {
            "location": "/products/ask/#start-docker", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type  docker quickstart  into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/products/ask/#troubleshooting", 
            "text": "You may have to use the command  eval $(docker-machine env)  before proceeding to get Docker to work.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.  If you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).   (default) Check network to re-create if needed...\n(default) Waiting for an IP...", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/products/ask/#spin-up-the-docker-container", 
            "text": "Ensure you are in the  ask/docker  directory.  The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f ask-basic-local.yaml up -d  The  ask-basic-local.yaml  file contained in the  ask/docker  directory contains all the instructions that Docker Compose needs to set up the Ask product.  Troubleshooting note : If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command  docker-compose --version .  Unsupported config option for services service: 'mongodata'  2. Docker will now download and install a number of Docker images. This may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating network  docker_default  with the default driver\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1  4. If this is your first time installing Ask, you ll now have to shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f ask-basic-local.yaml down  5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).  docker-compose -f ask-basic-local.yaml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/products/ask/#access-ask", 
            "text": "You can now use Ask by accessing the front end URL in your browser.   On Mac, the default Docker Machine IP for local machines is  192.168.99.100 :  http://192.168.99.100", 
            "title": "Access Ask"
        }, 
        {
            "location": "/products/ask/#basic-demo-setup-linux", 
            "text": "", 
            "title": "Basic demo setup: Linux"
        }, 
        {
            "location": "/products/ask/#before-you-begin_1", 
            "text": "You must have the following items installed:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .  Docker Toolbox : You can install Docker Toolbox from the  Docker Toolbox product page .  If you already have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose --version .     You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/products/ask/#browser-requirements_1", 
            "text": "We currently support Chrome.", 
            "title": "Browser requirements"
        }, 
        {
            "location": "/products/ask/#get-the-source-code_1", 
            "text": "Clone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/ask.git  Then cd into the  ask/docker  directory.  cd ask/docker", 
            "title": "Get the source code"
        }, 
        {
            "location": "/products/ask/#start-docker_1", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/products/ask/#troubleshooting_1", 
            "text": "You may have to use the command  eval $(docker-machine env)  before proceeding to get Docker to work.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.  If you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).   (default) Check network to re-create if needed...\n(default) Waiting for an IP...", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/products/ask/#set-frontend-url-variables", 
            "text": "On Linux, you will have to manually edit a few variables in the  ask-basic-local.yaml  file. This is because the current basic demo setup is geared toward Macs, and the Docker Machine IP for local installations on Mac is different from the IP for Linux machines.  Basically, anywhere that you see  192.168.99.100  in the  ask-basic-local.yaml  file, you want to change it to  127.0.0.1 .  Open up your  ask-basic-local.yaml  file and set these variables:   PILLAR_URL  (under  cayapp ): Set to  http://127.0.0.1:8080 .  ELKHORN_URL  (under  cayapp ): Set to  http://127.0.0.1:4444 .  PILLAR_URL  (under  elkhorn ): Set to  http://127.0.0.1:8080 .", 
            "title": "Set frontend URL variables"
        }, 
        {
            "location": "/products/ask/#spin-up-the-docker-container_1", 
            "text": "Ensure you are in the  ask/docker  directory.  The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f ask-basic-local.yaml up -d  The  ask-basic-local.yaml  file contained in the  ask/docker  directory contains all the instructions that Docker Compose needs to set up the Ask product.  Troubleshooting note : If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command  docker-compose --version .  Unsupported config option for services service: 'mongodata'  2. Docker will now download and install a number of Docker images. This may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating network  docker_default  with the default driver\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1  4. If this is your first time installing Ask, you ll now have to shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f ask-basic-local.yaml down  5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).  docker-compose -f ask-basic-local.yaml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/products/ask/#access-ask_1", 
            "text": "You can now use Ask by accessing the front end URL in your browser.   On Linux, this should be set to  127.0.0.1  (the URL we set back in the  setting frontend URL variables  step):  http://127.0.0.1", 
            "title": "Access Ask"
        }, 
        {
            "location": "/products/ask/#basic-demo-setup-windows", 
            "text": "", 
            "title": "Basic demo setup: Windows"
        }, 
        {
            "location": "/products/ask/#before-you-begin_2", 
            "text": "You must have the following items installed:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .  Docker Toolbox : You can install Docker Toolbox from the  Docker Toolbox product page .  If you already have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose --version .     You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/products/ask/#browser-requirements_2", 
            "text": "We currently support Chrome.", 
            "title": "Browser requirements"
        }, 
        {
            "location": "/products/ask/#get-the-source-code_2", 
            "text": "Clone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/ask.git  Then cd into the  ask/docker  directory.  cd ask/docker", 
            "title": "Get the source code"
        }, 
        {
            "location": "/products/ask/#start-docker_2", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/products/ask/#troubleshooting_2", 
            "text": "You may have to use the command  eval $(docker-machine env)  before proceeding to get Docker to work.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.  If you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).   (default) Check network to re-create if needed...\n(default) Waiting for an IP...", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/products/ask/#spin-up-the-docker-container_2", 
            "text": "Ensure you are in the  ask/docker  directory.  The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f ask-basic-local.yaml up -d  The  ask-basic-local.yaml  file contained in the  ask/docker  directory contains all the instructions that Docker Compose needs to set up the Ask product.  Troubleshooting note : If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command  docker-compose --version .  Unsupported config option for services service: 'mongodata'  2. Docker will now download and install a number of Docker images. This may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating network  docker_default  with the default driver\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1  4. If this is your first time installing Ask, you ll now have to shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f ask-basic-local.yaml down  5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).  docker-compose -f ask-basic-local.yaml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/products/ask/#access-ask_2", 
            "text": "You can now use Ask by accessing the front end URL in your browser.   On Windows, this should be set to  127.0.0.1  by default:  http://127.0.0.1", 
            "title": "Access Ask"
        }, 
        {
            "location": "/products/ask/#ask-installation-advanced-setup", 
            "text": "We currently support Mac, Linux, and Windows. Choose your operating system to view installation instructions.   Mac OS X : We support OS X El Capitan (10.11) or newer.  Linux : We support Ubuntu 15.10 or newer.  Windows : We support Windows 7 or newer.", 
            "title": "Ask installation: advanced setup"
        }, 
        {
            "location": "/products/ask/#advanced-setup-mac-os-x", 
            "text": "", 
            "title": "Advanced setup: Mac OS X"
        }, 
        {
            "location": "/products/ask/#before-you-begin_3", 
            "text": "You must have the following items installed and running:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .  Docker Toolbox : You can install Docker Toolbox from the  Docker Toolbox product page .  If you already have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose --version .     You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/products/ask/#browser-requirements_3", 
            "text": "We currently support Chrome.", 
            "title": "Browser requirements"
        }, 
        {
            "location": "/products/ask/#set-up-your-external-storage-system-optional", 
            "text": "Ask uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.  There are currently a couple of different options available for the external storage system you can use.   Amazon S3 : Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.  Local file system : If you don t set up an external storage system in the  set environment variables  step, Ask will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Ask for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.", 
            "title": "Set up your external storage system (optional)"
        }, 
        {
            "location": "/products/ask/#amazon-s3", 
            "text": "Amazon S3  is a good option for your external storage system because it is fast, handles concurrency, and will scale well.  The setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon s instructions  here .   Follow the directions for  Sign Up for Amazon S3  and  Create a Bucket . There is no need to continue further to the demos for  Add an Object to a Bucket  and beyond: those are simply examples showing you how to use S3.    For my example, I named my bucket  ask-bucket-test  and chose region  Northern California  (which corresponds to us-west-2).  During the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).     Once you have signed up and set up a bucket, go to your  S3 console  to set up your permissions under  Security Credentials.    Ensure that under  Permissions,  the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).    You re all set! You can now use your AWS Access Key to connect Ask to your S3 bucket (you ll set this up in the  Set environment variables  section below). If you didn t save your AWS Access Key during the set up process, you can go to the  Security Credentials  section and create a new one.", 
            "title": "Amazon S3"
        }, 
        {
            "location": "/products/ask/#get-the-source-code_3", 
            "text": "Clone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/ask.git  Then cd into the  ask/docker  directory.  cd ask/docker", 
            "title": "Get the source code"
        }, 
        {
            "location": "/products/ask/#set-environment-variables", 
            "text": "The  env.conf  file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral front end will have, as well as other information such as your MongoDB username and password.  export FRONTEND_HOST=192.168.99.100\n\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral   FRONTEND_HOST : set to your desired IP address for the front end.  On Mac, the default Docker Machine IP for laptops is  192.168.99.100 .     MongoDB:   MONGO_USER : set to the username for your MongoDB  MONGO_PASS : set to the password for your MongoDB  MONGO_DB : set to the name of your MongoDB (in this instance,  coral )  MONGO_AUTHDB : set to the admin user of your database   Amazon S3 (optional):   S3_BUCKET : set to the name of your S3 bucket (in this example,  ask-bucket-test )  AWS_REGION : set to the AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In this example, it is  us-west-2 .  AWS_ACCESS_KEY : set to your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.  AWS_ACCESS_KEY : set to your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.", 
            "title": "Set environment variables"
        }, 
        {
            "location": "/products/ask/#start-docker_3", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type  docker quickstart  into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/products/ask/#troubleshooting_3", 
            "text": "You may have to use the command  eval $(docker-machine env)  before proceeding to get Docker to work.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.  If you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).   (default) Check network to re-create if needed...\n(default) Waiting for an IP...", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/products/ask/#spin-up-the-docker-container_3", 
            "text": "Ensure you are in the  ask/docker  directory.  First, run the following command to export your edited variables and set the environment variables.  source env.conf  The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f docker-compose.yml up -d  The  docker-compose.yml  file contained in the  ask/docker  directory contains all the instructions that Docker Compose needs to set up the Ask product.  Troubleshooting note : If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command  docker-compose --version .  Unsupported config option for services service: 'mongodata'  2. Docker will now download and install a number of Docker images. This may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1  4. If this is your first time installing Ask, you ll now have to shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f docker-compose.yml down  5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).  docker-compose -f docker-compose.yml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/products/ask/#access-ask_3", 
            "text": "You can now use Ask by accessing the front end URL in your browser. This is the URL you specified as  FRONTEND_HOST  in the  env.conf  setup above.   On Mac, the default Docker Machine IP for laptops is  192.168.99.100 :  http://192.168.99.100", 
            "title": "Access Ask"
        }, 
        {
            "location": "/products/ask/#advanced-setup-linux", 
            "text": "", 
            "title": "Advanced setup: Linux"
        }, 
        {
            "location": "/products/ask/#before-you-begin_4", 
            "text": "You must have the following items installed and running:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .  Docker Toolbox : You can install Docker Toolbox from the  Docker Toolbox product page .  If you already have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose --version .     You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/products/ask/#browser-requirements_4", 
            "text": "We currently support Chrome.", 
            "title": "Browser requirements"
        }, 
        {
            "location": "/products/ask/#set-up-your-external-storage-system-optional_1", 
            "text": "Ask uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.  There are currently a couple of different options available for the external storage system you can use.   Amazon S3 : Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.  Local file system : If you don t set up an external storage system in the  set environment variables  step, Ask will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Ask for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.", 
            "title": "Set up your external storage system (optional)"
        }, 
        {
            "location": "/products/ask/#amazon-s3_1", 
            "text": "Amazon S3  is a good option for your external storage system because it is fast, handles concurrency, and will scale well.  The setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon s instructions  here .   Follow the directions for  Sign Up for Amazon S3  and  Create a Bucket . There is no need to continue further to the demos for  Add an Object to a Bucket  and beyond: those are simply examples showing you how to use S3.    For my example, I named my bucket  ask-bucket-test  and chose region  Northern California  (which corresponds to us-west-2).  During the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).     Once you have signed up and set up a bucket, go to your  S3 console  to set up your permissions under  Security Credentials.    Ensure that under  Permissions,  the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).    You re all set! You can now use your AWS Access Key to connect Ask to your S3 bucket (you ll set this up in the  Set environment variables  section below). If you didn t save your AWS Access Key during the set up process, you can go to the  Security Credentials  section and create a new one.", 
            "title": "Amazon S3"
        }, 
        {
            "location": "/products/ask/#get-the-source-code_4", 
            "text": "Clone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/ask.git  Then cd into the  ask/docker  directory.  cd ask/docker", 
            "title": "Get the source code"
        }, 
        {
            "location": "/products/ask/#set-environment-variables_1", 
            "text": "The  env.conf  file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral front end will have, as well as other information such as your MongoDB username and password.  export FRONTEND_HOST=192.168.99.100\n\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral   FRONTEND_HOST : set to your desired IP address for the front end.  On Linux, this should be set to  127.0.0.1  or a private IP address.     MongoDB:   MONGO_USER : set to the username for your MongoDB  MONGO_PASS : set to the password for your MongoDB  MONGO_DB : set to the name of your MongoDB (in this instance,  coral )  MONGO_AUTHDB : set to the admin user of your database   Amazon S3 (optional):   S3_BUCKET : set to the name of your S3 bucket (in this example,  ask-bucket-test )  AWS_REGION : set to the AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In this example, it is  us-west-2 .  AWS_ACCESS_KEY : set to your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.  AWS_ACCESS_KEY : set to your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.", 
            "title": "Set environment variables"
        }, 
        {
            "location": "/products/ask/#start-docker_4", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/products/ask/#troubleshooting_4", 
            "text": "You may have to use the command  eval $(docker-machine env)  before proceeding to get Docker to work.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.  If you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).   (default) Check network to re-create if needed...\n(default) Waiting for an IP...", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/products/ask/#spin-up-the-docker-container_4", 
            "text": "Ensure you are in the  ask/docker  directory.  First, run the following command to export your edited variables and set the environment variables.  source env.conf  The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f docker-compose.yml up -d  The  docker-compose.yml  file contained in the  ask/docker  directory contains all the instructions that Docker Compose needs to set up the Ask product.  Troubleshooting note : If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command  docker-compose --version .  Unsupported config option for services service: 'mongodata'  2. Docker will now download and install a number of Docker images. This may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1  4. If this is your first time installing Ask, you ll now have to shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f docker-compose.yml down  5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).  docker-compose -f docker-compose.yml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/products/ask/#access-ask_4", 
            "text": "You can now use Ask by accessing the front end URL in your browser. This is the URL you specified as  FRONTEND_HOST  in the  env.conf  setup above.   On Linux, this should be set to  127.0.0.1  or a private IP address (the IP you set when  setting your environment variables ):  http://127.0.0.1", 
            "title": "Access Ask"
        }, 
        {
            "location": "/products/ask/#advanced-setup-windows", 
            "text": "", 
            "title": "Advanced setup: Windows"
        }, 
        {
            "location": "/products/ask/#before-you-begin_5", 
            "text": "You must have the following items installed and running:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .  Docker Toolbox : You can install Docker Toolbox from the  Docker Toolbox product page .  If you already have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose --version .     You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/products/ask/#browser-requirements_5", 
            "text": "We currently support Chrome.", 
            "title": "Browser requirements"
        }, 
        {
            "location": "/products/ask/#set-up-your-external-storage-system-optional_2", 
            "text": "Ask uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.  There are currently a couple of different options available for the external storage system you can use.   Amazon S3 : Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.  Local file system : If you don t set up an external storage system in the  set environment variables  step, Ask will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Ask for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.", 
            "title": "Set up your external storage system (optional)"
        }, 
        {
            "location": "/products/ask/#amazon-s3_2", 
            "text": "Amazon S3  is a good option for your external storage system because it is fast, handles concurrency, and will scale well.  The setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon s instructions  here .   Follow the directions for  Sign Up for Amazon S3  and  Create a Bucket . There is no need to continue further to the demos for  Add an Object to a Bucket  and beyond: those are simply examples showing you how to use S3.    For my example, I named my bucket  ask-bucket-test  and chose region  Northern California  (which corresponds to us-west-2).  During the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).     Once you have signed up and set up a bucket, go to your  S3 console  to set up your permissions under  Security Credentials.    Ensure that under  Permissions,  the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).    You re all set! You can now use your AWS Access Key to connect Ask to your S3 bucket (you ll set this up in the  Set environment variables  section below). If you didn t save your AWS Access Key during the set up process, you can go to the  Security Credentials  section and create a new one.", 
            "title": "Amazon S3"
        }, 
        {
            "location": "/products/ask/#get-the-source-code_5", 
            "text": "Clone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/ask.git  Then cd into the  ask/docker  directory.  cd ask/docker", 
            "title": "Get the source code"
        }, 
        {
            "location": "/products/ask/#set-environment-variables_2", 
            "text": "The  env.conf  file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral front end will have, as well as other information such as your MongoDB username and password.  export FRONTEND_HOST=192.168.99.100\n\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral   FRONTEND_HOST : set to your desired IP address for the front end.  On Windows, this should be set to  127.0.0.1  or a private IP address.     MongoDB:   MONGO_USER : set to the username for your MongoDB  MONGO_PASS : set to the password for your MongoDB  MONGO_DB : set to the name of your MongoDB (in this instance,  coral )  MONGO_AUTHDB : set to the admin user of your database   Amazon S3 (optional):   S3_BUCKET : set to the name of your S3 bucket (in this example,  ask-bucket-test )  AWS_REGION : set to the AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In this example, it is  us-west-2 .  AWS_ACCESS_KEY : set to your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.  AWS_ACCESS_KEY : set to your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.", 
            "title": "Set environment variables"
        }, 
        {
            "location": "/products/ask/#start-docker_5", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type  docker quickstart  into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/products/ask/#troubleshooting_5", 
            "text": "You may have to use the command  eval $(docker-machine env)  before proceeding to get Docker to work.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.  If you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).   (default) Check network to re-create if needed...\n(default) Waiting for an IP...", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/products/ask/#spin-up-the-docker-container_5", 
            "text": "Ensure you are in the  ask/docker  directory.  First, run the following command to export your edited variables and set the environment variables.  source env.conf  The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f docker-compose.yml up -d  The  docker-compose.yml  file contained in the  ask/docker  directory contains all the instructions that Docker Compose needs to set up the Ask product.  Troubleshooting note : If you see an error, such as the one below, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command  docker-compose --version .  Unsupported config option for services service: 'mongodata'  2. Docker will now download and install a number of Docker images. This may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1  4. If this is your first time installing Ask, you ll now have to shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f docker-compose.yml down  5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).  docker-compose -f docker-compose.yml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/products/ask/#access-ask_5", 
            "text": "You can now use Ask by accessing the front end URL in your browser. This is the URL you specified as  FRONTEND_HOST  in the  env.conf  setup above.   On Windows, this should be set to  127.0.0.1  or a private IP address (the IP you set when  setting your environment variables ):  http://127.0.0.1", 
            "title": "Access Ask"
        }, 
        {
            "location": "/products/ask/#troubleshooting_6", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/products/ask/#old-version-of-docker", 
            "text": "If you see an error while running the Docker Compose commands, make sure that your Docker Compose installation is version 1.7 or above. You can check your version using the command  docker-compose --version .\nExample error:  Unsupported config option for services service: 'mongodata'", 
            "title": "Old version of Docker"
        }, 
        {
            "location": "/products/ask/#viewing-running-docker-containers", 
            "text": "To see all of the Docker containers currently running, use the command  docker ps  (you can read more about this command and its options at the  Docker website ).  docker ps  You should have all of the following containers running:   nginx:stable-alpine  coralproject/cay:release  coralproject/elkhorn  coralproject/pillar:release  coralproject/mongodata", 
            "title": "Viewing running Docker containers"
        }, 
        {
            "location": "/products/ask/#viewing-installed-docker-images", 
            "text": "To see all of the Docker images you have installed, use the command  docker images  (you can read more about this command and its options at the  Docker website ).  docker images", 
            "title": "Viewing installed Docker images"
        }, 
        {
            "location": "/products/ask/#viewing-docker-logs", 
            "text": "To view Docker logs for a container, use the command  docker logs  container id  (you can read more about this command and its options at the  Docker website ).  First you have to find the container id:  docker ps  Then use the container id to view the logs:  docker logs e0bbd7be19c7", 
            "title": "Viewing Docker logs"
        }, 
        {
            "location": "/products/ask/#removing-docker-images", 
            "text": "There are a few reasons you might want to remove Docker images. You may wish to ensure that you are getting the latest build of the image. Or maybe something has gone awry with one or more of the images, and you just want to perform a fresh install of all images.  To remove all Docker images, use this command:  docker rmi $(docker images -q)", 
            "title": "Removing Docker images"
        }, 
        {
            "location": "/products/ask/#removing-old-docker-machines", 
            "text": "Another option for a  fresh install  is to remove old Docker machines. You could try this in combination with  removing Docker images  and then reinstalling Ask to see if that fixes your issue.  docker rm -f $(docker ps -a -q)", 
            "title": "Removing old Docker machines"
        }, 
        {
            "location": "/products/ask/#other-issues-while-installing", 
            "text": "You may have to use the command  eval $(docker-machine env)  after you ve started Docker in order to get Docker to work.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.  If you see an error like the one below, try closing and reopening Docker Quickstart Terminal again, or simply waiting (sometimes it can take a few moments).   (default) Check network to re-create if needed...\n(default) Waiting for an IP...", 
            "title": "Other issues while installing"
        }, 
        {
            "location": "/products/ask/#ask-tutorials", 
            "text": "We are still developing our Ask tutorials. In the meantime, you can read our guide on  how to approach asking your readers for information.", 
            "title": "Ask tutorials"
        }, 
        {
            "location": "/products/ask/#ask-docker-compose-installation", 
            "text": "You can install the Ask product through a straightforward Docker Compose installation. This installs only the parts of Coral that are required for Ask.", 
            "title": "Ask Docker Compose Installation"
        }, 
        {
            "location": "/products/ask/#before-you-begin_6", 
            "text": "You must have the following items installed and running:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .   You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/products/ask/#install-docker-toolbox", 
            "text": "If you do not already have Docker installed, do that first. You can install Docker Toolbox using the Docker instructions  located here .  If you do have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker version .", 
            "title": "Install Docker Toolbox"
        }, 
        {
            "location": "/products/ask/#set-up-your-external-storage-system-optional_3", 
            "text": "Ask uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.  There are currently a couple of different options available for the external storage system you can use.   Amazon S3 : Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.  Local file system : If you don t set up an external storage system in the  set environment variables  step, Ask will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Ask for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.", 
            "title": "Set up your external storage system (optional)"
        }, 
        {
            "location": "/products/ask/#amazon-s3_3", 
            "text": "Amazon S3  is a good option for your external storage system because it is fast, handles concurrency, and will scale well.  The setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon s instructions  here .   Follow the directions for  Sign Up for Amazon S3  and  Create a Bucket . There is no need to continue further to the demos for  Add an Object to a Bucket  and beyond: those are simply examples showing you how to use S3.    For my example, I named my bucket  ask-bucket-test  and chose region  Northern California  (which corresponds to us-west-2).  During the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).     Once you have signed up and set up a bucket, go to your  S3 console  to set up your permissions under  Security Credentials.    Ensure that under  Permissions,  the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).    You re all set! You can now use your AWS Access Key to connect Ask to your S3 bucket (you ll set this up in the  Set environment variables  section below). If you didn t save your AWS Access Key during the set up process, you can go to the  Security Credentials  section and create a new one.", 
            "title": "Amazon S3"
        }, 
        {
            "location": "/products/ask/#get-the-source-code_6", 
            "text": "Clone the Ask repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/ask.git  Then cd into the  ask/docker  directory.  cd ask/docker", 
            "title": "Get the source code"
        }, 
        {
            "location": "/products/ask/#set-environment-variables_3", 
            "text": "The  env.conf  file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral front end will have, as well as other information such as your MongoDB username and password.  export FRONTEND_HOST=xxx\n\nexport AUTH_TOKEN_VALUE='Basic xxx'\nexport GAID_VALUE=xxx\n\nexport MONGO_USER=xxx\nexport MONGO_PASS=xxx\nexport MONGO_DB=xxx\nexport MONGO_AUTHDB=xxx\n\nexport RABBIT_USER=xxx\nexport RABBIT_PASS=xxx\n\nexport S3_BUCKET=xxx\nexport AWS_REGION=xxx\nexport AWS_ACCESS_KEY_ID=xxx\nexport AWS_ACCESS_KEY=xxx   FRONTEND_HOST : set to your desired IP address for the front end. For this example, we will use  192.168.99.100 .   MongoDB:   MONGO_USER : set to the username for your MongoDB  MONGO_PASS : set to the password for your MongoDB  MONGO_DB : set to the name of your MongoDB (in this instance,  coral )  MONGO_AUTHDB : set to the admin user of your database   Amazon S3:   S3_BUCKET : set to the name of your S3 bucket (in this example,  ask-bucket-test )  AWS_REGION : set to the AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In this example, it is  us-west-2 .  AWS_ACCESS_KEY : set to your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.  AWS_ACCESS_KEY : set to your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.   Optional edits:   GAID_VALUE=xxxx : If you re using Google Analytics, set your token at  export GAID_VALUE=xxxx . Otherwise, delete or comment out this line.  export AUTH_TOKEN_VALUE=xxxx : If you re using a custom auth token, set that at  export AUTH_TOKEN_VALUE=xxxx . Otherwise, delete or comment out this line.", 
            "title": "Set environment variables"
        }, 
        {
            "location": "/products/ask/#start-docker_6", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type  docker quickstart  into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.     Ensure you are in the  ask/docker  directory.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/products/ask/#spin-up-the-docker-container_6", 
            "text": "First, run the following command to export your edited variables and set the environment variables.  source env.conf  The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f docker-compose.yml up -d  The  docker-compose.yml  file contained in the  ask/docker  directory contains all the instructions that Docker Compose needs to set up the Ask product.  2. Docker will now download and install a number of Docker images. This may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating network  docker_default  with the default driver\nCreating docker_mongodata_1\nCreating docker_pillarapp_1\nCreating docker_elkhorn_1\nCreating docker_cayapp_1\nCreating docker_proxy_1  4. If this is your first time installing Ask, you ll now have to shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f docker-compose.yml down  5. Finally, start the Docker container back up. In future, you can simply use this command to start your Docker container (instead of bringing Docker up, then down, then up again).  docker-compose -f docker-compose.yml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/products/ask/#access-ask_6", 
            "text": "You can now use Ask by accessing the front end URL in your browser. This is the URL you specified as  FRONTEND_HOST  in the  env.conf  setup above. In this example, we set it to  http://192.168.99.100 .", 
            "title": "Access Ask"
        }, 
        {
            "location": "/products/ask/#troubleshooting_7", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/products/ask/#viewing-running-docker-containers_1", 
            "text": "To see all of the Docker containers currently running, use the command  docker ps  (you can read more about this command and its options at the  Docker website ).  docker ps  You should have all of the following containers running:   nginx:stable-alpine  coralproject/cay:release  coralproject/elkhorn  coralproject/pillar:release  coralproject/mongodata", 
            "title": "Viewing running Docker containers"
        }, 
        {
            "location": "/products/ask/#viewing-installed-docker-images_1", 
            "text": "To see all of the Docker images you have installed, use the command  docker images  (you can read more about this command and its options at the  Docker website ).  docker images", 
            "title": "Viewing installed Docker images"
        }, 
        {
            "location": "/products/ask/#viewing-docker-logs_1", 
            "text": "To view Docker logs for a container, use the command  docker logs  container id  (you can read more about this command and its options at the  Docker website ).  First you have to find the container id:  docker ps  Then use the container id to view the logs:  docker logs e0bbd7be19c7", 
            "title": "Viewing Docker logs"
        }, 
        {
            "location": "/products/ask/#operating-system-requirements", 
            "text": "On Mac, we support OS X El Capitan (10.11) or newer. If you are on an older OS, you may have to upgrade.", 
            "title": "Operating system requirements"
        }, 
        {
            "location": "/products/ask/#uninstalling-docker-images", 
            "text": "", 
            "title": "Uninstalling Docker images"
        }, 
        {
            "location": "/products/ask/#ask-tutorials_1", 
            "text": "This page will get filled in as we unroll the Ask product. In the meantime, you can find out more on the Ask product on  our website .", 
            "title": "Ask tutorials"
        }, 
        {
            "location": "/products/talk/", 
            "text": "Talk\n\n\nThis page will get filled in as we unroll the Talk product. In the meantime, you can find out more on the Talk product on \nour website\n.\n\n\nRoadmap\n\n\n\n\nBeta release\n: Q4 2016\n\n\nv1.0\n: Q4 2016/Q1 2017\n\n\n\n\nTalk tutorials\n\n\nThis page will get filled in as we unroll the Talk product. In the meantime, you can find out more on the Talk product on \nour website\n.", 
            "title": "Talk"
        }, 
        {
            "location": "/products/talk/#talk", 
            "text": "This page will get filled in as we unroll the Talk product. In the meantime, you can find out more on the Talk product on  our website .", 
            "title": "Talk"
        }, 
        {
            "location": "/products/talk/#roadmap", 
            "text": "Beta release : Q4 2016  v1.0 : Q4 2016/Q1 2017", 
            "title": "Roadmap"
        }, 
        {
            "location": "/products/talk/#talk-tutorials", 
            "text": "This page will get filled in as we unroll the Talk product. In the meantime, you can find out more on the Talk product on  our website .", 
            "title": "Talk tutorials"
        }, 
        {
            "location": "/products/trust/", 
            "text": "Trust overview\n\n\nWhat is Trust?\n\n\nThe Trust product is a tool that allows journalistic organizations to filter through and create metrics based on individual comment behavior, and also add qualitative information. This information can be used to help journalistic organizations take next steps to better utilize and strengthen their communities.\n\n\nThe \ntutorials section\n will help guide you through accomplishing goals like the following:\n\n\n\n\nI would like to find the most liked comments based on keyword/topic searches, so that I can do a round up (for instance, \nbest comments written about the Zika virus\u201d).\n\n\nI would like to identify commenters who leave high-quality comments that appear to be expert, so that potential sources can be identified.\n\n\nI would like to identify new commenters who leave comments that get a lot of likes, so I can welcome them personally.\n\n\nI would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.\n\n\n\n\nRoadmap\n\n\nThe Trust beta will be released Q3 of 2016.\n\n\nTrust sections\n\n\nTrust is comprised of the following sections:\n\n\n\n\nDashboard\n\n\nCommunity Explorer\n\n\nLists\n\n\nSettings\n\n\n\n\nTrust tutorials\n\n\nThis is where you can find tutorials on how to use Trust. \nThis section is still in development, as Trust continues to evolve.\n\n\nDo you have a tutorial you\nd like to see here? Please \nget in touch and let us know about it\n, or better still, \nadd it yourself!\n\n\nWhat would you like to do?\n\n\n\n\nIdentify trolls\n: I would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.\n\n\n\n\nWe are developing additional tutorials, including \nIdentify the most liked comments\n and \nIdentify high quality new commenters.\n\n\nIdentify trolls\n\n\nWe would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.\n\n\nWhat are some ways that can we identify trolls?\n\n\n\n\nA user with a high percentage of moderator deleted comments.\n\n\n\n\nWhat might we be able to do about users like this?\n\n\n\n\nIt\ns possible that a user may not exhibit troll behavior in all sections or for all authors. We can identify the sections in which they havea  high percentage of moderator deleted comments and ban them only for those sections/authors, so that they can continue to contribute to the community elsewhere.\n\n\nWe can automatically move that user\ns comments into pre-moderation.\n\n\n\n\nHow to identify trolls on certain topics or authors\n\n\nWe are going to create and save a list of commenters who have a high percentage of moderated deleted comments for a particular section or author. For the purposes of this tutorial, we\nll assume we are looking for trolls in the \nNational\n section.\n\n\n1) Open the \nCreate a Search\n page by clicking the wrench symbol on the side navigation bar.\n\n\n\n\n2) In the \nFilters\n section, choose \nSection\n in the drop down. This will trigger the display of a second drop down, which will let you choose which section you want to filter in (in this case, the \nnational\n section).\n\n\n \n\n\n3) Scroll down to the \nPercent moderator deleted\n filter.\n\n\n\n\n4) Fill in \n50\n and \n100\n: you\nre now filtering out all of the users in the \nNational\n section who have had 50% or more of their comments moderator deleted.\n\n\n\n\n5) You now have a filter that shows you all of the users who have had over 50% of their comments in the National section deleted by moderators. You can now save that search to refer back to later, or to allow your colleagues to have access to the search as well.\n\n\nClick the \nSave Search\n button in the upper right to save.\n\n\n\n\n6) You can now fill in the name of the search and a brief description. The \ntag\n field will create a tag that will attach itself to each user in the \nTrolls in National section\n list.\n\n\nClick \nConfirm\n to save your search.\n\n\n\n\n7) You (and your colleagues) can now access this saved search via the \nSaved Search\n button in the side navigation bar.", 
            "title": "Trust"
        }, 
        {
            "location": "/products/trust/#trust-overview", 
            "text": "", 
            "title": "Trust overview"
        }, 
        {
            "location": "/products/trust/#what-is-trust", 
            "text": "The Trust product is a tool that allows journalistic organizations to filter through and create metrics based on individual comment behavior, and also add qualitative information. This information can be used to help journalistic organizations take next steps to better utilize and strengthen their communities.  The  tutorials section  will help guide you through accomplishing goals like the following:   I would like to find the most liked comments based on keyword/topic searches, so that I can do a round up (for instance,  best comments written about the Zika virus\u201d).  I would like to identify commenters who leave high-quality comments that appear to be expert, so that potential sources can be identified.  I would like to identify new commenters who leave comments that get a lot of likes, so I can welcome them personally.  I would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.", 
            "title": "What is Trust?"
        }, 
        {
            "location": "/products/trust/#roadmap", 
            "text": "The Trust beta will be released Q3 of 2016.", 
            "title": "Roadmap"
        }, 
        {
            "location": "/products/trust/#trust-sections", 
            "text": "Trust is comprised of the following sections:   Dashboard  Community Explorer  Lists  Settings", 
            "title": "Trust sections"
        }, 
        {
            "location": "/products/trust/#trust-tutorials", 
            "text": "This is where you can find tutorials on how to use Trust.  This section is still in development, as Trust continues to evolve.  Do you have a tutorial you d like to see here? Please  get in touch and let us know about it , or better still,  add it yourself!", 
            "title": "Trust tutorials"
        }, 
        {
            "location": "/products/trust/#what-would-you-like-to-do", 
            "text": "Identify trolls : I would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.   We are developing additional tutorials, including  Identify the most liked comments  and  Identify high quality new commenters.", 
            "title": "What would you like to do?"
        }, 
        {
            "location": "/products/trust/#identify-trolls", 
            "text": "We would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.  What are some ways that can we identify trolls?   A user with a high percentage of moderator deleted comments.   What might we be able to do about users like this?   It s possible that a user may not exhibit troll behavior in all sections or for all authors. We can identify the sections in which they havea  high percentage of moderator deleted comments and ban them only for those sections/authors, so that they can continue to contribute to the community elsewhere.  We can automatically move that user s comments into pre-moderation.", 
            "title": "Identify trolls"
        }, 
        {
            "location": "/products/trust/#how-to-identify-trolls-on-certain-topics-or-authors", 
            "text": "We are going to create and save a list of commenters who have a high percentage of moderated deleted comments for a particular section or author. For the purposes of this tutorial, we ll assume we are looking for trolls in the  National  section.  1) Open the  Create a Search  page by clicking the wrench symbol on the side navigation bar.   2) In the  Filters  section, choose  Section  in the drop down. This will trigger the display of a second drop down, which will let you choose which section you want to filter in (in this case, the  national  section).     3) Scroll down to the  Percent moderator deleted  filter.   4) Fill in  50  and  100 : you re now filtering out all of the users in the  National  section who have had 50% or more of their comments moderator deleted.   5) You now have a filter that shows you all of the users who have had over 50% of their comments in the National section deleted by moderators. You can now save that search to refer back to later, or to allow your colleagues to have access to the search as well.  Click the  Save Search  button in the upper right to save.   6) You can now fill in the name of the search and a brief description. The  tag  field will create a tag that will attach itself to each user in the  Trolls in National section  list.  Click  Confirm  to save your search.   7) You (and your colleagues) can now access this saved search via the  Saved Search  button in the side navigation bar.", 
            "title": "How to identify trolls on certain topics or authors"
        }, 
        {
            "location": "/developer/", 
            "text": "Introduction\n\n\nWelcome! This is the place to be if you want to learn more about Coral from the standpoint of a developer or a technical user. Here you can learn about the inner workings of Coral, how to install the products, how to use the APIs, and more.\n\n\nIf you are a developer who is interested in contributing to our code, great! You can read more about contributing in our \nContribute section\n.\n\n\nThe Coral Ecosystem\n\n\nCoral is made up of a number of component apps that work together to power three products (Trust, Ask, and Talk). You can read more about how this ecosystem fits together \nhere\n.\n\n\nInstallation\n\n\nThere are a few different installation options to choose from. Which one is right for you?\n\n\nInstall a fully functioning single-server Coral Ecosystem, using Docker.\n\n\nThis is a quick, easy, packaged solution that requires few steps and should get all components up and running quickly. The downside is that this may not scale well, as everything is installed on one server. After a certain number of users (perhaps 50 or so), the server could become overloaded.\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space required: 4GB\n\n\n\n\nYou can find instructions on how to install Coral as a single Docker Compose installation \nhere\n.\n\n\nProbably best for you if:\n\n\n\n\nYou want to install Coral to perform a demo.\n\n\nYou want to get Coral running on your local machine to get a sense of its functionality and capabilities.\n\n\nYou want to get Coral up and running, and aren\nt worried about scaling right now.\n\n\n\n\nInstalling each component individually, using Docker.\n\n\nThis will install each component on a separate server, which allows for scaling up in future. It does require some more work to get each component talking and interacting with each other, but will scale better.\n\n\nIf you choose this option, you can visit the installation page for each Coral component, which has installation instructions for Docker and source.\n\n\n\n\nCay installation instructions\n\n\nElkhorn installation instructions\n\n\nPillar installation instructions\n\n\nSponge installation instructions\n\n\nXenia installation instructions\n\n\n\n\nProbably best for you if:\n\n\n\n\nYou have multiple servers, and are concerned about scalability.\n\n\nYou have a sysadmin to help manage installation and maintenance.\n\n\n\n\nInstalling each component individually from source code.\n\n\nThis option will have you install each component individually from source code, which will either be Go (most components) or Node.js.\n\n\nIf you choose this option, you can visit the installation page for each Coral component, which has installation instructions for Docker and source.\n\n\n\n\nCay installation instructions\n\n\nElkhorn installation instructions\n\n\nPillar installation instructions\n\n\nSponge installation instructions\n\n\nXenia installation instructions\n\n\n\n\nProbably best for you if:\n\n\n\n\nYou are a developer that wants to work on Coral and potentially \ncontribute to our code base\n (thank you!).", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/#introduction", 
            "text": "Welcome! This is the place to be if you want to learn more about Coral from the standpoint of a developer or a technical user. Here you can learn about the inner workings of Coral, how to install the products, how to use the APIs, and more.  If you are a developer who is interested in contributing to our code, great! You can read more about contributing in our  Contribute section .", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/#the-coral-ecosystem", 
            "text": "Coral is made up of a number of component apps that work together to power three products (Trust, Ask, and Talk). You can read more about how this ecosystem fits together  here .", 
            "title": "The Coral Ecosystem"
        }, 
        {
            "location": "/developer/#installation", 
            "text": "There are a few different installation options to choose from. Which one is right for you?", 
            "title": "Installation"
        }, 
        {
            "location": "/developer/#install-a-fully-functioning-single-server-coral-ecosystem-using-docker", 
            "text": "This is a quick, easy, packaged solution that requires few steps and should get all components up and running quickly. The downside is that this may not scale well, as everything is installed on one server. After a certain number of users (perhaps 50 or so), the server could become overloaded.  You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space required: 4GB   You can find instructions on how to install Coral as a single Docker Compose installation  here .  Probably best for you if:   You want to install Coral to perform a demo.  You want to get Coral running on your local machine to get a sense of its functionality and capabilities.  You want to get Coral up and running, and aren t worried about scaling right now.", 
            "title": "Install a fully functioning single-server Coral Ecosystem, using Docker."
        }, 
        {
            "location": "/developer/#installing-each-component-individually-using-docker", 
            "text": "This will install each component on a separate server, which allows for scaling up in future. It does require some more work to get each component talking and interacting with each other, but will scale better.  If you choose this option, you can visit the installation page for each Coral component, which has installation instructions for Docker and source.   Cay installation instructions  Elkhorn installation instructions  Pillar installation instructions  Sponge installation instructions  Xenia installation instructions   Probably best for you if:   You have multiple servers, and are concerned about scalability.  You have a sysadmin to help manage installation and maintenance.", 
            "title": "Installing each component individually, using Docker."
        }, 
        {
            "location": "/developer/#installing-each-component-individually-from-source-code", 
            "text": "This option will have you install each component individually from source code, which will either be Go (most components) or Node.js.  If you choose this option, you can visit the installation page for each Coral component, which has installation instructions for Docker and source.   Cay installation instructions  Elkhorn installation instructions  Pillar installation instructions  Sponge installation instructions  Xenia installation instructions   Probably best for you if:   You are a developer that wants to work on Coral and potentially  contribute to our code base  (thank you!).", 
            "title": "Installing each component individually from source code."
        }, 
        {
            "location": "/developer/architectural_overview/", 
            "text": "Architectural overview\n\n\nOver the course of the project, we are building an ecosystem of products, tools and practices. These elements will work together and/or integrate with existing community tools.\n\n\nCoral Ecosystem\n\n\nThe Coral Ecosystem consists of five apps working together with the Coral MongoDB database. You can see how these apps communicate with each other in the diagram below.\n\n\n\n\nCay\n is the front end application for Coral.\n\n\nElkhorn\n is the embeddable form builder. Cay sends a form specification in JSON format to Elkhorn, and Elkhorn sends back a rendered reader-facing form.\n\n\nPillar\n is the primary service that interacts with the Coral database. It works with Sponge to import external data, and performs CRUD (Create, Read, Update, Delete) operations on the Coral database.\n\n\nSponge\n is the data import service that extracts data from an external data source, and passes that data on to Pillar.\n\n\nXenia\n is a service layer that performs aggregated pipelines queries on the data in the Coral database.\n\n\n\n\n\n\nAsk\n\n\nAsk\n is a product that enables editors to create embeddable calls for contributions, including text, photo, video, audio.\n\n\n\n\nTrust\n\n\nTrust\n is a product that enables newsroom users to identify different kinds of end users in order to take actions (for instance, \nI want to block these trolls on this author,\n or \nI want to highlight the best commenters on this subject\n). It allows newsrooms to make manual or automated lists of users via a series of filters.\n\n\n\n\nTalk\n\n\nTalk is still in development.", 
            "title": "Architectural overview"
        }, 
        {
            "location": "/developer/architectural_overview/#architectural-overview", 
            "text": "Over the course of the project, we are building an ecosystem of products, tools and practices. These elements will work together and/or integrate with existing community tools.", 
            "title": "Architectural overview"
        }, 
        {
            "location": "/developer/architectural_overview/#coral-ecosystem", 
            "text": "The Coral Ecosystem consists of five apps working together with the Coral MongoDB database. You can see how these apps communicate with each other in the diagram below.   Cay  is the front end application for Coral.  Elkhorn  is the embeddable form builder. Cay sends a form specification in JSON format to Elkhorn, and Elkhorn sends back a rendered reader-facing form.  Pillar  is the primary service that interacts with the Coral database. It works with Sponge to import external data, and performs CRUD (Create, Read, Update, Delete) operations on the Coral database.  Sponge  is the data import service that extracts data from an external data source, and passes that data on to Pillar.  Xenia  is a service layer that performs aggregated pipelines queries on the data in the Coral database.", 
            "title": "Coral Ecosystem"
        }, 
        {
            "location": "/developer/architectural_overview/#ask", 
            "text": "Ask  is a product that enables editors to create embeddable calls for contributions, including text, photo, video, audio.", 
            "title": "Ask"
        }, 
        {
            "location": "/developer/architectural_overview/#trust", 
            "text": "Trust  is a product that enables newsroom users to identify different kinds of end users in order to take actions (for instance,  I want to block these trolls on this author,  or  I want to highlight the best commenters on this subject ). It allows newsrooms to make manual or automated lists of users via a series of filters.", 
            "title": "Trust"
        }, 
        {
            "location": "/developer/architectural_overview/#talk", 
            "text": "Talk is still in development.", 
            "title": "Talk"
        }, 
        {
            "location": "/developer/quickstart/install/", 
            "text": "All-in-One Docker Compose Installation\n\n\nThe all-in-one Docker Compose installation is a quick, easy, packaged solution that requires few steps and should get all components up and running quickly. The downside is that this may not scale well, as everything is installed on one server. After a certain number of users (perhaps 50 or so), the server could become overloaded.\n\n\nYou can read about the different types of installation options on the \ndeveloper introduction page\n.\n\n\nBefore you begin\n\n\nYou must have the following items installed and running:\n\n\n\n\nMongoDB Server\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nRabbitMQ\n: You can find instructions on installing RabbitMQ \non the RabbitMQ website\n.\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space required: 4GB\n\n\n\n\nOperating system requirements\n\n\nOn Mac, we support OS X El Capitan (10.11) or newer. If you are on an older OS, you may have to upgrade.\n\n\nInstall Docker Toolbox\n\n\nIf you do not already have Docker installed, do that first. You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you do have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose version\n.\n\n\n\n\nOn the server, you can install Docker with the following command:\n\n\n\n\nsudo yum install docker\n\n\n\n\nGet the source code\n\n\nClone the Proxy repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/Proxy.git\n\n\n\n\nThen cd into the Proxy directory.\n\n\ncd Proxy\n\n\n\n\nSet environment variables\n\n\nThe \nenv.conf\n file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral frontend will have, as well as other information such as your MongoDB username and password.\n\n\nexport FRONTEND_HOST=\n\nexport GAID_VALUE=xxxx\nexport AUTH_TOKEN_VALUE=xxxx\nexport RABBIT_USER=rabbitmq\nexport RABBIT_PASS=welcome\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral\n\n#elkhorn\nexport accessKeyId=xxx\nexport secretAccessKey=xxx\nexport pillarHost=xxx\nexport basicAuthorization=xxx\nexport bucket=xxx\nexport region=xxx\n# sponge:\nexport STRATEGY_CONF=/usr/local/strategy.json\n\n\n\n\nRequired edits:\n\n\n\n\nFRONTEND_HOST\n: set to your desired IP address for the front end. For this example, we will use \n192.168.99.100\n, which is the default Docker machine IP for local machine installs.\n\n\n\n\nOptional edits:\n\n\n\n\nGAID_VALUE=xxxx\n: If you\nre using Google Analytics, set your token at \nexport GAID_VALUE=xxxx\n. Otherwise, delete or comment out this line.\n\n\nexport AUTH_TOKEN_VALUE=xxxx\n: If you\nre using a custom auth token, set that at \nexport AUTH_TOKEN_VALUE=xxxx\n. Otherwise, delete or comment out this line.\n\n\n\n\nFinally, while inside the \nProxy\n directory, run the following command to export your edited variables and set the environment variables.\n\n\nsource env.conf\n\n\n\n\nSpin up the Docker container\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nThe \ndocker-compose.yml\n file contained in the docker-setup directory contains all the instructions that Docker Compose needs to set up the Coral Ecosystem.\n\n\n2. \nNote:\n If this is your first time spinning up the Docker container, Docker is going to download and install a number of Docker images first. These can be fairly large (~500MB per image), so it may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating proxy_mongodata_1\nCreating proxy_sponge_1\nCreating proxy_rabbitmq_1\nCreating proxy_atollapp_1\nCreating proxy_xeniaapp_1\nCreating proxy_pillarapp_1\nCreating proxy_cayapp_1\nCreating proxy_proxy_1\n\n\n\n\nNote\n: If this is your first time spinning up the Docker container, be aware that there is a large chunk of dummy data being downloaded as well. This happens behind the scenes, so it isn\nt as easy to tell whether or not it is done. You can check on its progress by looking at the logs.\n\n\nFirst you have to find the container id for proxy_mongodata_1:\n\n\ndocker ps\n\n\n\n\nThen use the container id to view the logs:\n\n\ndocker logs e0bbd7be19c7\n\n\n\n\nIf it has not finished downloading, you\nll see this as the final line in the logs:\n\n\nNotice: doownloading dump from https://s3.amazonaws.com/coral-demo-dataset/dump.tar.gz\n\n\n\n\nIf it has finished downloading, you should see this among the final lines in the logs:\n\n\n2016-07-21T00:42:33.024+0000 I NETWORK  [HostnameCanonicalizationWorker] Starting hostname canonicalization worker\n2016-07-21T00:42:33.025+0000 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/diagnostic.data'\n2016-07-21T00:42:33.031+0000 I NETWORK  [initandlisten] waiting for connections on port 27017\n\n\n\n\n4. Now, shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f docker-compose.yml down\n\n\n\n\n5. Finally, start the Docker container back up. In future (now that the Docker images have all been downloaded and set up), you can simply use this command to start your Docker container.\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nTest it out\n\n\nTo make sure it\ns working, try to hit the front-end URL in your browser. This is the URL you specified as \nFRONTEND_HOST\n in the \nenv.conf\n setup above; in this case, \nhttps://192.168.99.100\n.\n\n\nTroubleshooting\n\n\nViewing running Docker containers\n\n\nTo see all of the Docker containers currently running, use the command \ndocker ps\n (you can read more about this command and its options at the \nDocker website\n).\n\n\ndocker ps\n\n\n\n\nYou should have all of the following containers running:\n\n\n\n\nnginx:stable-alpine\n\n\ncoralproject/cay\n\n\ncoralproject/elkhorn\n\n\ncoralproject/pillar\n\n\ncoralproject/atoll\n\n\ncoralproject/xenia\n\n\ncoralproject/sponge\n\n\nrabbitmq:management\n\n\ncoralproject/mongodata\n\n\n\n\nViewing installed Docker images\n\n\nTo see all of the Docker images you have installed, use the command \ndocker images\n (you can read more about this command and its options at the \nDocker website\n).\n\n\ndocker images\n\n\n\n\nViewing Docker logs\n\n\nTo view Docker logs for a container, use the command \ndocker logs \ncontainer id\n (you can read more about this command and its options at the \nDocker website\n).\n\n\nFirst you have to find the container id:\n\n\ndocker ps\n\n\n\n\nThen use the container id to view the logs:\n\n\ndocker logs e0bbd7be19c7\n\n\n\n\nRemoving Docker images\n\n\nThere are a few reasons you might want to remove Docker images. You may wish to ensure that you are getting the latest build of the image. Or maybe something has gone awry with one or more of the images, and you just want to perform a fresh install of all images.\n\n\nTo remove all Docker images, use this command:\n\n\ndocker rmi $(docker images -q)\n\n\n\n\nRemoving old Docker machines\n\n\nAnother option for a \nfresh install\n is to remove old Docker machines. You could try this in combination with \nremoving Docker images\n and then reinstalling Ask to see if that fixes your issue.\n\n\ndocker rm -f $(docker ps -a -q)", 
            "title": "Installing Coral Ecosystem"
        }, 
        {
            "location": "/developer/quickstart/install/#all-in-one-docker-compose-installation", 
            "text": "The all-in-one Docker Compose installation is a quick, easy, packaged solution that requires few steps and should get all components up and running quickly. The downside is that this may not scale well, as everything is installed on one server. After a certain number of users (perhaps 50 or so), the server could become overloaded.  You can read about the different types of installation options on the  developer introduction page .", 
            "title": "All-in-One Docker Compose Installation"
        }, 
        {
            "location": "/developer/quickstart/install/#before-you-begin", 
            "text": "You must have the following items installed and running:   MongoDB Server : You can find instructions on installing MongoDB  on the MongoDB website .  RabbitMQ : You can find instructions on installing RabbitMQ  on the RabbitMQ website .   You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space required: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/developer/quickstart/install/#operating-system-requirements", 
            "text": "On Mac, we support OS X El Capitan (10.11) or newer. If you are on an older OS, you may have to upgrade.", 
            "title": "Operating system requirements"
        }, 
        {
            "location": "/developer/quickstart/install/#install-docker-toolbox", 
            "text": "If you do not already have Docker installed, do that first. You can install Docker Toolbox from the  Docker Toolbox product page .  If you do have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose version .   On the server, you can install Docker with the following command:   sudo yum install docker", 
            "title": "Install Docker Toolbox"
        }, 
        {
            "location": "/developer/quickstart/install/#get-the-source-code", 
            "text": "Clone the Proxy repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/Proxy.git  Then cd into the Proxy directory.  cd Proxy", 
            "title": "Get the source code"
        }, 
        {
            "location": "/developer/quickstart/install/#set-environment-variables", 
            "text": "The  env.conf  file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral frontend will have, as well as other information such as your MongoDB username and password.  export FRONTEND_HOST=\n\nexport GAID_VALUE=xxxx\nexport AUTH_TOKEN_VALUE=xxxx\nexport RABBIT_USER=rabbitmq\nexport RABBIT_PASS=welcome\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral\n\n#elkhorn\nexport accessKeyId=xxx\nexport secretAccessKey=xxx\nexport pillarHost=xxx\nexport basicAuthorization=xxx\nexport bucket=xxx\nexport region=xxx\n# sponge:\nexport STRATEGY_CONF=/usr/local/strategy.json  Required edits:   FRONTEND_HOST : set to your desired IP address for the front end. For this example, we will use  192.168.99.100 , which is the default Docker machine IP for local machine installs.   Optional edits:   GAID_VALUE=xxxx : If you re using Google Analytics, set your token at  export GAID_VALUE=xxxx . Otherwise, delete or comment out this line.  export AUTH_TOKEN_VALUE=xxxx : If you re using a custom auth token, set that at  export AUTH_TOKEN_VALUE=xxxx . Otherwise, delete or comment out this line.   Finally, while inside the  Proxy  directory, run the following command to export your edited variables and set the environment variables.  source env.conf", 
            "title": "Set environment variables"
        }, 
        {
            "location": "/developer/quickstart/install/#spin-up-the-docker-container", 
            "text": "The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f docker-compose.yml up -d  The  docker-compose.yml  file contained in the docker-setup directory contains all the instructions that Docker Compose needs to set up the Coral Ecosystem.  2.  Note:  If this is your first time spinning up the Docker container, Docker is going to download and install a number of Docker images first. These can be fairly large (~500MB per image), so it may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating proxy_mongodata_1\nCreating proxy_sponge_1\nCreating proxy_rabbitmq_1\nCreating proxy_atollapp_1\nCreating proxy_xeniaapp_1\nCreating proxy_pillarapp_1\nCreating proxy_cayapp_1\nCreating proxy_proxy_1  Note : If this is your first time spinning up the Docker container, be aware that there is a large chunk of dummy data being downloaded as well. This happens behind the scenes, so it isn t as easy to tell whether or not it is done. You can check on its progress by looking at the logs.  First you have to find the container id for proxy_mongodata_1:  docker ps  Then use the container id to view the logs:  docker logs e0bbd7be19c7  If it has not finished downloading, you ll see this as the final line in the logs:  Notice: doownloading dump from https://s3.amazonaws.com/coral-demo-dataset/dump.tar.gz  If it has finished downloading, you should see this among the final lines in the logs:  2016-07-21T00:42:33.024+0000 I NETWORK  [HostnameCanonicalizationWorker] Starting hostname canonicalization worker\n2016-07-21T00:42:33.025+0000 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/diagnostic.data'\n2016-07-21T00:42:33.031+0000 I NETWORK  [initandlisten] waiting for connections on port 27017  4. Now, shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f docker-compose.yml down  5. Finally, start the Docker container back up. In future (now that the Docker images have all been downloaded and set up), you can simply use this command to start your Docker container.  docker-compose -f docker-compose.yml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/developer/quickstart/install/#test-it-out", 
            "text": "To make sure it s working, try to hit the front-end URL in your browser. This is the URL you specified as  FRONTEND_HOST  in the  env.conf  setup above; in this case,  https://192.168.99.100 .", 
            "title": "Test it out"
        }, 
        {
            "location": "/developer/quickstart/install/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/developer/quickstart/install/#viewing-running-docker-containers", 
            "text": "To see all of the Docker containers currently running, use the command  docker ps  (you can read more about this command and its options at the  Docker website ).  docker ps  You should have all of the following containers running:   nginx:stable-alpine  coralproject/cay  coralproject/elkhorn  coralproject/pillar  coralproject/atoll  coralproject/xenia  coralproject/sponge  rabbitmq:management  coralproject/mongodata", 
            "title": "Viewing running Docker containers"
        }, 
        {
            "location": "/developer/quickstart/install/#viewing-installed-docker-images", 
            "text": "To see all of the Docker images you have installed, use the command  docker images  (you can read more about this command and its options at the  Docker website ).  docker images", 
            "title": "Viewing installed Docker images"
        }, 
        {
            "location": "/developer/quickstart/install/#viewing-docker-logs", 
            "text": "To view Docker logs for a container, use the command  docker logs  container id  (you can read more about this command and its options at the  Docker website ).  First you have to find the container id:  docker ps  Then use the container id to view the logs:  docker logs e0bbd7be19c7", 
            "title": "Viewing Docker logs"
        }, 
        {
            "location": "/developer/quickstart/install/#removing-docker-images", 
            "text": "There are a few reasons you might want to remove Docker images. You may wish to ensure that you are getting the latest build of the image. Or maybe something has gone awry with one or more of the images, and you just want to perform a fresh install of all images.  To remove all Docker images, use this command:  docker rmi $(docker images -q)", 
            "title": "Removing Docker images"
        }, 
        {
            "location": "/developer/quickstart/install/#removing-old-docker-machines", 
            "text": "Another option for a  fresh install  is to remove old Docker machines. You could try this in combination with  removing Docker images  and then reinstalling Ask to see if that fixes your issue.  docker rm -f $(docker ps -a -q)", 
            "title": "Removing old Docker machines"
        }, 
        {
            "location": "/developer/developer_setup/", 
            "text": "Developer tools setup\n\n\nIn order to install and work on Coral, there are a number of tools and software components you\nll need to install first. You may not need everything on this page, but we\nve collected all of the setup information here in one place for convenience.\n\n\nGit\n\n\nIf you don\nt already have Git installed, you\nll want to get that set up first. You\nll have to \ndownload and install Git\n. You can read more about Git on \ntheir website\n.\n\n\nYou will also have to \ncreate a GitHub account\n, which is a very straightforward process.\n\n\nAfter installing Git, the first thing you should do is setup your name and email using the following commands:\n\n\ngit config --global user.name \nYour Real Name\n\ngit config --global user.email \nyou@email.com\n\n\n\n\n\nNote that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.\n\n\nGo\n\n\nYou will need to have Go installed if you want to work on and/or install Coral components written in Go (these include Pillar, Sponge, and Xenia).\n\n\nYou can \ndownload and install Go from their website\n. The \ninstallation and setup instructions\n on the Go website are quite good.\n\n\nEnsure that you have exported your $GOPATH environment variable, as detailed in the \ninstallation instructions\n.\n\n\nIf you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.\n\n\nexport GO15VENDOREXPERIMENT=1\n\n\n\n\nIf you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.\n\n\nNode.js\n\n\nYou will need to have Node.js installed if you want to work on and/or install Coral components written in Node.js (these include Cay, Elkhorn, and Xenia Driver).\n\n\nYou can \ndownload and install Node.js from their website\n.\n\n\n\n\nYou must be running version 5.0.0 or higher of node. You can check your current version of node with the command \nnode --version\n\n\nWe recommend using \nnvm\n to manage your node installations.\n\n\n\n\nDocker\n\n\nIf you want to install Coral or Coral components using Docker, you will have to install Docker Toolbox.\n\n\nYou can install Docker Toolbox from the \nDocker Toolbox page\n.\n\n\nIf you do have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose version\n.\n\n\n\n\nOn the server, you can install Docker with the following command:\n\n\n\n\nsudo yum install docker\n\n\n\n\nMongoDB\n\n\nUsing sample data with MongoDB\n\n\nIf you are installing locally, you will want to have a local MongoDB running with sample data. When you install the all-in-one Docker Compose installation, this portion is taken care of for you.\n\n\nHowever, if you are running from source, for example, you will want to set up your local MongoDB and import sample data.\n\n\nAdditionally, if you ran into any problems with the automatic MongoDB setup portion of the installation, you can follow these instructions to import the data and set up your MongoDB manually.\n\n\nDownload and install MongoDB\n\n\nFirst, download and set up MongoDB. The MongoDB website offers \ninstructions on how to download and install\n.\n\n\nA nice GUI tool you can use with MongoDB is \nMongoChef\n, and it\ns quite easy to install and set up.\n\n\nDownload the sample data dump\n\n\nWe have provided a sample data dump for MongoDB, available to download here: \nMongoDB data dump\n.\n\n\nImport data\n\n\nThe simplest way to do this is from the command line. First, ensure you have MongoDB running.\n\n\nThen, take the dump.tar.gz file you downloaded, place it in a folder, and extract it. Copy the path to the coral directory within the extracted file.\n\n\nThen, run the below command (filling in your own directory path):\n\n\nmongorestore -d coral /yourpath/dump/coral/\n\n\n\n\nThis will import all the data from the data dump into your own local MongoDB. You\nre all set!", 
            "title": "Developer tools setup"
        }, 
        {
            "location": "/developer/developer_setup/#developer-tools-setup", 
            "text": "In order to install and work on Coral, there are a number of tools and software components you ll need to install first. You may not need everything on this page, but we ve collected all of the setup information here in one place for convenience.", 
            "title": "Developer tools setup"
        }, 
        {
            "location": "/developer/developer_setup/#git", 
            "text": "If you don t already have Git installed, you ll want to get that set up first. You ll have to  download and install Git . You can read more about Git on  their website .  You will also have to  create a GitHub account , which is a very straightforward process.  After installing Git, the first thing you should do is setup your name and email using the following commands:  git config --global user.name  Your Real Name \ngit config --global user.email  you@email.com   Note that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.", 
            "title": "Git"
        }, 
        {
            "location": "/developer/developer_setup/#go", 
            "text": "You will need to have Go installed if you want to work on and/or install Coral components written in Go (these include Pillar, Sponge, and Xenia).  You can  download and install Go from their website . The  installation and setup instructions  on the Go website are quite good.  Ensure that you have exported your $GOPATH environment variable, as detailed in the  installation instructions .  If you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.  export GO15VENDOREXPERIMENT=1  If you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.", 
            "title": "Go"
        }, 
        {
            "location": "/developer/developer_setup/#nodejs", 
            "text": "You will need to have Node.js installed if you want to work on and/or install Coral components written in Node.js (these include Cay, Elkhorn, and Xenia Driver).  You can  download and install Node.js from their website .   You must be running version 5.0.0 or higher of node. You can check your current version of node with the command  node --version  We recommend using  nvm  to manage your node installations.", 
            "title": "Node.js"
        }, 
        {
            "location": "/developer/developer_setup/#docker", 
            "text": "If you want to install Coral or Coral components using Docker, you will have to install Docker Toolbox.  You can install Docker Toolbox from the  Docker Toolbox page .  If you do have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose version .   On the server, you can install Docker with the following command:   sudo yum install docker", 
            "title": "Docker"
        }, 
        {
            "location": "/developer/developer_setup/#mongodb", 
            "text": "", 
            "title": "MongoDB"
        }, 
        {
            "location": "/developer/developer_setup/#using-sample-data-with-mongodb", 
            "text": "If you are installing locally, you will want to have a local MongoDB running with sample data. When you install the all-in-one Docker Compose installation, this portion is taken care of for you.  However, if you are running from source, for example, you will want to set up your local MongoDB and import sample data.  Additionally, if you ran into any problems with the automatic MongoDB setup portion of the installation, you can follow these instructions to import the data and set up your MongoDB manually.", 
            "title": "Using sample data with MongoDB"
        }, 
        {
            "location": "/developer/developer_setup/#download-and-install-mongodb", 
            "text": "First, download and set up MongoDB. The MongoDB website offers  instructions on how to download and install .  A nice GUI tool you can use with MongoDB is  MongoChef , and it s quite easy to install and set up.", 
            "title": "Download and install MongoDB"
        }, 
        {
            "location": "/developer/developer_setup/#download-the-sample-data-dump", 
            "text": "We have provided a sample data dump for MongoDB, available to download here:  MongoDB data dump .", 
            "title": "Download the sample data dump"
        }, 
        {
            "location": "/developer/developer_setup/#import-data", 
            "text": "The simplest way to do this is from the command line. First, ensure you have MongoDB running.  Then, take the dump.tar.gz file you downloaded, place it in a folder, and extract it. Copy the path to the coral directory within the extracted file.  Then, run the below command (filling in your own directory path):  mongorestore -d coral /yourpath/dump/coral/  This will import all the data from the data dump into your own local MongoDB. You re all set!", 
            "title": "Import data"
        }, 
        {
            "location": "/developer/cay/", 
            "text": "Introduction\n\n\nCay\n is the front-end application for Coral.\n\n\nIt\ns made up of a series of \nReact\n components, compiled into modules with \nwebpack\n.\n\n\nThe webpack build process results in a \nbundle.js\n file, which contains all Javascript and CSS for Cay. Common issues like CSS cross-browser issues, ES6 transpilation, and minification are all handled by webpack. \nbundle.js\n lives in-memory until build time (\nnpm run build\n).\n\n\nSource code folder structure\n\n\n.\n+-- .github\n+-- assets               -\n nginx config\n+-- css\n+-- dist                 -\n built files\n+-- fonts\n+-- lang\n+-- public               -\n images and config\n   config.json           -\n environment variables and such\n   data_config.json      -\n filters and dimension defs\n+-- src\n|  +-- app               -\n top-level route views connected to Redux\n|    +-- layout\n|    AppActions.js\n|    AppReducer.js\n|    MainReducer.js\n     ... other page-level (stateful) components\n|  +-- auth\n|  +-- comments          -\n any UI and redux for Comments\n|  +-- components        -\n re-usable generic UI components\n|  +-- explorer          -\n data visualization explorer domain\n|  +-- filters           -\n any UI and redux for Filters\n|  +-- search            -\n any UI and redux for Searches\n|  +-- i18n              -\n internationalization wrappers\n|  +-- tags              -\n any UI and redux for Tags\n|  +-- users             -\n any UI and redux for Users\nindex.js                 -\n entry point for app\nsettings.js              -\n colors for the app\nstore.js                 -\n redux store\n\n+-- test                 -\n mirrors the src folder\n\n\n\n\nThe meat of the application lives in the \n/src\n folder. Components are grouped into subdirectories based on their \ndomain\n: for instance, everything that has to do with creating, viewing and editing searches lives in the \nsearch\n folder. Similarly, everything having to do with tags lives in the \ntags\n folder.\n\n\nThe reducers are combined in \n/src/app/MainReducer.js\n.\n\n\nCay installation\n\n\nInstalling from source\n\n\nBefore you begin\n\n\nBefore you begin, be sure you have the following installed and running:\n\n\n\n\nXenia\n\n\nPillar\n\n\n\n\nIn addition, you must have Node.js installed:\n\n\n\n\nNode.js\n\n\nYou must be running version 5.0.0 or higher of node. You can check your current version of node with the command \nnode --version\n\n\nWe recommend using \nnvm\n to manage your node installations.\n\n\n\n\n\n\n\n\nGet the source\n\n\nClone the Cay repository onto your machine:\n\n\ngit clone https://github.com/coralproject/cay.git\n\n\n\n\ncd into the Cay directory:\n\n\ncd cay\n\n\n\n\nAnd perform an \nnpm install\n:\n\n\nnpm install\n\n\n\n\nSet up configuration file\n\n\nThe folder called \npublic\n has a sample configuration file, called \nconfig.sample.json\n. Copy this file to a new file called \nconfig.json\n, that you will edit:\n\n\ncp public/config.sample.json public/config.json\n\n\n\n\nNow, edit the config.json file.\n\n\n{\n  \nxeniaHost\n: \n,\n  \npillarHost\n: \n,\n  \nelkhornHost\n: \n,\n  \nelkhornStaticHost\n: \n,\n  \nenvironment\n: \ndevelopment\n,\n  \nbrand\n: \n,\n  \ngoogleAnalyticsId\n: \nUA-12345678-9\n,\n  \nrequireLogin\n: false,\n  \nbasicAuthorization\n: \n,\n  \nfeatures\n: {\n    \ntrust\n: true,\n    \nask\n: true\n  }\n}\n\n\n\n\nRequired edits:\n\n\n\n\nxeniaHost\n: The URL where Xenia is running.\n\n\nIf you installed Xenia \nlocally from source\n, \nxeniaHost\n should be \nhttp://localhost:4000/1.0/exec/\n.\n\n\n\n\n\n\npillarHost\n: The URL where Pillar is running.\n\n\nIf you installed Pillar \nlocally from source\n, \npillarHost\n should be \nhttp://localhost:8080\n.\n\n\nIf you installed Pillar \nlocally as a Docker container\n, \npillarHost\n should be \nhttp://10.0.4.105:8080\n. \nhttp://10.0.4.105\n is the URL generated by Docker.\n\n\n\n\n\n\nelkhornHost\n: The URL where Elkhorn is running.\n\n\nIf you installed \nlocally from source\n, \nelkhornHost\n should be \nhttp://localhost:4444\n.\n\n\n\n\n\n\nfeatures\n: The fields in features allow to toggle the features for the different products on and off.\n\n\ntrust\n: When set to \ntrue\n, this will show Trust functionality (such as \nCreate a Search.\n) When set to \nfalse\n, it will hide Trust functionality. If this is not set, it will default to \ntrue\n.\n\n\nask\n: When set to \ntrue\n, this will show Ask functionality (such as \nCreate Form.\n) When set to \nfalse\n, it will hide Ask functionality.\n\n\n\n\n\n\n\n\nOptional edits:\n\n\n\n\nenvironment\n:\n\n\nbrand\n:\n\n\ngoogleAnalyticsId\n:\n\n\nrequireLogin\n:\n\n\nbasicAuthorization\n:\n\n\n\n\nRun the app\n\n\nYou can now start Cay by running npm start:\n\n\nnpm start\n\n\n\n\nYou can now visit Cay by visiting the URL \nhttp://localhost:3000\n.", 
            "title": "Cay"
        }, 
        {
            "location": "/developer/cay/#introduction", 
            "text": "Cay  is the front-end application for Coral.  It s made up of a series of  React  components, compiled into modules with  webpack .  The webpack build process results in a  bundle.js  file, which contains all Javascript and CSS for Cay. Common issues like CSS cross-browser issues, ES6 transpilation, and minification are all handled by webpack.  bundle.js  lives in-memory until build time ( npm run build ).", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/cay/#source-code-folder-structure", 
            "text": ".\n+-- .github\n+-- assets               -  nginx config\n+-- css\n+-- dist                 -  built files\n+-- fonts\n+-- lang\n+-- public               -  images and config\n   config.json           -  environment variables and such\n   data_config.json      -  filters and dimension defs\n+-- src\n|  +-- app               -  top-level route views connected to Redux\n|    +-- layout\n|    AppActions.js\n|    AppReducer.js\n|    MainReducer.js\n     ... other page-level (stateful) components\n|  +-- auth\n|  +-- comments          -  any UI and redux for Comments\n|  +-- components        -  re-usable generic UI components\n|  +-- explorer          -  data visualization explorer domain\n|  +-- filters           -  any UI and redux for Filters\n|  +-- search            -  any UI and redux for Searches\n|  +-- i18n              -  internationalization wrappers\n|  +-- tags              -  any UI and redux for Tags\n|  +-- users             -  any UI and redux for Users\nindex.js                 -  entry point for app\nsettings.js              -  colors for the app\nstore.js                 -  redux store\n\n+-- test                 -  mirrors the src folder  The meat of the application lives in the  /src  folder. Components are grouped into subdirectories based on their  domain : for instance, everything that has to do with creating, viewing and editing searches lives in the  search  folder. Similarly, everything having to do with tags lives in the  tags  folder.  The reducers are combined in  /src/app/MainReducer.js .", 
            "title": "Source code folder structure"
        }, 
        {
            "location": "/developer/cay/#cay-installation", 
            "text": "", 
            "title": "Cay installation"
        }, 
        {
            "location": "/developer/cay/#installing-from-source", 
            "text": "", 
            "title": "Installing from source"
        }, 
        {
            "location": "/developer/cay/#before-you-begin", 
            "text": "Before you begin, be sure you have the following installed and running:   Xenia  Pillar   In addition, you must have Node.js installed:   Node.js  You must be running version 5.0.0 or higher of node. You can check your current version of node with the command  node --version  We recommend using  nvm  to manage your node installations.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/developer/cay/#get-the-source", 
            "text": "Clone the Cay repository onto your machine:  git clone https://github.com/coralproject/cay.git  cd into the Cay directory:  cd cay  And perform an  npm install :  npm install", 
            "title": "Get the source"
        }, 
        {
            "location": "/developer/cay/#set-up-configuration-file", 
            "text": "The folder called  public  has a sample configuration file, called  config.sample.json . Copy this file to a new file called  config.json , that you will edit:  cp public/config.sample.json public/config.json  Now, edit the config.json file.  {\n   xeniaHost :  ,\n   pillarHost :  ,\n   elkhornHost :  ,\n   elkhornStaticHost :  ,\n   environment :  development ,\n   brand :  ,\n   googleAnalyticsId :  UA-12345678-9 ,\n   requireLogin : false,\n   basicAuthorization :  ,\n   features : {\n     trust : true,\n     ask : true\n  }\n}  Required edits:   xeniaHost : The URL where Xenia is running.  If you installed Xenia  locally from source ,  xeniaHost  should be  http://localhost:4000/1.0/exec/ .    pillarHost : The URL where Pillar is running.  If you installed Pillar  locally from source ,  pillarHost  should be  http://localhost:8080 .  If you installed Pillar  locally as a Docker container ,  pillarHost  should be  http://10.0.4.105:8080 .  http://10.0.4.105  is the URL generated by Docker.    elkhornHost : The URL where Elkhorn is running.  If you installed  locally from source ,  elkhornHost  should be  http://localhost:4444 .    features : The fields in features allow to toggle the features for the different products on and off.  trust : When set to  true , this will show Trust functionality (such as  Create a Search. ) When set to  false , it will hide Trust functionality. If this is not set, it will default to  true .  ask : When set to  true , this will show Ask functionality (such as  Create Form. ) When set to  false , it will hide Ask functionality.     Optional edits:   environment :  brand :  googleAnalyticsId :  requireLogin :  basicAuthorization :", 
            "title": "Set up configuration file"
        }, 
        {
            "location": "/developer/cay/#run-the-app", 
            "text": "You can now start Cay by running npm start:  npm start  You can now visit Cay by visiting the URL  http://localhost:3000 .", 
            "title": "Run the app"
        }, 
        {
            "location": "/developer/elkhorn/", 
            "text": "Introduction\n\n\nElkhorn\n is the form composer and embeddable builder.\n\n\nElkhorn lets you create forms to solicit feedback from readers. You can then take the resulting forms and embed them in your website. The resulting data you collect is viewable in the \nAsk\n interface.\n\n\nElkhorn consists of the AskComposer and the Embed Service, which acts as an API.\n\n\nComposition\n\n\n\n\nAsk Composer\n\n\nAsk Composer is a JavaScript class that takes a spec in JSON format and turns it into a reader-facing form.\n\n\n\n\nAsk Composer doesn\nt know where the JSON originates from. In our case, in will come from the Ask interface in Cay (passed via the Embed Service), but in theory it could come from anywhere.\n\n\nAsk Composer stores the state of the form (completed fields, current progress, etc.).\n\n\nAsk Composer persists or saves the state of the form by sending the form to a data storage destination (this could be S3 if you set that up during the \ninstallation process\n, or on your local file system if you didn\nt set up S3).\n\n\nPartial states may be stored locally, even if S3 has been set up.\n\n\n\n\nEmbed Service\n\n\nThe Embed Service is a REST-style API.\n\n\n\n\nThe Embed Service talks to Cay, to receive the form spec in JSON format and pass that on to Ask Composer, and to pass the fully rendered form from Ask Composer to Cay.\n\n\nThe Embed Service generates a bundle (using the \nrollup\n module bundler) with all the required JavaScript to build and run the form, and sends this to the external storage system (S3 or local file system, depending on your installation set up).\n\n\nThe Embed Service receives the form submission data from the embedded forms on the partner sites, and passes this data on to Pillar.\n\n\n\n\nUsing the generated forms\n\n\nYou can read more information about generating forms on the \nAsk\n user page.\n\n\nAs a standalone page\n\n\nThe form can be viewed on a full standalone page, using the following URL:\n\n\nhttps://[elkhornserver]/iframe/[form_id]\n\n\n\n\nEmbedded as an iframe\n\n\nYou can take the standalone page link and use it in an iframe, which you can then embed directly into your page:\n\n\niframe src=\nhttps://[elkhornserver]/iframe/[form_id]\n width=\n100%\n height=\n600px\n/iframe\n\n\n\n\n\n\n\nYou may have to tweak the width and height parameters.\n\n\n\n\nEmbedded directly into your page\n\n\nYou can render a form directly into a page, using a \nscript src\n tag. This offers the advantages of native CSS inheritance (as iframes won\nt inherit any CSS from the parent page).\n\n\ndiv id=\nask-form\n/div\nscript src=\n[filewritelocation]/[formid].js\n/script\n\n\n\n\n\n\n\nThe div does need to be named \nask-form\n: the name is hardcoded.\n\n\n\n\nElkhorn installation\n\n\nInstall from source\n\n\nBefore you begin\n\n\nBefore you begin, be sure you have the following installed and running:\n\n\n\n\nPillar\n\n\n\n\nIn addition, you must have Node.js installed:\n\n\n\n\nNode.js\n\n\nYou must be running version 5.0.0 or higher of node. You can check your current version of node with the command \nnode --version\n\n\nWe recommend using \nnvm\n to manage your node installations.\n\n\n\n\n\n\n\n\nSet up your external storage system (optional)\n\n\nElkhorn uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.\n\n\nThere are currently a couple of different options available for the external storage system you can use.\n\n\n\n\nAmazon S3\n: Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.\n\n\nLocal file system\n: If you don\nt set up an external storage system in the \nset environment variables\n step, Elkhorn will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Elkhorn for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.\n\n\n\n\nAmazon S3\n\n\nAmazon S3\n is a good option for your external storage system because it is fast, handles concurrency, and will scale well.\n\n\nThe setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon\ns instructions \nhere\n.\n\n\n\n\nFollow the directions for \nSign Up for Amazon S3\n and \nCreate a Bucket\n. There is no need to continue further to the demos for \nAdd an Object to a Bucket\n and beyond: those are simply examples showing you how to use S3.\n\n\n\n\n\n\nFor my example, I named my bucket \nask-bucket-test\n and chose region \nNorthern California\n (which corresponds to us-west-2).\n\n\nDuring the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).\n\n\n\n\n\n\n\n\nOnce you have signed up and set up a bucket, go to your \nS3 console\n to set up your permissions under \nSecurity Credentials.\n\n\n\n\n\n\nEnsure that under \nPermissions,\n the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).\n\n\n\n\n\n\nYou\nre all set! You can now use your AWS Access Key to connect Elkhorn to your S3 bucket (you\nll set this up in the \nSet up configuration file\n section below). If you didn\nt save your AWS Access Key during the set up process, you can go to the \nSecurity Credentials\n section and create a new one.\n\n\nClone the Elkhorn repository\n\n\nClone the Elkhorn repository:\n\n\ngit clone https://github.com/coralproject/elkhorn.git\n\n\n\n\nThen cd into the Elkhorn directory:\n\n\ncd elkhorn\n\n\n\n\nAnd perform an \nnpm install\n:\n\n\nnpm install\n\n\n\n\nSet up configuration file\n\n\nThe Elkhorn directory has a configuration file, called \nconfig.sample.json\n. Copy this file to a new file called \nconfig.json\n, that you will edit:\n\n\ncp config.sample.json config.json\n\n\n\n\nNow edit the config.json file.\n\n\n{\n  \npillarHost\n: \n,\n  \nbasicAuthorization\n: \nBasic 123123123123213\n,\n  \ns3\n: {\n    \nbucket\n: \n,\n    \nregion\n: \n,\n    \naccessKeyId\n: \n,\n    \nsecretAccessKey\n: \n\n  }\n}\n\n\n\n\nRequired edits:\n\n\n\n\npillarHost\n: The URL where Pillar is running.\n\n\nIf you installed Pillar \nlocally from source\n, \npillarHost\n should be \nhttp://localhost:8080\n.\n\n\nIf you installed Pillar \nlocally as a Docker container\n, \npillarHost\n should be \nhttp://10.0.4.105:8080\n. \nhttp://10.0.4.105\n is the URL generated by Docker.\n\n\n\n\n\n\ns3\n: If you \nset up Amazon S3\n above, here is where you will enter that information. If you leave these fields blank, Elkhorn will default to using your local file system for external storage.\n\n\nbucket\n: The name of your S3 bucket (in the example setup above, \nask-bucket-test\n)\n\n\nregion\n: The AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In the example setup above, it is \nus-west-2\n.\n\n\naccessKeyId\n: Your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\nsecretAccessKey\n: Your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the \nSecurity Credentials\n area of your S3 console.\n\n\n\n\n\n\n\n\nOptional edits:\n* \nbasicAuthorization\n:\n\n\nRun the app\n\n\nYou can now start Elkhorn by running npm start:\n\n\nnpm start\n\n\n\n\nElkhorn will now be running locally on port 4444. You can now visit Elkhorn by visiting the URL \nhttp://localhost:4444\n.\n\n\nInstall as a Docker container\n\n\nInstall Docker Toolbox\n\n\nIf you do not already have Docker installed, do that first. You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you do have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose version\n.\n\n\nClone the Elkhorn repository\n\n\nClone the Elkhorn repository:\n\n\ngit clone https://github.com/coralproject/elkhorn.git\n\n\n\n\nThen cd into the Elkhorn directory:\n\n\ncd elkhorn\n\n\n\n\nBuild and run Elkhorn\n\n\nBuild Elkhorn:\n\n\ndocker build -t elkhorn .\n\n\n\n\nRun Elkhorn:\n\n\ndocker run  --name elkhorn -d -p 4444:4444 elkhorn\n\n\n\n\nElkhorn will now be running locally on port 4444. You can now visit Elkhorn by visiting the URL \nhttp://localhost:4444\n.\n\n\nEmbed Service API\n\n\nThe Embed Service is a REST-style API.\n\n\nEndpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/create\n\n\nPOST\n\n\nCreate a form\n\n\n\n\n\n\n/preview.js\n\n\nGET\n\n\nPreview form\n\n\n\n\n\n\n/iframe\n\n\nGET\n\n\nGet iframe form\n\n\n\n\n\n\n\n\nCreate\n\n\n\n\nCay sends a form specification in JSON format to Elkhorn.\n\n\nElkhorn creates the form and sends it to Pillar.\n\n\nElkhorn returns the ID to Cay.\n\n\nCay has now the form ID.\n\n\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/create\n\n\nPOST\n\n\nCreate a form\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nPOST\nhttps://localhost:4444/create\n\n\n\n\nExample message body\n\n\n{\n    \ntarget\n: \n#ask-form\n,\n    \ntheme\n: {\n        \nheaderBackground\n: \n#FFFFFF\n,\n        \nheaderText\n: \n#222222\n,\n        \nheaderIntroText\n: \n#444444\n,\n        \nformBackground\n: \n#FFFFFF\n,\n        \nfooterBackground\n: \n#FFFFFF\n,\n        \nrequiredAsterisk\n: \n#939393\n,\n        \ninputBackground\n: \n#FFFFFF\n,\n        \ninputText\n: \n#222222\n,\n        \nfooterText\n: \n#222222\n,\n        \nfieldTitleText\n: \n#222222\n,\n        \nprogressBar\n: \n#44AA44\n,\n        \nprogressBarBackground\n: \n#CCCCCC\n,\n        \nsubmitButtonBackground\n: \n#F67D6E\n,\n        \nsubmitButtonText\n: \n#FFFFFF\n,\n        \nselectedItemBackground\n: \n#2E343B\n,\n        \nselectedItemText\n: \n#FAFAFA\n\n    },\n    \nsettings\n: {\n        \nsaveDestination\n: \nhttp://10.0.1.195:8080/api/form_submission/\n,\n        \nshowFieldNumbers\n: true,\n        \nisActive\n: false,\n        \ninactiveMessage\n: \nWe are not currently accepting submissions. Thank you.\n\n    },\n    \nheader\n: {\n        \ntitle\n: \nA form about drinks\n,\n        \ndescription\n: \nTell us all about your favorite beverages.\n,\n        \nheading\n: \nWhat is your favorite drink?\n\n    },\n    \nfooter\n: {\n        \nconditions\n: \n\n    },\n    \nfinishedScreen\n: {\n        \ntitle\n: \nThanks.\n,\n        \ndescription\n: \nThank you for helping us with our journalism. We read all submissions, and will be in touch if we have any more questions.\n\n    },\n    \nsteps\n: [{\n        \nid\n: \nb42cb533-5506-4fb0-a9d3-2b6e740ff6b6\n,\n        \nname\n: \nfirst_step\n,\n        \ncreatedAt\n: 1471970980762,\n        \nwidgets\n: [{\n            \ntitle\n: \nA simple question\n,\n            \nfriendlyType\n: \nShort Answer\n,\n            \ntype\n: \nfield\n,\n            \ncomponent\n: \nTextField\n,\n            \nidentity\n: false,\n            \nwrapper\n: {},\n            \nprops\n: {},\n            \nid\n: \n0970a788-db9a-4595-9e44-5d3b99549a60\n\n        }, {\n            \ntitle\n: \nAnother question\n,\n            \nfriendlyType\n: \nLong Answer\n,\n            \ntype\n: \nfield\n,\n            \ncomponent\n: \nTextArea\n,\n            \nidentity\n: false,\n            \nwrapper\n: {},\n            \nprops\n: {},\n            \nid\n: \n11218a75-0cce-4869-829a-cf7d877460a0\n\n        }]\n    }],\n    \nstatus\n: \nclosed\n\n}\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nPreview.js\n\n\n\n\nCay sends a form as JSON to Elkhorn.\n\n\nElkhorn returns the rendered public-facing form preview.\n\n\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/preview.js\n\n\nGET\n\n\nPreview form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:4444/preview.js?id=1234\n\n\n\n\nExample response\n\n\n{\n  \nresults\n: [\n    {\n      \nplayerName\n: \nJang Min Chul\n,\n      \nupdatedAt\n: \n2011-08-19T02:24:17.787Z\n,\n      \ncheatMode\n: false,\n      \ncreatedAt\n: \n2011-08-19T02:24:17.787Z\n,\n      \nobjectId\n: \nA22v5zRAgd\n,\n      \nscore\n: 80075\n    },\n    {\n      \nplayerName\n: \nSean Plott\n,\n      \nupdatedAt\n: \n2011-08-21T18:02:52.248Z\n,\n      \ncheatMode\n: false,\n      \ncreatedAt\n: \n2011-08-20T02:06:57.931Z\n,\n      \nobjectId\n: \nEd1nuqPvcm\n,\n      \nscore\n: 73453\n    }\n  ]\n}\n\n\n\n\nIframe\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/iframe\n\n\nGET\n\n\nGet iframe form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:4444/iframe?id=1234\n\n\n\n\nExample response\n\n\n{\n  \nresults\n: [\n    {\n      \nplayerName\n: \nJang Min Chul\n,\n      \nupdatedAt\n: \n2011-08-19T02:24:17.787Z\n,\n      \ncheatMode\n: false,\n      \ncreatedAt\n: \n2011-08-19T02:24:17.787Z\n,\n      \nobjectId\n: \nA22v5zRAgd\n,\n      \nscore\n: 80075\n    },\n    {\n      \nplayerName\n: \nSean Plott\n,\n      \nupdatedAt\n: \n2011-08-21T18:02:52.248Z\n,\n      \ncheatMode\n: false,\n      \ncreatedAt\n: \n2011-08-20T02:06:57.931Z\n,\n      \nobjectId\n: \nEd1nuqPvcm\n,\n      \nscore\n: 73453\n    }\n  ]\n}\n\n\n\n\nContributing an answer field\n\n\nWe\nve included a variety of question field types in Elkhorn that can be used in building your forms. These include:\n\n\n\n\nShort Answer\n: Provides a single line text input area. You can set the character limits.\n\n\nLong Answer\n: Provides a paragraph text input area. You can set the character limits.\n\n\nNumbers\n: Only number characters can be entered in this field.\n\n\nMultiple Choice\n: Provides multiple choice answer options.\n\n\nEmail\n\n\nDate\n\n\nPhone number\n\n\n\n\nHowever, you may find that there is a question field we haven\nt included yet that you\nd like to have. You can create your own, and then \nadd it to our code base\n so others can use it too!\n\n\nHow to create a new question field\n\n\nIn order to create a new question field, there are two main things you must do:\n\n\n\n\nExtend the AskInterface interface\n: Your question field class will extend the \nAskField\n interface.\n\n\nExpose \nvalidate\n and \ngetValue\n methods\n: You will have to implement these methods from the \nAskField\n interface.\n\n\n\n\nA good place to start is to \ncheck out the source\n for our existing question fields.", 
            "title": "Elkhorn"
        }, 
        {
            "location": "/developer/elkhorn/#introduction", 
            "text": "Elkhorn  is the form composer and embeddable builder.  Elkhorn lets you create forms to solicit feedback from readers. You can then take the resulting forms and embed them in your website. The resulting data you collect is viewable in the  Ask  interface.  Elkhorn consists of the AskComposer and the Embed Service, which acts as an API.", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/elkhorn/#composition", 
            "text": "", 
            "title": "Composition"
        }, 
        {
            "location": "/developer/elkhorn/#ask-composer", 
            "text": "Ask Composer is a JavaScript class that takes a spec in JSON format and turns it into a reader-facing form.   Ask Composer doesn t know where the JSON originates from. In our case, in will come from the Ask interface in Cay (passed via the Embed Service), but in theory it could come from anywhere.  Ask Composer stores the state of the form (completed fields, current progress, etc.).  Ask Composer persists or saves the state of the form by sending the form to a data storage destination (this could be S3 if you set that up during the  installation process , or on your local file system if you didn t set up S3).  Partial states may be stored locally, even if S3 has been set up.", 
            "title": "Ask Composer"
        }, 
        {
            "location": "/developer/elkhorn/#embed-service", 
            "text": "The Embed Service is a REST-style API.   The Embed Service talks to Cay, to receive the form spec in JSON format and pass that on to Ask Composer, and to pass the fully rendered form from Ask Composer to Cay.  The Embed Service generates a bundle (using the  rollup  module bundler) with all the required JavaScript to build and run the form, and sends this to the external storage system (S3 or local file system, depending on your installation set up).  The Embed Service receives the form submission data from the embedded forms on the partner sites, and passes this data on to Pillar.", 
            "title": "Embed Service"
        }, 
        {
            "location": "/developer/elkhorn/#using-the-generated-forms", 
            "text": "You can read more information about generating forms on the  Ask  user page.", 
            "title": "Using the generated forms"
        }, 
        {
            "location": "/developer/elkhorn/#as-a-standalone-page", 
            "text": "The form can be viewed on a full standalone page, using the following URL:  https://[elkhornserver]/iframe/[form_id]", 
            "title": "As a standalone page"
        }, 
        {
            "location": "/developer/elkhorn/#embedded-as-an-iframe", 
            "text": "You can take the standalone page link and use it in an iframe, which you can then embed directly into your page:  iframe src= https://[elkhornserver]/iframe/[form_id]  width= 100%  height= 600px /iframe    You may have to tweak the width and height parameters.", 
            "title": "Embedded as an iframe"
        }, 
        {
            "location": "/developer/elkhorn/#embedded-directly-into-your-page", 
            "text": "You can render a form directly into a page, using a  script src  tag. This offers the advantages of native CSS inheritance (as iframes won t inherit any CSS from the parent page).  div id= ask-form /div script src= [filewritelocation]/[formid].js /script    The div does need to be named  ask-form : the name is hardcoded.", 
            "title": "Embedded directly into your page"
        }, 
        {
            "location": "/developer/elkhorn/#elkhorn-installation", 
            "text": "", 
            "title": "Elkhorn installation"
        }, 
        {
            "location": "/developer/elkhorn/#install-from-source", 
            "text": "", 
            "title": "Install from source"
        }, 
        {
            "location": "/developer/elkhorn/#before-you-begin", 
            "text": "Before you begin, be sure you have the following installed and running:   Pillar   In addition, you must have Node.js installed:   Node.js  You must be running version 5.0.0 or higher of node. You can check your current version of node with the command  node --version  We recommend using  nvm  to manage your node installations.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/developer/elkhorn/#set-up-your-external-storage-system-optional", 
            "text": "Elkhorn uses an external storage system as a cache to store pre-built bundled files of your created form. This allows the forms to be quickly served up when embedded on your page. Each bundled file runs about ~100KB, and there is one bundled file per form.  There are currently a couple of different options available for the external storage system you can use.   Amazon S3 : Amazon S3 is a storage system that is relatively easy to set up and use, and scales well: it allows many concurrent users to access the files.  Local file system : If you don t set up an external storage system in the  set environment variables  step, Elkhorn will default to using your local file system for storage. This can be a good option if you are developing locally, or just installing Elkhorn for demo purposes. If you want to scale, however, this can get unwieldy, and it will be best to set up a storage system that is fast and handles concurrency well.", 
            "title": "Set up your external storage system (optional)"
        }, 
        {
            "location": "/developer/elkhorn/#amazon-s3", 
            "text": "Amazon S3  is a good option for your external storage system because it is fast, handles concurrency, and will scale well.  The setup of S3 is straightforward, and Amazon has good documentation. For the purposes of setting S3 up for Ask, you can follow Amazon s instructions  here .   Follow the directions for  Sign Up for Amazon S3  and  Create a Bucket . There is no need to continue further to the demos for  Add an Object to a Bucket  and beyond: those are simply examples showing you how to use S3.    For my example, I named my bucket  ask-bucket-test  and chose region  Northern California  (which corresponds to us-west-2).  During the sign up process, you will create an AWS Access Key. Hang on to that information (you have the option to download it).     Once you have signed up and set up a bucket, go to your  S3 console  to set up your permissions under  Security Credentials.    Ensure that under  Permissions,  the only Grantee is you. This means that nobody but you can access your bucket (using your AWS Access Key).    You re all set! You can now use your AWS Access Key to connect Elkhorn to your S3 bucket (you ll set this up in the  Set up configuration file  section below). If you didn t save your AWS Access Key during the set up process, you can go to the  Security Credentials  section and create a new one.", 
            "title": "Amazon S3"
        }, 
        {
            "location": "/developer/elkhorn/#clone-the-elkhorn-repository", 
            "text": "Clone the Elkhorn repository:  git clone https://github.com/coralproject/elkhorn.git  Then cd into the Elkhorn directory:  cd elkhorn  And perform an  npm install :  npm install", 
            "title": "Clone the Elkhorn repository"
        }, 
        {
            "location": "/developer/elkhorn/#set-up-configuration-file", 
            "text": "The Elkhorn directory has a configuration file, called  config.sample.json . Copy this file to a new file called  config.json , that you will edit:  cp config.sample.json config.json  Now edit the config.json file.  {\n   pillarHost :  ,\n   basicAuthorization :  Basic 123123123123213 ,\n   s3 : {\n     bucket :  ,\n     region :  ,\n     accessKeyId :  ,\n     secretAccessKey :  \n  }\n}  Required edits:   pillarHost : The URL where Pillar is running.  If you installed Pillar  locally from source ,  pillarHost  should be  http://localhost:8080 .  If you installed Pillar  locally as a Docker container ,  pillarHost  should be  http://10.0.4.105:8080 .  http://10.0.4.105  is the URL generated by Docker.    s3 : If you  set up Amazon S3  above, here is where you will enter that information. If you leave these fields blank, Elkhorn will default to using your local file system for external storage.  bucket : The name of your S3 bucket (in the example setup above,  ask-bucket-test )  region : The AWS region that you selected in your S3 setup. You can find it in your S3 console URL. In the example setup above, it is  us-west-2 .  accessKeyId : Your AWS Access Key ID that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.  secretAccessKey : Your AWS Access Key that you received when you set up S3. You can also create a new key and key ID in the  Security Credentials  area of your S3 console.     Optional edits:\n*  basicAuthorization :", 
            "title": "Set up configuration file"
        }, 
        {
            "location": "/developer/elkhorn/#run-the-app", 
            "text": "You can now start Elkhorn by running npm start:  npm start  Elkhorn will now be running locally on port 4444. You can now visit Elkhorn by visiting the URL  http://localhost:4444 .", 
            "title": "Run the app"
        }, 
        {
            "location": "/developer/elkhorn/#install-as-a-docker-container", 
            "text": "", 
            "title": "Install as a Docker container"
        }, 
        {
            "location": "/developer/elkhorn/#install-docker-toolbox", 
            "text": "If you do not already have Docker installed, do that first. You can install Docker Toolbox from the  Docker Toolbox product page .  If you do have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose version .", 
            "title": "Install Docker Toolbox"
        }, 
        {
            "location": "/developer/elkhorn/#clone-the-elkhorn-repository_1", 
            "text": "Clone the Elkhorn repository:  git clone https://github.com/coralproject/elkhorn.git  Then cd into the Elkhorn directory:  cd elkhorn", 
            "title": "Clone the Elkhorn repository"
        }, 
        {
            "location": "/developer/elkhorn/#build-and-run-elkhorn", 
            "text": "Build Elkhorn:  docker build -t elkhorn .  Run Elkhorn:  docker run  --name elkhorn -d -p 4444:4444 elkhorn  Elkhorn will now be running locally on port 4444. You can now visit Elkhorn by visiting the URL  http://localhost:4444 .", 
            "title": "Build and run Elkhorn"
        }, 
        {
            "location": "/developer/elkhorn/#embed-service-api", 
            "text": "The Embed Service is a REST-style API.", 
            "title": "Embed Service API"
        }, 
        {
            "location": "/developer/elkhorn/#endpoints", 
            "text": "URL  HTTP Verb  Description      /create  POST  Create a form    /preview.js  GET  Preview form    /iframe  GET  Get iframe form", 
            "title": "Endpoints"
        }, 
        {
            "location": "/developer/elkhorn/#create", 
            "text": "Cay sends a form specification in JSON format to Elkhorn.  Elkhorn creates the form and sends it to Pillar.  Elkhorn returns the ID to Cay.  Cay has now the form ID.      URL  HTTP Verb  Functionality      /create  POST  Create a form", 
            "title": "Create"
        }, 
        {
            "location": "/developer/elkhorn/#parameters", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/elkhorn/#example-call", 
            "text": "POST\nhttps://localhost:4444/create", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/elkhorn/#example-message-body", 
            "text": "{\n     target :  #ask-form ,\n     theme : {\n         headerBackground :  #FFFFFF ,\n         headerText :  #222222 ,\n         headerIntroText :  #444444 ,\n         formBackground :  #FFFFFF ,\n         footerBackground :  #FFFFFF ,\n         requiredAsterisk :  #939393 ,\n         inputBackground :  #FFFFFF ,\n         inputText :  #222222 ,\n         footerText :  #222222 ,\n         fieldTitleText :  #222222 ,\n         progressBar :  #44AA44 ,\n         progressBarBackground :  #CCCCCC ,\n         submitButtonBackground :  #F67D6E ,\n         submitButtonText :  #FFFFFF ,\n         selectedItemBackground :  #2E343B ,\n         selectedItemText :  #FAFAFA \n    },\n     settings : {\n         saveDestination :  http://10.0.1.195:8080/api/form_submission/ ,\n         showFieldNumbers : true,\n         isActive : false,\n         inactiveMessage :  We are not currently accepting submissions. Thank you. \n    },\n     header : {\n         title :  A form about drinks ,\n         description :  Tell us all about your favorite beverages. ,\n         heading :  What is your favorite drink? \n    },\n     footer : {\n         conditions :  \n    },\n     finishedScreen : {\n         title :  Thanks. ,\n         description :  Thank you for helping us with our journalism. We read all submissions, and will be in touch if we have any more questions. \n    },\n     steps : [{\n         id :  b42cb533-5506-4fb0-a9d3-2b6e740ff6b6 ,\n         name :  first_step ,\n         createdAt : 1471970980762,\n         widgets : [{\n             title :  A simple question ,\n             friendlyType :  Short Answer ,\n             type :  field ,\n             component :  TextField ,\n             identity : false,\n             wrapper : {},\n             props : {},\n             id :  0970a788-db9a-4595-9e44-5d3b99549a60 \n        }, {\n             title :  Another question ,\n             friendlyType :  Long Answer ,\n             type :  field ,\n             component :  TextArea ,\n             identity : false,\n             wrapper : {},\n             props : {},\n             id :  11218a75-0cce-4869-829a-cf7d877460a0 \n        }]\n    }],\n     status :  closed \n}", 
            "title": "Example message body"
        }, 
        {
            "location": "/developer/elkhorn/#example-response", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/elkhorn/#previewjs", 
            "text": "Cay sends a form as JSON to Elkhorn.  Elkhorn returns the rendered public-facing form preview.      URL  HTTP Verb  Functionality      /preview.js  GET  Preview form", 
            "title": "Preview.js"
        }, 
        {
            "location": "/developer/elkhorn/#parameters_1", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/elkhorn/#example-call_1", 
            "text": "GET\nhttps://localhost:4444/preview.js?id=1234", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/elkhorn/#example-response_1", 
            "text": "{\n   results : [\n    {\n       playerName :  Jang Min Chul ,\n       updatedAt :  2011-08-19T02:24:17.787Z ,\n       cheatMode : false,\n       createdAt :  2011-08-19T02:24:17.787Z ,\n       objectId :  A22v5zRAgd ,\n       score : 80075\n    },\n    {\n       playerName :  Sean Plott ,\n       updatedAt :  2011-08-21T18:02:52.248Z ,\n       cheatMode : false,\n       createdAt :  2011-08-20T02:06:57.931Z ,\n       objectId :  Ed1nuqPvcm ,\n       score : 73453\n    }\n  ]\n}", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/elkhorn/#iframe", 
            "text": "URL  HTTP Verb  Functionality      /iframe  GET  Get iframe form", 
            "title": "Iframe"
        }, 
        {
            "location": "/developer/elkhorn/#parameters_2", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/elkhorn/#example-call_2", 
            "text": "GET\nhttps://localhost:4444/iframe?id=1234", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/elkhorn/#example-response_2", 
            "text": "{\n   results : [\n    {\n       playerName :  Jang Min Chul ,\n       updatedAt :  2011-08-19T02:24:17.787Z ,\n       cheatMode : false,\n       createdAt :  2011-08-19T02:24:17.787Z ,\n       objectId :  A22v5zRAgd ,\n       score : 80075\n    },\n    {\n       playerName :  Sean Plott ,\n       updatedAt :  2011-08-21T18:02:52.248Z ,\n       cheatMode : false,\n       createdAt :  2011-08-20T02:06:57.931Z ,\n       objectId :  Ed1nuqPvcm ,\n       score : 73453\n    }\n  ]\n}", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/elkhorn/#contributing-an-answer-field", 
            "text": "We ve included a variety of question field types in Elkhorn that can be used in building your forms. These include:   Short Answer : Provides a single line text input area. You can set the character limits.  Long Answer : Provides a paragraph text input area. You can set the character limits.  Numbers : Only number characters can be entered in this field.  Multiple Choice : Provides multiple choice answer options.  Email  Date  Phone number   However, you may find that there is a question field we haven t included yet that you d like to have. You can create your own, and then  add it to our code base  so others can use it too!", 
            "title": "Contributing an answer field"
        }, 
        {
            "location": "/developer/elkhorn/#how-to-create-a-new-question-field", 
            "text": "In order to create a new question field, there are two main things you must do:   Extend the AskInterface interface : Your question field class will extend the  AskField  interface.  Expose  validate  and  getValue  methods : You will have to implement these methods from the  AskField  interface.   A good place to start is to  check out the source  for our existing question fields.", 
            "title": "How to create a new question field"
        }, 
        {
            "location": "/developer/pillar/", 
            "text": "Introduction\n\n\nPillar\n is a REST based API written in Go. It provides the following services:\n\n\n\n\nImports external data (working with Sponge) into the Coral database.\n\n\nAllows CRUD (Create, Read, Update, Delete) operations on the Coral database.\n\n\n\n\nPillar is one of the primary services that interacts with the Coral database. The other service that interacts with the Coral database is \nXenia\n, but Xenia\ns queries are much more complex than Pillar\ns. Pillar does use Xenia to perform one specific, more complex search, but they largely serve different purposes.\n\n\nIf you\nd like to see more about how Pillar fits into the Coral Ecosystem, you can find some drawings and diagrams on the \nArchitectural Overview\n page.\n\n\nKey Points\n\n\n\n\n\n\nThe Pillar API adheres strongly to \nREST style\n.\n\n\n\n\n\n\nThe Pillar API works only with \nJSON\n data.\n\n\n\n\n\n\nThe regular \nCRUD\n endpoint URL pattern is \n/api/*\n, where as the URL pattern for import endpoints is \n/api/import/*\n.\n\n\n\n\n\n\nImport-related endpoints allow you to import data into Coral from an existing source system (i.e., an existing database of comment information).\n\n\n\n\nCoral keeps track of the original identifiers (i.e., the user id), and stores that data (using a structure called \nImportSource\n) in a field named \nSource\n. That means you won\nt lose the original identifier data from your original source when you import into Coral.\n\n\n\n\n\n\n\n\nAll import endpoints \nupsert\n data. This means that when you import an entry, it will overwrite the information for that entry if the entry already exists. This prevents duplications and other problems.\n\n\n\n\n\n\nGoDoc source code documentation\n\n\nPillar has automatically generated \nGoDoc generated documentation\n available, which you can view \nhere\n. GoDoc generates documentation from Go source code.\n\n\nPillar installation\n\n\nIf you want to install Pillar as part of an all-in-one installation of the Coral Ecosystem, you can \nfind instructions to do that here\n.\n\n\nWhen installing Pillar by itself, you can choose between installing Pillar as a Docker container, or installing from source.\n\n\n\n\nInstall Pillar from source\n\n\nInstall Pillar as a Docker container\n\n\n\n\nBefore you begin\n\n\nBefore you install Pillar, you must have the following items installed and running:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nThere are \ninstructions on importing sample comment data into MongoDB here\n\n\n\n\n\n\nRabbitMQ\n: You can find instructions on installing RabbitMQ \non the RabbitMQ website\n.\n\n\nXenia\n: Xenia is a configurable service layer that publishes endpoints against MongoDB aggregation pipeline queries. It is part of the Coral ecosystem. You can find instructions on how to install Xenia \nhere\n.\n\n\n\n\nInstall Pillar from source\n\n\nBefore you begin\n\n\nIf you want to install from source, you will need to have Go installed.\n\n\nYou can install \ninstall Go from their website\n. The \ninstallation and setup instructions\n on the Go website are quite good. Ensure that you have exported your $GOPATH environment variable, as detailed in the \ninstallation instructions\n.\n\n\nIf you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.\n\n\nexport GO15VENDOREXPERIMENT=1\n\n\n\n\nIf you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.\n\n\nGet the source code\n\n\nYou can install the source code via using the \ngo get\n command, or by manually cloning the code.\n\n\nUsing the go get command\n\n\ngo get github.com/coralproject/pillar\n\n\n\n\nIf you see a message about \nno buildable Go source files\n as shown below, you can ignore it. It simply means that there are no buildable source files in the uppermost pillar directory (though there are buildable source files in subdirectories).\n\n\npackage github.com/coralproject/pillar: no buildable Go source files in [directory]\n\n\n\n\nCloning manually\n\n\nYou can also clone the code manually (this does the same thing as the \ngo get\n command above).\n\n\nmkdir $GOPATH/src/github.com/coralproject/pillar\ncd $GOPATH/src/github.com/coralproject/pillar\n\ngit clone https://github.com/coralproject/pillar.git\n\n\n\n\nSet your environment variables\n\n\nSetting your environment variables tells Pillar the URLs and other information for communicating with MongoDB, RabbitMQ, and Xenia.\n\n\nMake your own copy of the \nconfig/dev.cfg\n file (you can edit this configuration file with your own values, and then ensure that you don\nt commit it back to the repository). Call your config file whatever you like; we\nll call it \ncustom\n in this example.\n\n\ncd $GOPATH/src/github.com/coralproject/pillar\ncp config/dev.cfg config/custom.cfg\n\n\n\n\nNow edit the values in your custom.cfg file:\n\n\n#Resources\nexport MONGODB_URL=\nmongodb://localhost:27017/coral\n\nexport AMQP_URL=\namqp://localhost:5672/\n\nexport AMQP_EXCHANGE=\nPillarMQ\n\n\n#Pillar\nexport PILLAR_ADDRESS=\n:8080\n\nexport PILLAR_HOME=\n/opt/pillar\n\nexport PILLAR_CRON=\nfalse\n\nexport PILLAR_CRON_SEARCH=\n@every 30m\n\nexport PILLAR_CRON_STATS=\n@every 1m\n\n\n#Xenia\nexport XENIA_URL=\nhttp://localhost:4000/1.0/exec/\n\nexport XENIA_QUERY_PARAM=\n?skip=0\nlimit=100\n\nexport XENIA_AUTH=\nauth token\n\n\n# Stats\nexport MONGODB_ADDRESS=\n127.0.0.1:27017\n\nexport MONGODB_USERNAME=\n\nexport MONGODB_PASSWORD=\n\nexport MONGODB_DATABASE=\n\nexport MONGODB_SSL=\nFalse\n\n\n\n\n\nRequired edits:\n\n\n\n\nXENIA_URL\n: The URL where Xenia is running.\n\n\nIf you installed Xenia \nlocally from source\n, \nXENIA_URL\n should be \nhttp://localhost:4000/1.0/exec/\n.\n\n\n\n\n\n\nMONGODB_URL\n: The URL where your MongoDB is running.\n\n\nIf your MongoDB is a local installation, \nMONGODB_URL\n should be \nmongodb://localhost:27017/coral\n.\n\n\n\n\n\n\nAMQP_URL\n: The URL where your RabbitMQ is running.\n\n\nIf your RabbitMQ is a local installation, \nAMQP_URL\n should be \namqp://localhost:5672/\n.\n\n\n\n\n\n\n\n\nOnce you\nve edited and saved your custom.cfg file, source it with the following command:\n\n\nsource $GOPATH/src/github.com/coralproject/pillar/config/custom.cfg\n\n\n\n\nRun Pillar\n\n\n$GOPATH/bin/pillar\n\n\n\n\nYou should see:\n\n\n[negroni] listening on :8080\n\n\n\n\nInstall as Docker Container\n\n\nInstall Docker Toolbox\n\n\nIf you do not already have Docker installed, do that first. You can install Docker Toolbox from the \nDocker Toolbox product page\n.\n\n\nIf you do have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker-compose version\n.\n\n\n\n\nOn the server, you can install Docker with the following command:\n\n\n\n\nsudo yum install docker\n\n\n\n\nClone the Pillar repository\n\n\nClone the Pillar repository:\n\n\ngit clone https://github.com/coralproject/pillar.git\n\n\n\n\nThen cd into the Pillar directory.\n\n\ncd pillar\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type \ndocker quickstart\n into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\n\n\n\n\n\n\nBuild Pillar server\n\n\nBuild the Pillar server using \ndocker build\n.\n\n\ndocker build -t pillar-server:0.1 .\n\n\n\n\n\n\nIf you are building on the server, you may have to use \nsudo\n:\n\n\n\n\nsudo docker build -t pillar-server:0.1 .\n\n\n\n\nEdit environment variables\n\n\nThe env.list file contains environment variables you need to set. Edit this file to reflect the settings on your own system.\n\n\nMONGODB_URL=\nmongodb://localhost:27017/coral\n\nAMQP_URL=\namqp://localhost:5672/\n\nAMQP_EXCHANGE=\nPillarMQ\n\n\nPILLAR_ADDRESS=\n:8080\n\nPILLAR_HOME=\n/opt/pillar\n\nPILLAR_CRON=\nfalse\n\nPILLAR_CRON_SEARCH=\n@every 30m\n\nPILLAR_CRON_STATS=\n@every 1m\n\n\nXENIA_URL=\nhttp://localhost:4000/1.0/exec/\n\nXENIA_QUERY_PARAM=\n?skip=0\nlimit=100\n\nXENIA_AUTH=\nauth token\n\n\nMONGODB_ADDRESS=\n127.0.0.1:27017\n\nMONGODB_USERNAME=\n\nMONGODB_PASSWORD=\n\nMONGODB_DATABASE=\n\nMONGODB_SSL=\nFalse\n\n\n\n\n\nRequired edits:\n\n\n\n\nXENIA_URL\n: The URL where Xenia is running.\n\n\nIf you installed Xenia \nlocally from source\n, \nXENIA_URL\n should be \nhttp://localhost:4000/1.0/exec/\n.\n\n\n\n\n\n\nMONGODB_URL\n: The URL where your MongoDB is running.\n\n\nIf your MongoDB is a local installation, \nMONGODB_URL\n should be \nmongodb://localhost:27017/coral\n.\n\n\n\n\n\n\nMONGO_ADDRESS\n: The address where your MongoDB is running.\n\n\nIf your MongoDB is a local installation, \nMONGODB_ADDRESS\n should be \n127.0.0.1:27017\n.\n\n\n\n\n\n\nAMQP_URL\n: The URL where your RabbitMQ is running.\n\n\nIf your RabbitMQ is a local installation, \nAMQP_URL\n should be \namqp://localhost:5672/\n.\n\n\n\n\n\n\n\n\nRun Docker\n\n\nFirst, find the Image ID for the Pillar server:\n\n\ndocker images\n\n\n\n\n\n\nIf you are running on a server, you may have to use \nsudo\n.\n\n\n\n\nThis shows you the Image ID:\n\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\npillar-server       0.1                 24b7acf7a4b3        4 hours ago         771 MB\ngolang              1.6                 024309f28934        8 days ago          744.1 MB\n\n\n\n\nThen run the docker run command with the Image ID:\n\n\ndocker run --env-file env.list --publish 8080:8080 24b7acf7a4b3\n\n\n\n\nYou should see the following:\n\n\n[negroni] listening on :8080\n\n\n\n\nTest it out\n\n\nTo see if Pillar is working correctly, visit this url: \nhttp://10.0.4.105:8080/about\n. \nhttp://10.0.4.105\n is the URL generated by Docker for Pillar.\n\n\nIf things are running properly, you should see this text:\n\n\n{\nApp\n:\nCoral Pillar Web Service\n,\nVersion\n:\nVersion - 0.0.1\n}\n\n\n\n\nShutting Pillar down\n\n\nShutting Pillar down when running from source\n\n\nIf you installed and ran Pillar from source using the command \n$GOPATH/bin/pillar\n, you can shut it down by using the Ctrl + C command.\n\n\nShutting Pillar down when running as a Docker container\n\n\nTo shut Pillar down when running as Docker container, first find the container ID (if you are running on a server, you may have to use \nsudo\n):\n\n\ndocker ps\n\n\n\n\nFind the container ID for Pillar:\n\n\nCONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                                                                                        NAMES\nb30f4fa5f497        coralproject/pillar      \n/bin/sh -c /go/bin/p\n   3 days ago          Up 3 days           0.0.0.0:32776-\n8080/tcp                                                                      proxy_pillarapp_1\n\n\n\n\nRun \ndocker stop\n with the container ID (if you are running on a server, you may have to use \nsudo\n):\n\n\ndocker stop b30f4fa5f497\n\n\n\n\nPillar API\n\n\nThis section is under construction, and is not currently complete.\n\n\n\n\n\n\nThe Pillar API adheres strongly to \nREST style\n.\n\n\n\n\n\n\nThe Pillar API works only with \nJSON\n data.\n\n\n\n\n\n\nThe regular \nCRUD\n endpoint URL pattern is \n/api/*\n, where as the URL pattern for import endpoints is \n/api/import/*\n.\n\n\n\n\n\n\nImport-related endpoints allow you to import data into Coral from an existing source system (i.e., an existing database of comment information).\n\n\n\n\nCoral keeps track of the original identifiers (i.e., the user id), and stores that data (using a structure called \nImportSource\n) in a field named \nSource\n. That means you won\nt lose the original identifier data from your original source when you import into Coral.\n\n\n\n\n\n\n\n\nAll import endpoints \nupsert\n data. This means that when you import an entry, it will overwrite the information for that entry if the entry already exists. This prevents duplications and other problems.\n\n\n\n\n\n\nImport endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/import/action\n\n\nGET\n\n\nImport action\n\n\n\n\n\n\n/api/import/asset\n\n\nGET\n\n\nImport asset\n\n\n\n\n\n\n/api/import/comment\n\n\nGET\n\n\nImport comment\n\n\n\n\n\n\n/api/import/note\n\n\nGET\n\n\nImport note\n\n\n\n\n\n\n/api/import/user\n\n\nGET\n\n\nImport user\n\n\n\n\n\n\n\n\nTag endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/tags\n\n\nGET\n\n\nGet tags\n\n\n\n\n\n\n/api/tag\n\n\nPOST\n\n\nCreate or update tag\n\n\n\n\n\n\n/api/tag\n\n\nDELETE\n\n\nDelete tag\n\n\n\n\n\n\n\n\nSearch endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/searches\n\n\nGET\n\n\nGet searches\n\n\n\n\n\n\n/api/search/{id}\n\n\nGET\n\n\nGet search by id\n\n\n\n\n\n\n/api/search\n\n\nPUT\n\n\nCreate or update search\n\n\n\n\n\n\n/api/search\n\n\nPOST\n\n\nCreate or update search\n\n\n\n\n\n\n/api/search/{id}\n\n\nDELETE\n\n\nDelete search by id\n\n\n\n\n\n\n\n\nManage user activities endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/cay/useraction\n\n\nPOST\n\n\nCreate or update user action\n\n\n\n\n\n\n\n\nCreate / update endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/author\n\n\nPOST\n\n\nCreate or update author\n\n\n\n\n\n\n/api/asset\n\n\nPOST\n\n\nCreate or update asset\n\n\n\n\n\n\n/api/comment\n\n\nPOST\n\n\nCreate or update comment\n\n\n\n\n\n\n/api/index\n\n\nPOST\n\n\nCreate index\n\n\n\n\n\n\n/api/metadata\n\n\nPOST\n\n\nUpdate metadata\n\n\n\n\n\n\n/api/section\n\n\nPOST\n\n\nCreate or update section\n\n\n\n\n\n\n/api/user\n\n\nPOST\n\n\nCreate or update user\n\n\n\n\n\n\n\n\nForm endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/form\n\n\nPOST\n\n\nCreate or update form\n\n\n\n\n\n\n/api/form\n\n\nPUT\n\n\nCreate or update form\n\n\n\n\n\n\n/api/form/{id}/status/{status}\n\n\nPOST\n\n\nUpdate form status\n\n\n\n\n\n\n/api/forms\n\n\nGET\n\n\nGet forms\n\n\n\n\n\n\n/api/form/{id}\n\n\nGET\n\n\nGet form by id\n\n\n\n\n\n\n/api/form/{id}\n\n\nDELETE\n\n\nDelete form\n\n\n\n\n\n\n\n\nForm submission endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{form_id}\n\n\nPOST\n\n\nCreate form submission\n\n\n\n\n\n\n/api/form_submission/{id}/status/{status}\n\n\nPUT\n\n\nUpdate form submission status\n\n\n\n\n\n\n/api/form_submissions/{form_id}\n\n\nGET\n\n\nGet form submissions by form\n\n\n\n\n\n\n/api/form_submission/{id}\n\n\nGET\n\n\nGet form submission\n\n\n\n\n\n\n/api/form_submission/{id}/{answer_id}\n\n\nPUT\n\n\nEdit form submission answer\n\n\n\n\n\n\n/api/form_submission/{id}/flag/{flag}\n\n\nPUT\n\n\nAdd flag to form submission\n\n\n\n\n\n\n/api/form_submission/{id}/flag/{flag}\n\n\nDELETE\n\n\nDelete flag from form submission\n\n\n\n\n\n\n/api/form_submission/{id}\n\n\nDELETE\n\n\nDelete form submission\n\n\n\n\n\n\n/api/form_submission/search\n\n\nPOST\n\n\nSearch a string on the answers of the form submissions\n\n\n\n\n\n\n\n\nForm galleries endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/form_gallery/{id}\n\n\nGET\n\n\nGet form gallery\n\n\n\n\n\n\n/api/form_galleries/{form_id}\n\n\nGET\n\n\nGet form galleries by form\n\n\n\n\n\n\n/api/form_galleries/form/{form_id}\n\n\nGET\n\n\nGet form galleries by form (version 2)\n\n\n\n\n\n\n/api/form_gallery/{id}/add/{submission_id}/{answer_id}\n\n\nPUT\n\n\nAdd answer to form gallery\n\n\n\n\n\n\n/api/form_gallery/{id}/remove/{submission_id}/{answer_id}\n\n\nDELETE\n\n\nRemove answer from form gallery\n\n\n\n\n\n\n\n\nImport action\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/action\n\n\nGET\n\n\nImport action\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/action\n\n\n\n\nExample response\n\n\n{\n  \nresults\n: [\n    {\n      \nplayerName\n: \nJang Min Chul\n,\n      \nupdatedAt\n: \n2011-08-19T02:24:17.787Z\n,\n      \ncheatMode\n: false,\n      \ncreatedAt\n: \n2011-08-19T02:24:17.787Z\n,\n      \nobjectId\n: \nA22v5zRAgd\n,\n      \nscore\n: 80075\n    },\n    {\n      \nplayerName\n: \nSean Plott\n,\n      \nupdatedAt\n: \n2011-08-21T18:02:52.248Z\n,\n      \ncheatMode\n: false,\n      \ncreatedAt\n: \n2011-08-20T02:06:57.931Z\n,\n      \nobjectId\n: \nEd1nuqPvcm\n,\n      \nscore\n: 73453\n    }\n  ]\n}\n\n\n\n\nImport asset\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/asset\n\n\nGET\n\n\nImport asset\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/asset\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nImport comment\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/comment\n\n\nGET\n\n\nImport comment\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/comment\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nImport note\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/note\n\n\nGET\n\n\nImport note\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/note\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nImport user\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/user\n\n\nGET\n\n\nImport user\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/user\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet tags\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/tags\n\n\nGET\n\n\nGet tags\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/tags\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nCreate or update tag\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/tag\n\n\nPOST\n\n\nCreate or update tag\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nMessage body\n\n\nbody here\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/tag\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nDelete tag\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/tag\n\n\nPOST\n\n\nCreate or update tag\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nMessage body\n\n\nbody\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/tag\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet searches\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/searches\n\n\nGET\n\n\nGet searches\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/searches\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nGet search by id\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/search/{id}\n\n\nGET\n\n\nGet search by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: search id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/search/123\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nCreate or update search (put)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/search\n\n\nPUT\n\n\nCreate or update search\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: search id\n\n\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/search\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update search (post)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/search\n\n\nPUT\n\n\nCreate or update search\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: search id\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/search\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nDelete search\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/search{id}\n\n\nDELETE\n\n\nDelete search by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: search id\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/search/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update user action\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/cay/useraction\n\n\nPOST\n\n\nCreate or update user action\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: user id\n\n\n\n\nMessage body\n\n\n.\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/cay/useraction?userid=123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update author\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/author/{id}\n\n\nPOST\n\n\nCreate or update author\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: author id\n\n\n\n\nMessage body\n\n\n.\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/author/456\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update asset\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/asset/{id}\n\n\nPOST\n\n\nCreate or update asset\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: asset id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/asset/456\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update comment\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/comment/{id}\n\n\nPOST\n\n\nCreate or update comment\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: comment id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/comment/456\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate index\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/index/{id}\n\n\nPOST\n\n\nCreate index\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: index id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/index/678\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nUpdate metadata\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/metadata/{id}\n\n\nPOST\n\n\nUpdate metadata\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: metadata id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/metadata/789\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update section\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/section/{id}\n\n\nPOST\n\n\nCreate or update section\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: section id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/section/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update user\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/user/{id}\n\n\nPOST\n\n\nCreate or update user\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: user id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/user/234\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update form (post)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}\n\n\nPOST\n\n\nCreate or update form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update form (put)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}\n\n\nPUT\n\n\nCreate or update form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: asset id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nUpdate form status\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}/status/{status}\n\n\nPOST\n\n\nUpdate form status\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nid\n: updated form status (what are the available form status options?)\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/form/123/status/complete\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet forms\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/forms\n\n\nGET\n\n\nGet all forms\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/forms\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nGet form by id\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}\n\n\nGET\n\n\nGet form by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nDelete form\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}\n\n\nDELETE\n\n\nDelete form by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{form_id}\n\n\nPOST\n\n\nCreate form submission by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nform_id\n: form id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nUpdate form submission status\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}/status/{status}\n\n\nPUT\n\n\nUpdate form submission status\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nstatus\n: updated form submission status\n\n\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/form_submission/123/status/completed\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet form submissions by form\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submissions/{form_id}\n\n\nGET\n\n\nGet form submission by form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nParameters\n\n\nRequired?\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nform_id\n\n\nY\n\n\nNumber\n\n\nForm id for which we want to see the submissions\n\n\n\n\n\n\nskip\n\n\nY\n\n\nNumber\n\n\nSkip the first \nn\n submissions\n\n\n\n\n\n\nlimit\n\n\nN\n\n\nNumber\n\n\nLimit to \nn\n submission returns\n\n\n\n\n\n\norderby\n\n\nN\n\n\nasc\n or \ndsc\n\n\nOrder by ascending date (\nasc\n) or descending date (\ndsc\n)\n\n\n\n\n\n\nfilterby\n\n\nN\n\n\nRegex string (example: \n^(?!test_the_flag)\n)\n\n\nFilter by a specific flag using regular expressions. If you want to match all the submissions that do not have a specific flag, use \n^(?!test_the_flag)\n\n\n\n\n\n\nsearch\n\n\nN\n\n\nString\n\n\nString to search through submissions \nreplies.answer\n\n\n\n\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_submissions/123\n\n\n\n\nExample response\n\n\n{\n    \ncounts\n: {\n        \nsearch_by_flag\n: {\n            \ntest_the_flag\n: 1,\n            \nsomething_else\n: 1\n        },\n        \ntotal_search\n: 1,\n        \ntotal_submissions\n: 2\n    },\n    \nsubmissions\n: [\n        {\n            \nid\n: \n5751ef7310780b96f002a3af\n,\n            \nform_id\n: \n5751ef7310780b96f002a3ad\n,\n            \nstatus\n: \n,\n            \nreplies\n: [\n                {\n                    \nwidget_id\n: \n1\n,\n                    \nidentity\n: false,\n                    \nanswer\n: \nGophers everywhere\n,\n                    \nedited\n: \nThis is an edit! Purple Monkey Dishwasher.\n,\n                    \nquestion\n: \nIs there anybody out there?\n,\n                    \nprops\n: {\n                        \na\n: \nB\n,\n                        \nc\n: 4\n                    }\n                },\n                {\n                    \nwidget_id\n: \n2\n,\n                    \nidentity\n: false,\n                    \nanswer\n: \nDave\n,\n                    \nedited\n: \nThis is an edit! Purple Monkey Dishwasher.\n,\n                    \nquestion\n: \nName\n,\n                    \nprops\n: {\n                        \na\n: \nB\n,\n                        \nc\n: 4\n                    }\n                },\n                {\n                    \nwidget_id\n: \n3\n,\n                    \nidentity\n: false,\n                    \nanswer\n: \nD@ve.name\n,\n                    \nedited\n: \nThis is an edit! Purple Monkey Dishwasher.\n,\n                    \nquestion\n: \nEmail\n,\n                    \nprops\n: {\n                        \na\n: \nB\n,\n                        \nc\n: 4\n                    }\n                }\n            ],\n            \nflags\n: [\n                \ntest_the_flag\n,\n                \nsomething_else\n\n            ],\n            \nheader\n: {\n                \ndescription\n: \nof the rest of your life\n,\n                \ntitle\n: \nThis is the first form\n\n            },\n            \nfooter\n: {\n                \nconditions\n: \nlots of conditions\n\n            },\n            \nfinishedScreen\n: null,\n            \ncreated_by\n: \n,\n            \nupdated_by\n: \n,\n            \ndate_created\n: \n2016-06-03T16:58:27.56-04:00\n,\n            \ndate_updated\n: \n2016-06-03T16:58:27.56-04:00\n\n        }\n    ]\n}\n\n\n\n\nwhere\n\n\n\n\nsearch_by_flag\n : brings a count on all the tags for for the specific search (without filtering by flag) for that form id\n\n\ntotal_search\n: count all the submissions for the specific search (without filtering by flag) for that form id\n\n\ntotal_submissions\n: count all the submissions for that form id\n\n\n\n\nGet form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}\n\n\nGET\n\n\nGet form submission\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_submission/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nEdit form submission answer\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}/{answer_id}\n\n\nPUT\n\n\nEdit form submission answer\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nanswer_id\n: answer id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/form_submission/123/456\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nAdd flag to form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}/flag/{flag}\n\n\nPUT\n\n\nAdd flag to form submission\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nflag\n: updated flag\n\n\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/form_submission/123/flag/g\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nDelete flag from form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}/flag/{flag}\n\n\nDELETE\n\n\nDelete flag from form submission\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nflag\n: flag to delete\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/form_submission/123/flag/g\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nDelete form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}\n\n\nDELETE\n\n\nDelete form submission\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/form_submission/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nSearch form submissions\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/search\n\n\nPOST\n\n\nSearch form submissions\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nParameters\n\n\nRequired?\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nform_id\n\n\nY\n\n\nNumber\n\n\nForm id for which we want to see the submissions\n\n\n\n\n\n\nskip\n\n\nY\n\n\nNumber\n\n\nSkip the first \nn\n submissions\n\n\n\n\n\n\nlimit\n\n\nN\n\n\nNumber\n\n\nLimit to \nn\n submission returns\n\n\n\n\n\n\norderby\n\n\nN\n\n\nasc\n or \ndsc\n\n\nOrder by ascending date (\nasc\n) or descending date (\ndsc\n)\n\n\n\n\n\n\nfilterby\n\n\nN\n\n\nRegex string (example: \n^(?!test_the_flag)\n)\n\n\nFilter by a specific flag using regular expressions. If you want to match all the submissions that do not have a specific flag, use \n^(?!test_the_flag)\n\n\n\n\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/form_submission/search\n\n\n\n\n{\n  \nsearch\n: \nGophers\n\n}\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nBody: [\n  {\n    \nid\n: \n577c197810780b3401e7a3af\n,\n    \nform_id\n: \n577c18f4a969c805f7f8c889\n,\n    \nstatus\n: \n,\n    \nreplies\n: [\n      {\n        \nwidget_id\n: \n1\n,\n        \nidentity\n: false,\n        \nanswer\n: \nGophers everywhere\n,\n        \nedited\n: null,\n        \nquestion\n: \nIs there anybody out there?\n,\n        \nprops\n: {\n          \na\n: \nB\n,\n          \nc\n: 4\n        }\n      },\n      {\n        \nwidget_id\n: \n2\n,\n        \nidentity\n: true,\n        \nanswer\n: \nDave\n,\n        \nedited\n: null,\n        \nquestion\n: \nName\n,\n        \nprops\n: {\n          \na\n: \nB\n,\n          \nc\n: 4\n        }\n      },\n      {\n        \nwidget_id\n: \n3\n,\n        \nidentity\n: true,\n        \nanswer\n: \nD@ve.name\n,\n        \nedited\n: null,\n        \nquestion\n: \nEmail\n,\n        \nprops\n: {\n          \na\n: \nB\n,\n          \nc\n: 4\n        }\n      }\n    ],\n    \nflags\n: [],\n    \nheader\n: {\n      \ndescription\n: \nof the rest of your life\n,\n      \ntitle\n: \nThis is the first form\n\n    },\n    \nfooter\n: {\n      \nconditions\n: \nlots of conditions\n\n    },\n    \nfinishedScreen\n: null,\n    \ncreated_by\n: null,\n    \nupdated_by\n: null,\n    \ndate_created\n: \n2016-07-01T21:31:45-06:00\n,\n    \ndate_updated\n: \n2016-07-01T21:31:45-06:00\n\n  }\n]\n\n\n\n\nGet form gallery\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_gallery/{id}\n\n\nGET\n\n\nGet form gallery\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form gallery id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_gallery/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet form galleries by form\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_galleries/{form_id}\n\n\nGET\n\n\nGet form galleries by form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nform_id\n: form gallery id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_galleries/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet form galleries by form (version 2)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_galleries/form/{form_id}\n\n\nGET\n\n\nGet form galleries by form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nform_id\n: form gallery id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_galleries/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nAdd answer to form gallery\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_gallery/{id}/add/{submission_id}/{answer_id}\n\n\nPUT\n\n\nAdd answer to form gallery\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form gallery id\n\n\nsubmission_id\n: submission id\n\n\nanswer_id\n: answer id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_gallery/123/add/456/789\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nRemove answer from form gallery\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_gallery/{id}/remove/{submission_id}/{answer_id}\n\n\nDELETE\n\n\nRemove answer from form gallery\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form gallery id\n\n\nsubmission_id\n: submission id\n\n\nanswer_id\n: answer id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_gallery/123/remove/456/789\n\n\n\n\nExample response\n\n\nStatus: 200 OK", 
            "title": "Pillar"
        }, 
        {
            "location": "/developer/pillar/#introduction", 
            "text": "Pillar  is a REST based API written in Go. It provides the following services:   Imports external data (working with Sponge) into the Coral database.  Allows CRUD (Create, Read, Update, Delete) operations on the Coral database.   Pillar is one of the primary services that interacts with the Coral database. The other service that interacts with the Coral database is  Xenia , but Xenia s queries are much more complex than Pillar s. Pillar does use Xenia to perform one specific, more complex search, but they largely serve different purposes.  If you d like to see more about how Pillar fits into the Coral Ecosystem, you can find some drawings and diagrams on the  Architectural Overview  page.", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/pillar/#key-points", 
            "text": "The Pillar API adheres strongly to  REST style .    The Pillar API works only with  JSON  data.    The regular  CRUD  endpoint URL pattern is  /api/* , where as the URL pattern for import endpoints is  /api/import/* .    Import-related endpoints allow you to import data into Coral from an existing source system (i.e., an existing database of comment information).   Coral keeps track of the original identifiers (i.e., the user id), and stores that data (using a structure called  ImportSource ) in a field named  Source . That means you won t lose the original identifier data from your original source when you import into Coral.     All import endpoints  upsert  data. This means that when you import an entry, it will overwrite the information for that entry if the entry already exists. This prevents duplications and other problems.", 
            "title": "Key Points"
        }, 
        {
            "location": "/developer/pillar/#godoc-source-code-documentation", 
            "text": "Pillar has automatically generated  GoDoc generated documentation  available, which you can view  here . GoDoc generates documentation from Go source code.", 
            "title": "GoDoc source code documentation"
        }, 
        {
            "location": "/developer/pillar/#pillar-installation", 
            "text": "If you want to install Pillar as part of an all-in-one installation of the Coral Ecosystem, you can  find instructions to do that here .  When installing Pillar by itself, you can choose between installing Pillar as a Docker container, or installing from source.   Install Pillar from source  Install Pillar as a Docker container", 
            "title": "Pillar installation"
        }, 
        {
            "location": "/developer/pillar/#before-you-begin", 
            "text": "Before you install Pillar, you must have the following items installed and running:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .  There are  instructions on importing sample comment data into MongoDB here    RabbitMQ : You can find instructions on installing RabbitMQ  on the RabbitMQ website .  Xenia : Xenia is a configurable service layer that publishes endpoints against MongoDB aggregation pipeline queries. It is part of the Coral ecosystem. You can find instructions on how to install Xenia  here .", 
            "title": "Before you begin"
        }, 
        {
            "location": "/developer/pillar/#install-pillar-from-source", 
            "text": "", 
            "title": "Install Pillar from source"
        }, 
        {
            "location": "/developer/pillar/#before-you-begin_1", 
            "text": "If you want to install from source, you will need to have Go installed.  You can install  install Go from their website . The  installation and setup instructions  on the Go website are quite good. Ensure that you have exported your $GOPATH environment variable, as detailed in the  installation instructions .  If you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.  export GO15VENDOREXPERIMENT=1  If you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/developer/pillar/#get-the-source-code", 
            "text": "You can install the source code via using the  go get  command, or by manually cloning the code.", 
            "title": "Get the source code"
        }, 
        {
            "location": "/developer/pillar/#using-the-go-get-command", 
            "text": "go get github.com/coralproject/pillar  If you see a message about  no buildable Go source files  as shown below, you can ignore it. It simply means that there are no buildable source files in the uppermost pillar directory (though there are buildable source files in subdirectories).  package github.com/coralproject/pillar: no buildable Go source files in [directory]", 
            "title": "Using the go get command"
        }, 
        {
            "location": "/developer/pillar/#cloning-manually", 
            "text": "You can also clone the code manually (this does the same thing as the  go get  command above).  mkdir $GOPATH/src/github.com/coralproject/pillar\ncd $GOPATH/src/github.com/coralproject/pillar\n\ngit clone https://github.com/coralproject/pillar.git", 
            "title": "Cloning manually"
        }, 
        {
            "location": "/developer/pillar/#set-your-environment-variables", 
            "text": "Setting your environment variables tells Pillar the URLs and other information for communicating with MongoDB, RabbitMQ, and Xenia.  Make your own copy of the  config/dev.cfg  file (you can edit this configuration file with your own values, and then ensure that you don t commit it back to the repository). Call your config file whatever you like; we ll call it  custom  in this example.  cd $GOPATH/src/github.com/coralproject/pillar\ncp config/dev.cfg config/custom.cfg  Now edit the values in your custom.cfg file:  #Resources\nexport MONGODB_URL= mongodb://localhost:27017/coral \nexport AMQP_URL= amqp://localhost:5672/ \nexport AMQP_EXCHANGE= PillarMQ \n\n#Pillar\nexport PILLAR_ADDRESS= :8080 \nexport PILLAR_HOME= /opt/pillar \nexport PILLAR_CRON= false \nexport PILLAR_CRON_SEARCH= @every 30m \nexport PILLAR_CRON_STATS= @every 1m \n\n#Xenia\nexport XENIA_URL= http://localhost:4000/1.0/exec/ \nexport XENIA_QUERY_PARAM= ?skip=0 limit=100 \nexport XENIA_AUTH= auth token \n\n# Stats\nexport MONGODB_ADDRESS= 127.0.0.1:27017 \nexport MONGODB_USERNAME= \nexport MONGODB_PASSWORD= \nexport MONGODB_DATABASE= \nexport MONGODB_SSL= False   Required edits:   XENIA_URL : The URL where Xenia is running.  If you installed Xenia  locally from source ,  XENIA_URL  should be  http://localhost:4000/1.0/exec/ .    MONGODB_URL : The URL where your MongoDB is running.  If your MongoDB is a local installation,  MONGODB_URL  should be  mongodb://localhost:27017/coral .    AMQP_URL : The URL where your RabbitMQ is running.  If your RabbitMQ is a local installation,  AMQP_URL  should be  amqp://localhost:5672/ .     Once you ve edited and saved your custom.cfg file, source it with the following command:  source $GOPATH/src/github.com/coralproject/pillar/config/custom.cfg", 
            "title": "Set your environment variables"
        }, 
        {
            "location": "/developer/pillar/#run-pillar", 
            "text": "$GOPATH/bin/pillar  You should see:  [negroni] listening on :8080", 
            "title": "Run Pillar"
        }, 
        {
            "location": "/developer/pillar/#install-as-docker-container", 
            "text": "", 
            "title": "Install as Docker Container"
        }, 
        {
            "location": "/developer/pillar/#install-docker-toolbox", 
            "text": "If you do not already have Docker installed, do that first. You can install Docker Toolbox from the  Docker Toolbox product page .  If you do have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker-compose version .   On the server, you can install Docker with the following command:   sudo yum install docker", 
            "title": "Install Docker Toolbox"
        }, 
        {
            "location": "/developer/pillar/#clone-the-pillar-repository", 
            "text": "Clone the Pillar repository:  git clone https://github.com/coralproject/pillar.git  Then cd into the Pillar directory.  cd pillar", 
            "title": "Clone the Pillar repository"
        }, 
        {
            "location": "/developer/pillar/#start-docker", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type  docker quickstart  into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/developer/pillar/#build-pillar-server", 
            "text": "Build the Pillar server using  docker build .  docker build -t pillar-server:0.1 .   If you are building on the server, you may have to use  sudo :   sudo docker build -t pillar-server:0.1 .", 
            "title": "Build Pillar server"
        }, 
        {
            "location": "/developer/pillar/#edit-environment-variables", 
            "text": "The env.list file contains environment variables you need to set. Edit this file to reflect the settings on your own system.  MONGODB_URL= mongodb://localhost:27017/coral \nAMQP_URL= amqp://localhost:5672/ \nAMQP_EXCHANGE= PillarMQ \n\nPILLAR_ADDRESS= :8080 \nPILLAR_HOME= /opt/pillar \nPILLAR_CRON= false \nPILLAR_CRON_SEARCH= @every 30m \nPILLAR_CRON_STATS= @every 1m \n\nXENIA_URL= http://localhost:4000/1.0/exec/ \nXENIA_QUERY_PARAM= ?skip=0 limit=100 \nXENIA_AUTH= auth token \n\nMONGODB_ADDRESS= 127.0.0.1:27017 \nMONGODB_USERNAME= \nMONGODB_PASSWORD= \nMONGODB_DATABASE= \nMONGODB_SSL= False   Required edits:   XENIA_URL : The URL where Xenia is running.  If you installed Xenia  locally from source ,  XENIA_URL  should be  http://localhost:4000/1.0/exec/ .    MONGODB_URL : The URL where your MongoDB is running.  If your MongoDB is a local installation,  MONGODB_URL  should be  mongodb://localhost:27017/coral .    MONGO_ADDRESS : The address where your MongoDB is running.  If your MongoDB is a local installation,  MONGODB_ADDRESS  should be  127.0.0.1:27017 .    AMQP_URL : The URL where your RabbitMQ is running.  If your RabbitMQ is a local installation,  AMQP_URL  should be  amqp://localhost:5672/ .", 
            "title": "Edit environment variables"
        }, 
        {
            "location": "/developer/pillar/#run-docker", 
            "text": "First, find the Image ID for the Pillar server:  docker images   If you are running on a server, you may have to use  sudo .   This shows you the Image ID:  REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\npillar-server       0.1                 24b7acf7a4b3        4 hours ago         771 MB\ngolang              1.6                 024309f28934        8 days ago          744.1 MB  Then run the docker run command with the Image ID:  docker run --env-file env.list --publish 8080:8080 24b7acf7a4b3  You should see the following:  [negroni] listening on :8080", 
            "title": "Run Docker"
        }, 
        {
            "location": "/developer/pillar/#test-it-out", 
            "text": "To see if Pillar is working correctly, visit this url:  http://10.0.4.105:8080/about .  http://10.0.4.105  is the URL generated by Docker for Pillar.  If things are running properly, you should see this text:  { App : Coral Pillar Web Service , Version : Version - 0.0.1 }", 
            "title": "Test it out"
        }, 
        {
            "location": "/developer/pillar/#shutting-pillar-down", 
            "text": "", 
            "title": "Shutting Pillar down"
        }, 
        {
            "location": "/developer/pillar/#shutting-pillar-down-when-running-from-source", 
            "text": "If you installed and ran Pillar from source using the command  $GOPATH/bin/pillar , you can shut it down by using the Ctrl + C command.", 
            "title": "Shutting Pillar down when running from source"
        }, 
        {
            "location": "/developer/pillar/#shutting-pillar-down-when-running-as-a-docker-container", 
            "text": "To shut Pillar down when running as Docker container, first find the container ID (if you are running on a server, you may have to use  sudo ):  docker ps  Find the container ID for Pillar:  CONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                                                                                        NAMES\nb30f4fa5f497        coralproject/pillar       /bin/sh -c /go/bin/p    3 days ago          Up 3 days           0.0.0.0:32776- 8080/tcp                                                                      proxy_pillarapp_1  Run  docker stop  with the container ID (if you are running on a server, you may have to use  sudo ):  docker stop b30f4fa5f497", 
            "title": "Shutting Pillar down when running as a Docker container"
        }, 
        {
            "location": "/developer/pillar/#pillar-api", 
            "text": "This section is under construction, and is not currently complete.    The Pillar API adheres strongly to  REST style .    The Pillar API works only with  JSON  data.    The regular  CRUD  endpoint URL pattern is  /api/* , where as the URL pattern for import endpoints is  /api/import/* .    Import-related endpoints allow you to import data into Coral from an existing source system (i.e., an existing database of comment information).   Coral keeps track of the original identifiers (i.e., the user id), and stores that data (using a structure called  ImportSource ) in a field named  Source . That means you won t lose the original identifier data from your original source when you import into Coral.     All import endpoints  upsert  data. This means that when you import an entry, it will overwrite the information for that entry if the entry already exists. This prevents duplications and other problems.", 
            "title": "Pillar API"
        }, 
        {
            "location": "/developer/pillar/#import-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/import/action  GET  Import action    /api/import/asset  GET  Import asset    /api/import/comment  GET  Import comment    /api/import/note  GET  Import note    /api/import/user  GET  Import user", 
            "title": "Import endpoints"
        }, 
        {
            "location": "/developer/pillar/#tag-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/tags  GET  Get tags    /api/tag  POST  Create or update tag    /api/tag  DELETE  Delete tag", 
            "title": "Tag endpoints"
        }, 
        {
            "location": "/developer/pillar/#search-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/searches  GET  Get searches    /api/search/{id}  GET  Get search by id    /api/search  PUT  Create or update search    /api/search  POST  Create or update search    /api/search/{id}  DELETE  Delete search by id", 
            "title": "Search endpoints"
        }, 
        {
            "location": "/developer/pillar/#manage-user-activities-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/cay/useraction  POST  Create or update user action", 
            "title": "Manage user activities endpoints"
        }, 
        {
            "location": "/developer/pillar/#create-update-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/author  POST  Create or update author    /api/asset  POST  Create or update asset    /api/comment  POST  Create or update comment    /api/index  POST  Create index    /api/metadata  POST  Update metadata    /api/section  POST  Create or update section    /api/user  POST  Create or update user", 
            "title": "Create / update endpoints"
        }, 
        {
            "location": "/developer/pillar/#form-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/form  POST  Create or update form    /api/form  PUT  Create or update form    /api/form/{id}/status/{status}  POST  Update form status    /api/forms  GET  Get forms    /api/form/{id}  GET  Get form by id    /api/form/{id}  DELETE  Delete form", 
            "title": "Form endpoints"
        }, 
        {
            "location": "/developer/pillar/#form-submission-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/form_submission/{form_id}  POST  Create form submission    /api/form_submission/{id}/status/{status}  PUT  Update form submission status    /api/form_submissions/{form_id}  GET  Get form submissions by form    /api/form_submission/{id}  GET  Get form submission    /api/form_submission/{id}/{answer_id}  PUT  Edit form submission answer    /api/form_submission/{id}/flag/{flag}  PUT  Add flag to form submission    /api/form_submission/{id}/flag/{flag}  DELETE  Delete flag from form submission    /api/form_submission/{id}  DELETE  Delete form submission    /api/form_submission/search  POST  Search a string on the answers of the form submissions", 
            "title": "Form submission endpoints"
        }, 
        {
            "location": "/developer/pillar/#form-galleries-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/form_gallery/{id}  GET  Get form gallery    /api/form_galleries/{form_id}  GET  Get form galleries by form    /api/form_galleries/form/{form_id}  GET  Get form galleries by form (version 2)    /api/form_gallery/{id}/add/{submission_id}/{answer_id}  PUT  Add answer to form gallery    /api/form_gallery/{id}/remove/{submission_id}/{answer_id}  DELETE  Remove answer from form gallery", 
            "title": "Form galleries endpoints"
        }, 
        {
            "location": "/developer/pillar/#import-action", 
            "text": "URL  HTTP Verb  Functionality      /api/import/action  GET  Import action", 
            "title": "Import action"
        }, 
        {
            "location": "/developer/pillar/#parameters", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call", 
            "text": "GET\nhttps://localhost:8080/api/import/action", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response", 
            "text": "{\n   results : [\n    {\n       playerName :  Jang Min Chul ,\n       updatedAt :  2011-08-19T02:24:17.787Z ,\n       cheatMode : false,\n       createdAt :  2011-08-19T02:24:17.787Z ,\n       objectId :  A22v5zRAgd ,\n       score : 80075\n    },\n    {\n       playerName :  Sean Plott ,\n       updatedAt :  2011-08-21T18:02:52.248Z ,\n       cheatMode : false,\n       createdAt :  2011-08-20T02:06:57.931Z ,\n       objectId :  Ed1nuqPvcm ,\n       score : 73453\n    }\n  ]\n}", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#import-asset", 
            "text": "URL  HTTP Verb  Functionality      /api/import/asset  GET  Import asset", 
            "title": "Import asset"
        }, 
        {
            "location": "/developer/pillar/#parameters_1", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_1", 
            "text": "GET\nhttps://localhost:8080/api/import/asset", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_1", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#import-comment", 
            "text": "URL  HTTP Verb  Functionality      /api/import/comment  GET  Import comment", 
            "title": "Import comment"
        }, 
        {
            "location": "/developer/pillar/#parameters_2", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_2", 
            "text": "GET\nhttps://localhost:8080/api/import/comment", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_2", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#import-note", 
            "text": "URL  HTTP Verb  Functionality      /api/import/note  GET  Import note", 
            "title": "Import note"
        }, 
        {
            "location": "/developer/pillar/#parameters_3", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_3", 
            "text": "GET\nhttps://localhost:8080/api/import/note", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_3", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#import-user", 
            "text": "URL  HTTP Verb  Functionality      /api/import/user  GET  Import user", 
            "title": "Import user"
        }, 
        {
            "location": "/developer/pillar/#parameters_4", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_4", 
            "text": "GET\nhttps://localhost:8080/api/import/user", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_4", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-tags", 
            "text": "URL  HTTP Verb  Functionality      /api/tags  GET  Get tags", 
            "title": "Get tags"
        }, 
        {
            "location": "/developer/pillar/#parameters_5", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_5", 
            "text": "GET\nhttps://localhost:8080/api/tags", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_5", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-tag", 
            "text": "URL  HTTP Verb  Functionality      /api/tag  POST  Create or update tag", 
            "title": "Create or update tag"
        }, 
        {
            "location": "/developer/pillar/#parameters_6", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body", 
            "text": "body here", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_6", 
            "text": "POST\nhttps://localhost:8080/api/tag", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_6", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#delete-tag", 
            "text": "URL  HTTP Verb  Functionality      /api/tag  POST  Create or update tag", 
            "title": "Delete tag"
        }, 
        {
            "location": "/developer/pillar/#parameters_7", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_1", 
            "text": "body", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_7", 
            "text": "DELETE\nhttps://localhost:8080/api/tag", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_7", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-searches", 
            "text": "URL  HTTP Verb  Functionality      /api/searches  GET  Get searches", 
            "title": "Get searches"
        }, 
        {
            "location": "/developer/pillar/#parameters_8", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_8", 
            "text": "GET\nhttps://localhost:8080/api/searches", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_8", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-search-by-id", 
            "text": "URL  HTTP Verb  Functionality      /api/search/{id}  GET  Get search by id", 
            "title": "Get search by id"
        }, 
        {
            "location": "/developer/pillar/#parameters_9", 
            "text": "id : search id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_9", 
            "text": "GET\nhttps://localhost:8080/api/search/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_9", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-search-put", 
            "text": "URL  HTTP Verb  Functionality      /api/search  PUT  Create or update search", 
            "title": "Create or update search (put)"
        }, 
        {
            "location": "/developer/pillar/#parameters_10", 
            "text": "id : search id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_10", 
            "text": "PUT\nhttps://localhost:8080/api/search", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_10", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-search-post", 
            "text": "URL  HTTP Verb  Functionality      /api/search  PUT  Create or update search", 
            "title": "Create or update search (post)"
        }, 
        {
            "location": "/developer/pillar/#parameters_11", 
            "text": "id : search id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_11", 
            "text": "POST\nhttps://localhost:8080/api/search", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_11", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#delete-search", 
            "text": "URL  HTTP Verb  Functionality      /api/search{id}  DELETE  Delete search by id", 
            "title": "Delete search"
        }, 
        {
            "location": "/developer/pillar/#parameters_12", 
            "text": "id : search id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_12", 
            "text": "DELETE\nhttps://localhost:8080/api/search/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_12", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-user-action", 
            "text": "URL  HTTP Verb  Functionality      /api/cay/useraction  POST  Create or update user action", 
            "title": "Create or update user action"
        }, 
        {
            "location": "/developer/pillar/#parameters_13", 
            "text": "id : user id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_2", 
            "text": ".", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_13", 
            "text": "POST\nhttps://localhost:8080/api/cay/useraction?userid=123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_13", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-author", 
            "text": "URL  HTTP Verb  Functionality      /api/author/{id}  POST  Create or update author", 
            "title": "Create or update author"
        }, 
        {
            "location": "/developer/pillar/#parameters_14", 
            "text": "id : author id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_3", 
            "text": ".", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_14", 
            "text": "POST\nhttps://localhost:8080/api/author/456", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_14", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-asset", 
            "text": "URL  HTTP Verb  Functionality      /api/asset/{id}  POST  Create or update asset", 
            "title": "Create or update asset"
        }, 
        {
            "location": "/developer/pillar/#parameters_15", 
            "text": "id : asset id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_4", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_15", 
            "text": "POST\nhttps://localhost:8080/api/asset/456", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_15", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-comment", 
            "text": "URL  HTTP Verb  Functionality      /api/comment/{id}  POST  Create or update comment", 
            "title": "Create or update comment"
        }, 
        {
            "location": "/developer/pillar/#parameters_16", 
            "text": "id : comment id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_5", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_16", 
            "text": "POST\nhttps://localhost:8080/api/comment/456", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_16", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-index", 
            "text": "URL  HTTP Verb  Functionality      /api/index/{id}  POST  Create index", 
            "title": "Create index"
        }, 
        {
            "location": "/developer/pillar/#parameters_17", 
            "text": "id : index id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_6", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_17", 
            "text": "POST\nhttps://localhost:8080/api/index/678", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_17", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#update-metadata", 
            "text": "URL  HTTP Verb  Functionality      /api/metadata/{id}  POST  Update metadata", 
            "title": "Update metadata"
        }, 
        {
            "location": "/developer/pillar/#parameters_18", 
            "text": "id : metadata id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_7", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_18", 
            "text": "POST\nhttps://localhost:8080/api/metadata/789", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_18", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-section", 
            "text": "URL  HTTP Verb  Functionality      /api/section/{id}  POST  Create or update section", 
            "title": "Create or update section"
        }, 
        {
            "location": "/developer/pillar/#parameters_19", 
            "text": "id : section id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_8", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_19", 
            "text": "POST\nhttps://localhost:8080/api/section/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_19", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-user", 
            "text": "URL  HTTP Verb  Functionality      /api/user/{id}  POST  Create or update user", 
            "title": "Create or update user"
        }, 
        {
            "location": "/developer/pillar/#parameters_20", 
            "text": "id : user id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_9", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_20", 
            "text": "POST\nhttps://localhost:8080/api/user/234", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_20", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-form-post", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}  POST  Create or update form", 
            "title": "Create or update form (post)"
        }, 
        {
            "location": "/developer/pillar/#parameters_21", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_10", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_21", 
            "text": "POST\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_21", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-or-update-form-put", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}  PUT  Create or update form", 
            "title": "Create or update form (put)"
        }, 
        {
            "location": "/developer/pillar/#parameters_22", 
            "text": "id : asset id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_11", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_22", 
            "text": "PUT\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_22", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#update-form-status", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}/status/{status}  POST  Update form status", 
            "title": "Update form status"
        }, 
        {
            "location": "/developer/pillar/#parameters_23", 
            "text": "id : form id  id : updated form status (what are the available form status options?)", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_12", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_23", 
            "text": "POST\nhttps://localhost:8080/api/form/123/status/complete", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_23", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-forms", 
            "text": "URL  HTTP Verb  Functionality      /api/forms  GET  Get all forms", 
            "title": "Get forms"
        }, 
        {
            "location": "/developer/pillar/#parameters_24", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_24", 
            "text": "GET\nhttps://localhost:8080/api/forms", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_24", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-form-by-id", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}  GET  Get form by id", 
            "title": "Get form by id"
        }, 
        {
            "location": "/developer/pillar/#parameters_25", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_25", 
            "text": "GET\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_25", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#delete-form", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}  DELETE  Delete form by id", 
            "title": "Delete form"
        }, 
        {
            "location": "/developer/pillar/#parameters_26", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_26", 
            "text": "DELETE\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_26", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#create-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{form_id}  POST  Create form submission by id", 
            "title": "Create form submission"
        }, 
        {
            "location": "/developer/pillar/#parameters_27", 
            "text": "form_id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_13", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_27", 
            "text": "POST\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_27", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#update-form-submission-status", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}/status/{status}  PUT  Update form submission status", 
            "title": "Update form submission status"
        }, 
        {
            "location": "/developer/pillar/#parameters_28", 
            "text": "id : form id  status : updated form submission status", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_28", 
            "text": "PUT\nhttps://localhost:8080/api/form_submission/123/status/completed", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_28", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-form-submissions-by-form", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submissions/{form_id}  GET  Get form submission by form", 
            "title": "Get form submissions by form"
        }, 
        {
            "location": "/developer/pillar/#parameters_29", 
            "text": "Parameters  Required?  Value  Description      form_id  Y  Number  Form id for which we want to see the submissions    skip  Y  Number  Skip the first  n  submissions    limit  N  Number  Limit to  n  submission returns    orderby  N  asc  or  dsc  Order by ascending date ( asc ) or descending date ( dsc )    filterby  N  Regex string (example:  ^(?!test_the_flag) )  Filter by a specific flag using regular expressions. If you want to match all the submissions that do not have a specific flag, use  ^(?!test_the_flag)    search  N  String  String to search through submissions  replies.answer", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_29", 
            "text": "GET\nhttps://localhost:8080/api/form_submissions/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_29", 
            "text": "{\n     counts : {\n         search_by_flag : {\n             test_the_flag : 1,\n             something_else : 1\n        },\n         total_search : 1,\n         total_submissions : 2\n    },\n     submissions : [\n        {\n             id :  5751ef7310780b96f002a3af ,\n             form_id :  5751ef7310780b96f002a3ad ,\n             status :  ,\n             replies : [\n                {\n                     widget_id :  1 ,\n                     identity : false,\n                     answer :  Gophers everywhere ,\n                     edited :  This is an edit! Purple Monkey Dishwasher. ,\n                     question :  Is there anybody out there? ,\n                     props : {\n                         a :  B ,\n                         c : 4\n                    }\n                },\n                {\n                     widget_id :  2 ,\n                     identity : false,\n                     answer :  Dave ,\n                     edited :  This is an edit! Purple Monkey Dishwasher. ,\n                     question :  Name ,\n                     props : {\n                         a :  B ,\n                         c : 4\n                    }\n                },\n                {\n                     widget_id :  3 ,\n                     identity : false,\n                     answer :  D@ve.name ,\n                     edited :  This is an edit! Purple Monkey Dishwasher. ,\n                     question :  Email ,\n                     props : {\n                         a :  B ,\n                         c : 4\n                    }\n                }\n            ],\n             flags : [\n                 test_the_flag ,\n                 something_else \n            ],\n             header : {\n                 description :  of the rest of your life ,\n                 title :  This is the first form \n            },\n             footer : {\n                 conditions :  lots of conditions \n            },\n             finishedScreen : null,\n             created_by :  ,\n             updated_by :  ,\n             date_created :  2016-06-03T16:58:27.56-04:00 ,\n             date_updated :  2016-06-03T16:58:27.56-04:00 \n        }\n    ]\n}  where   search_by_flag  : brings a count on all the tags for for the specific search (without filtering by flag) for that form id  total_search : count all the submissions for the specific search (without filtering by flag) for that form id  total_submissions : count all the submissions for that form id", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}  GET  Get form submission", 
            "title": "Get form submission"
        }, 
        {
            "location": "/developer/pillar/#parameters_30", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_30", 
            "text": "GET\nhttps://localhost:8080/api/form_submission/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_30", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#edit-form-submission-answer", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}/{answer_id}  PUT  Edit form submission answer", 
            "title": "Edit form submission answer"
        }, 
        {
            "location": "/developer/pillar/#parameters_31", 
            "text": "id : form id  answer_id : answer id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_14", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_31", 
            "text": "PUT\nhttps://localhost:8080/api/form_submission/123/456", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_31", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#add-flag-to-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}/flag/{flag}  PUT  Add flag to form submission", 
            "title": "Add flag to form submission"
        }, 
        {
            "location": "/developer/pillar/#parameters_32", 
            "text": "id : form id  flag : updated flag", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_32", 
            "text": "PUT\nhttps://localhost:8080/api/form_submission/123/flag/g", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_32", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#delete-flag-from-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}/flag/{flag}  DELETE  Delete flag from form submission", 
            "title": "Delete flag from form submission"
        }, 
        {
            "location": "/developer/pillar/#parameters_33", 
            "text": "id : form id  flag : flag to delete", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_33", 
            "text": "DELETE\nhttps://localhost:8080/api/form_submission/123/flag/g", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_33", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#delete-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}  DELETE  Delete form submission", 
            "title": "Delete form submission"
        }, 
        {
            "location": "/developer/pillar/#parameters_34", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_34", 
            "text": "DELETE\nhttps://localhost:8080/api/form_submission/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_34", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#search-form-submissions", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/search  POST  Search form submissions", 
            "title": "Search form submissions"
        }, 
        {
            "location": "/developer/pillar/#parameters_35", 
            "text": "Parameters  Required?  Value  Description      form_id  Y  Number  Form id for which we want to see the submissions    skip  Y  Number  Skip the first  n  submissions    limit  N  Number  Limit to  n  submission returns    orderby  N  asc  or  dsc  Order by ascending date ( asc ) or descending date ( dsc )    filterby  N  Regex string (example:  ^(?!test_the_flag) )  Filter by a specific flag using regular expressions. If you want to match all the submissions that do not have a specific flag, use  ^(?!test_the_flag)", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_35", 
            "text": "POST\nhttps://localhost:8080/api/form_submission/search  {\n   search :  Gophers \n}", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_35", 
            "text": "Status: 200 OK  Body: [\n  {\n     id :  577c197810780b3401e7a3af ,\n     form_id :  577c18f4a969c805f7f8c889 ,\n     status :  ,\n     replies : [\n      {\n         widget_id :  1 ,\n         identity : false,\n         answer :  Gophers everywhere ,\n         edited : null,\n         question :  Is there anybody out there? ,\n         props : {\n           a :  B ,\n           c : 4\n        }\n      },\n      {\n         widget_id :  2 ,\n         identity : true,\n         answer :  Dave ,\n         edited : null,\n         question :  Name ,\n         props : {\n           a :  B ,\n           c : 4\n        }\n      },\n      {\n         widget_id :  3 ,\n         identity : true,\n         answer :  D@ve.name ,\n         edited : null,\n         question :  Email ,\n         props : {\n           a :  B ,\n           c : 4\n        }\n      }\n    ],\n     flags : [],\n     header : {\n       description :  of the rest of your life ,\n       title :  This is the first form \n    },\n     footer : {\n       conditions :  lots of conditions \n    },\n     finishedScreen : null,\n     created_by : null,\n     updated_by : null,\n     date_created :  2016-07-01T21:31:45-06:00 ,\n     date_updated :  2016-07-01T21:31:45-06:00 \n  }\n]", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-form-gallery", 
            "text": "URL  HTTP Verb  Functionality      /api/form_gallery/{id}  GET  Get form gallery", 
            "title": "Get form gallery"
        }, 
        {
            "location": "/developer/pillar/#parameters_36", 
            "text": "id : form gallery id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_36", 
            "text": "GET\nhttps://localhost:8080/api/form_gallery/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_36", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-form-galleries-by-form", 
            "text": "URL  HTTP Verb  Functionality      /api/form_galleries/{form_id}  GET  Get form galleries by form", 
            "title": "Get form galleries by form"
        }, 
        {
            "location": "/developer/pillar/#parameters_37", 
            "text": "form_id : form gallery id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_37", 
            "text": "GET\nhttps://localhost:8080/api/form_galleries/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_37", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#get-form-galleries-by-form-version-2", 
            "text": "URL  HTTP Verb  Functionality      /api/form_galleries/form/{form_id}  GET  Get form galleries by form", 
            "title": "Get form galleries by form (version 2)"
        }, 
        {
            "location": "/developer/pillar/#parameters_38", 
            "text": "form_id : form gallery id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_38", 
            "text": "GET\nhttps://localhost:8080/api/form_galleries/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_38", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#add-answer-to-form-gallery", 
            "text": "URL  HTTP Verb  Functionality      /api/form_gallery/{id}/add/{submission_id}/{answer_id}  PUT  Add answer to form gallery", 
            "title": "Add answer to form gallery"
        }, 
        {
            "location": "/developer/pillar/#parameters_39", 
            "text": "id : form gallery id  submission_id : submission id  answer_id : answer id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#message-body_15", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/developer/pillar/#example-call_39", 
            "text": "GET\nhttps://localhost:8080/api/form_gallery/123/add/456/789", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_39", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/pillar/#remove-answer-from-form-gallery", 
            "text": "URL  HTTP Verb  Functionality      /api/form_gallery/{id}/remove/{submission_id}/{answer_id}  DELETE  Remove answer from form gallery", 
            "title": "Remove answer from form gallery"
        }, 
        {
            "location": "/developer/pillar/#parameters_40", 
            "text": "id : form gallery id  submission_id : submission id  answer_id : answer id", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/pillar/#example-call_40", 
            "text": "GET\nhttps://localhost:8080/api/form_gallery/123/remove/456/789", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/pillar/#example-response_40", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/sponge/", 
            "text": "Introduction\n\n\nSponge is a data import service used to get your existing community (comments, authors, assets, and other entities) into the Coral ecosystem.\n\n\nIt is an Extract, Transform, and Load command line tool designed to:\n\n\n\n\nRead data from a foreign source,\n\n\nTranslate the schema into Coral conventions, and\n\n\nPOST entities to our service layer for insertion.\n\n\n\n\nSponge uses strategy files to assist with data import. Strategy files are JSON files that are used to tell Sponge where to get the data, and how to translate it. You can read more about \nstrategy files here\n, including information on their structure and examples.\n\n\nGoDoc source code documentation\n\n\nSponge has automatically generated \nGoDoc generated documentation\n available, which you can view \nhere\n. GoDoc generates documentation from Go source code.\n\n\nComposition\n\n\nSponge is made up of several different packages, and you can read more about them on the \nincluded packages section\n. They work together as shown in the diagram below:\n\n\n\n\nData import sources supported\n\n\nSponge currently only supports importing data from mySQL, PostgreSQL, MongoDB or web services with REST APIs.\n\n\nCommand line tool\n\n\nUsage:\n\n\nsponge --flag [command]\n\n\n\n\nAvailable Commands:\n\n\n\n\nimport\n: Import data to the coral database.\n\n\nindex\n: Work with indexes in the coral database.\n\n\nshow\n: Read the report on errors.\n\n\nversion\n: Print the version number of Sponge.\n\n\nall\n: Import and Create Indexes.\n\n\n\n\nFlags\n\n\n--dbname=\nreport.db\n: set the name for the db to read\n--filepath=\nreport.db\n: set the file path for the report on errors (default is report.db)\n-h, --help[=false]: help for sponge\n--limit=9999999999: number of rows that we are going to import (default is 9999999999)\n--offset=0: offset for rows to import (default is 0)\n--onlyfails[=false]: import only the the records that failed in the last import(default is import all)\n--orderby=\n: order by field on the external source (default is not ordered)\n--query=\n: query on the external table (where condition on mysql, query document on mongodb). It only works with a specific --type. Example updated_date \n'2003-12-31 01:02:03'\n--report[=false]: create report on records that fail importing (default is do not report)\n--type=\n: import or create indexes for only these types of data (default is everything)\n\n\n\n\nSponge installation\n\n\nBefore you begin\n\n\nPillar\n\n\nYou will need to have an instance of \nPillar\n running, where your translated data will be sent. Instructions on installing Pillar \ncan be found here\n.\n\n\nExternal database source\n\n\nYou will also have your external database running. This external database is the source of your existing comment data that will be extracted by Sponge and sent to Pillar, which will then load it into the Coral ecosystem.\n\n\nThe external sources we currently support are: PostgreSQL, MySQL, MongoDB, and REST APIs.\n\n\nVendoring dependencies\n\n\nYou should be vendoring the packages you choose to use (\nvendoring\n is the moving of all third party items such as packages into the \n/vendor\n directory). We recommend using \ngovendor\n. This tool will manage your dependencies from the vendor folder associated with this project repository.\n\n\nInstall from source\n\n\nBefore you begin\n\n\nIf you want to install from source, you will need to have Go installed.\n\n\nFirst \ninstall Go\n. The \ninstallation and setup instructions\n on the Go website are pretty good. Ensure that you have exported your $GOPATH environment variable, as detailed in the \ninstallation instructions\n.\n\n\nIf you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.\n\n\nexport GO15VENDOREXPERIMENT=1\n\n\n\n\nIf you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.\n\n\nGet the source code\n\n\nYou can install the source code via using the \ngo get\n command, or by manually cloning the code.\n\n\nUsing the go get command\n\n\ngo get github.com/coralproject/sponge\n\n\n\n\nIf you see a message about \nno buildable Go source files\n like the below, you can ignore it. It simply means that there are buildable source files in subdirectories, just not the uppermost sponge directory.\n\n\npackage github.com/coralproject/sponge: no buildable Go source files in [directory]\n\n\n\n\nCloning manually\n\n\nYou can also clone the code manually.\n\n\nmkdir $GOPATH/src/github.com/coralproject/sponge\ncd $GOPATH/src/github.com/coralproject/sponge\n\ngit clone https://github.com/coralproject/sponge.git\n\n\n\n\nSet up your strategy.json file\n\n\nYou can read about \nstrategy files in depth here\n.\n\n\nThe strategy.json file tells Sponge how to do the transformation between the publisher\ns existing data and the Coral data schema. It also tells us how to connect to the external publisher\ns source data. We currently support the following sources: PostgreSQL, MySQL, MongoDB, and REST APIs.\n\n\nWe have example strategy.json files for each of those source types. You can see those example strategy.json files in the \nexamples\n folder: \n$GOPATH/src/github.com/coralproject/sponge/examples\n\n\nTo copy one of the example strategy.json files to another folder, where you can then customize it:\n\n\ncp $GOPATH/src/github.com/coralproject/sponge/examples/strategy.json.example $GOPATH/src/github.com/coralproject/sponge/strategy/strategy.json\n\n\n\n\nSet your environment variables\n\n\nSetting your environment variables tells Sponge which strategy file you want to use, and the URL for the \nPillar\n instance you are pushing data to.\n\n\nMake your own copy of the \nconfig/dev.cfg\n file (you can edit this configuration file with your own values, and then ensure that you don\nt commit it back to the repository). Call your config file whatever you like; we\nll call it \ncustom\n in this example.\n\n\ncd $GOPATH/src/github.com/coralproject/sponge\ncp config/dev.cfg config/custom.cfg\n\n\n\n\nNow edit the values in your custom.cfg file:\n\n\nexport STRATEGY_CONF=/path/to/my/strategy.json\nexport PILLAR_URL=http://localhost:8080\n\n\n\n\n\n\nSTRATEGY_CONF\n: Specifies the path to your strategy.json file.\n\n\nPILLAR_URL\n: Specifies the URL where your Pillar instance is running. If you installed Pillar locally from source, this will probably be \nhttp://localhost:8080\n.\n\n\n\n\nOnce you\nve edited and saved your custom.cfg file, source it:\n\n\nsource $GOPATH/src/github.com/coralproject/sponge/config/custom.cfg\n\n\n\n\nRun Sponge\n\n\nYou can either run Sponge using Go, or via a CLI tool.\n\n\nRunning Sponge using go run\n\n\ncd $GOPATH/src/github.com/coralproject/sponge/cmd/sponge\ngo run main.go\n\n\n\n\nRunning Sponge using the CLI tool\n\n\nFirst build the CLI tool:\n\n\ncd $GOPATH/src/github.com/coralproject/cmd/cmd/sponge\ngo build\n\n\n\n\nThen run the CLI tool\n\n\n./sponge -h\n\n\n\n\nInstall as a Docker container\n\n\nBuilding image\n\n\nTo build the docker image, run this command:\n\n\ndocker build -t \nsponge:latest\n -f Dockerfile ./\n\n\n\n\nEdit env.list\n\n\nSetting your environment variables tells Sponge which strategy file you want to use, and the URL for the \nPillar\n instance you are pushing data to.\n\n\nPILLAR_URL=http://192.168.99.100:8080\nSTRATEGY_CONF=/strategy/strategy_psql.json\n\n# DATABASE\n# (optional if you want to overwrite strategy file values)\nDB_database= \n\nDB_username= \n\nDB_password= \n\nDB_host= \n\nDB_port= \n\n\n# WEB SERVICE\n# (optional if you want to overwrite strategy file values)\nWS_appkey= \n\nWS_endpoint= \n\nWS_records= \n\nWS_pagination= \n\nWS_useragent= \n\nWS_attributes= \n\n\n\n\n\nRequired edits:\n\n\n\n\nSTRATEGY_CONF\n: Specifies the path to your strategy.json file.\n\n\nPILLAR_URL\n: Specifies the URL where your Pillar instance is running. If you installed Pillar locally from source, this will probably be \nhttp://localhost:8080\n.\n\n\n\n\nRunning the container\n\n\nSpinning up the container will start importing everything setup in the \nstrategy file\n.\n\n\ndocker run --env-file env.list -d sponge\n\n\n\n\nPackages included in Sponge\n\n\n\n\nStrategy\n reads the translations file.\n\n\nSource\n performs the extraction of data from the external data source.\n\n\nFiddler\n performs the transformation of data.\n\n\nCoral\n sends data to Pillar.\n\n\nSponge\n ties all the pieces together.\n\n\n\n\n\n\nStrategy\n\n\nimport \ngithub.com/coralproject/sponge/pkg/strategy\n\n\n\n\n\nThe Strategy package reads in the external \nstrategy JSON file\n and creates a structure containing translation information.\n\n\nVariables\n\n\n\n\nvar pillarURL string\n: URL that points to the Pillar instance, where the data will be sent.\n\n\nThis is initialized by the \nPILLAR_URL\n environment variable.\n\n\n\n\n\n\nvar uuid string\n: Universally Unique Identifier used for the logs.\n\n\n\n\nTo read more about strategy JSON files, you can read \nour section on strategy files\n.\n\n\nSource\n\n\nimport \ngithub.com/coralproject/sponge/pkg/source\n\n\n\n\n\nThe Source package contains the drivers that we use to connect to the external source and retrieve data. The credentials for the external data source are set up in the \nstrategy file\n.\n\n\nVariables\n\n\n\n\nvar strategy str.Strategy\n: Holds the credentials for the external source, as well as all the entities that need to be extracted.\n\n\nvar uuid string\n: Universally Unique Identifier used for the logs.\n\n\nvar credential str.Credential\n: Credential for the external source (database or web service).\n\n\n\n\nSourcer interface\n\n\nThis is the interface that needs to be implemented by any driver that connects to an external data source.\n\n\nfunc GetData\n\n\nGetData(string, *Options) ([]map[string]interface{}, error)\n\n\n\n\nReturns all the data (query by options in Options) in the format \n[]map[string]interface{}\n\n\nfunc IsWebService\n\n\nIsWebService() bool\n\n\n\n\nReturns true if the implementation of Sourcer is a web service.\n\n\nfunc New\n\n\nfunc New(d string) (Sourcer, error)\n\n\n\n\nReturns a structure with the connection to the external source that implements the interface Sourcer.\n\n\nfunc GetEntities\n\n\nfunc GetEntities() ([]string, error)\n\n\n\n\nGets all of the entity names from the external data source.\n\n\nfunc GetforeignEntity\n\n\nfunc GetForeignEntity(name string) string\n\n\n\n\nGets a single foreign entity\ns name.\n\n\nmySQL driver\n\n\nThe mySQL driver is contained in the \nmysql.go\n file. It has a mySQL struct that implements the Sourcer interface, and enables data extraction from a mySQL database.\n\n\nPostgreSQL driver\n\n\nThe PostgreSQL driver is contained in the \npostgresql.go\n file. It has a PostgreSQL struct that implements the Sourcer interface, and enables data extraction from a PostgreSQL database.\n\n\nMongoDB driver\n\n\nThe MongoDB driver is contained in the \nmongodb.go\n file. It has a MongoDB struct that implements the Sourcer interface, and enables data extraction from a MongoDB database.\n\n\nAPI driver\n\n\nThe API driver is contained in the \napi.go\n file. It has an API struct that implements the Sourcer interface, and enables data extraction from an API interface.\n\n\nHow to add a new source\n\n\nCurrently, we offer the four drivers listed above (mySQL, PostgreSQL, MongoDB, and REST API). If you need to add a new type of external source, you can write your own driver. To write your own driver, you will implement the Sourcer interface for your type of external data source.\n\n\nFiddler\n\n\nimport \ngithub.com/coralproject/sponge/pkg/fiddler\n\n\n\n\n\nThe Fiddler package performs the translation from the external database schema into Coral\ns database schema.\n\n\nVariables\n\n\n\n\nstrategy   str.Strategy\n Holds the translation, in JSON form, to apply to the data.\n\n\ndateLayout string\n Date Layout as specified in the strategy file.\n\n\nuuid string\n Universally Unique Identifier used for the logs.\n\n\n\n\nFunctions\n\n\nfunc GetID\n\n\nfunc GetID(modelName string) string\n\n\n\n\nReturns the field that is the identifier for that model\n\n\nfunc GetCollections\n\n\nfunc GetCollections() []string\n\n\n\n\nReturns the names of all the collections in the strategy file.\n\n\nfunc TransformRow\n\n\nfunc TransformRow(row map[string]interface{}, coralName string) (interface{}, []map[string]interface{}, error)\n\n\n\n\nApplies the coral schema to a row of data from the external source.\n\n\nCoral\n\n\nNote\n: The \nCoral\n package is not to be confused with the Coral ecosystem as a whole. In this instance, this is merely the name of a package included in the Sponge app.\n\n\nimport \ngithub.com/coralproject/sponge/pkg/coral\n\n\n\n\n\nCoral interacts with Pillar endpoints to import data into the Coral system.\n\n\nConstants\n\n\n\n\nretryTimes int    = 3\n Determines how many times to retry communication with Pillar, if it initially fails.\n\n\nmethodGet  string = \"GET\"\n\n\nmethodPost string = \"POST\"\n\n\n\n\nVariables\n\n\n\n\nendpoints map[string]string\n \nendpoints\n is a map containing all of the services where we can send data. Right now, that is only Pillar.\n\n\nuuid string\n Universally Unique Identifier used for the logs.\n\n\nstr  strategy.Strategy\n Holds the translation, in JSON form, to apply to the data.\n\n\n\n\nFunctions\n\n\nfunc AddRow\n\n\nfunc AddRow(data map[string]interface{}, tableName string) error\n\n\n\n\nAdds data to the collection \ntableName\n.\n\n\nfunc CreateIndex\n\n\nfunc CreateIndex(collection string) error\n\n\n\n\nCalls the service to create index for \ncollection\n.\n\n\nSponge\n\n\nNote\n: The \nSponge\n package is not to be confused with the Sponge app as a whole. In this instance, this is merely the name of a package included in the larger Sponge app.\n\n\nimport \ngithub.com/coralproject/sponge/pkg/sponge\n\n\n\n\n\nThe Sponge package ties together all of the other packages, so that they all communicate and work with each other.\n\n\nConstants\n\n\n\n\nVersionNumber = 0.1\n Provides the version number of Sponge.\n\n\n\n\nVariables\n\n\n\n\ndbsource source.Sourcer\n\n\nuuid     string\n\n\noptions  source.Options\n\n\n\n\nFunctions\n\n\nfunc AddOptions\n\n\nfunc AddOptions(limit int, offset int, orderby string, query string, types string, importonlyfailed bool, reportOnFailedRecords bool, reportdbfile string)\n\n\n\n\nAddOptions\n sets options for how Sponge will run. The options are:\n\n\n\n\nLimit\n: Limit for the query.\n\n\nOffset\n: Offset for the query.\n\n\nOrderby\n:  Order by this field\n\n\nQuery\n:  We use this field if we want to specific a filter on WHERE for mySQL/PostgreSQL and Find for MongoDB.\n\n\nTypes\n: Specifies which entities to import (the default is \neverything\n).\n\n\nImportonlyfailed\n: Import only the documents that are in the report.\n\n\nReportOnFailedRecords\n: Create a report with all the documents that failed the import.\n\n\nReportdbfile\n: Name of the file for the report on documents that fail the import.\n\n\n\n\nfunc Import\n\n\nfunc Import()\n\n\n\n\nGets data, transforms it and sends it to Pillar. It bases everything on the STRATEGY_CONF environment variable and the PILLAR_URL environment variable.\n\n\nfunc CreateIndex\n\n\nfunc CreateIndex(collection string)\n\n\n\n\nCreates index on the collection \ncollection\n. This feature creates indexes on the Coral database, depending on the data in the strategy file.\n\n\nFor example:\n\n\nIndex\n: [\n  {\n    \nname\n: \nasset-url\n,\n    \nkeys\n: [\nasseturl\n],\n    \nunique\n: \ntrue\n,\n    \ndropdups\n: \ntrue\n\n  }\n],\n\n\n\n\nYou can read more information at the \nmongodb\ns create index definition\n.\n\n\nStrategy files\n\n\nStrategy files are JSON configuration files that contain all the information Sponge needs to extract data from a source, translate it to the Coral schema, and send it on to Pillar and from there to the Coral MongoDB.\n\n\nThe external data sources we currently support are: PostgreSQL, MySQL, MongoDB, and REST APIs.\n\n\nThe strategy spec is still being refined. We have examples that you can view in the \nexamples directory\n.\n\n\nExamples:\n\n\n\n\nAPI example\n\n\nMongoDB example\n\n\nmySQL example\n\n\nPostgreSQL example\n\n\n\n\nFields in the strategy.json file\n\n\nGeneral fields\n\n\n\n\nName\n: The name of the strategy that we are describing.\n\n\nMap\n: Contains all the information to map fields from the external data source to our local Coral database.\n\n\nForeign\n: Describes the type of external database source (for example, \nmysql\n or \nmongodb\n).\n\n\nDateTimeFormat\n: Tells us how to parse date/time fields in the external data source. You should populate this field with the date and time of \n2006 Mon Jan 2 15:04:05\n, written in the format that appears in your external database.\n\n\n\n\nEntity fields\n\n\nEntities\n is a JSON object that describes all of the different entities in the Coral database, and how to perform the transformation for that entity.\n\n\n\n\nForeign\n: The name of the foreign entity.\n\n\nLocal\n: The collection into which we are importing this entity.\n\n\nPriority\n: This is a number that specifies which entity to import first (the highest priority is 0).\n\n\nOrderBy\n: The field to order the results by when querying the foreign source.\n\n\nID\n: The identifier field for the foreign entity. We use this field when we need to import only some records and not the whole entity.\n\n\nEndpoint\n: This is the \nPillar endpoint URL\n where we will push the data.\n\n\nFields\n: All the fields that are being mapped.\n\n\nforeign\n: The name of the field in the foreign entity.\n\n\nlocal\n: The name of the field in our local database.\n\n\nrelation\n: The relationship between the foreign field and the local one. We have the following options:\n\n\nPassthrough\n: When the value is the same.\n\n\nSource\n: When it needs to be added to our source struct for the local collection (the original identifiers have to go into source).\n\n\nParseTimeDate\n: When we need to parse the foreign value as date time.\n\n\nConstant\n: When the local field should always be the same value. In this case we will have \nforeign\n blank and we will have other field called \nvalue\n with the value of the local field.\n\n\nSubDocument\n: When the local field has an array of documents in one of the fields.\n\n\nStatus\n: When the field need to be translated based on the status map that is declared in that same strategy file for the entity.\n\n\n\n\n\n\nType\n: The type of the value we are converting.\n\n\nString\n\n\nTimedate\n\n\n\n\n\n\n\n\nCredentials\n\n\nThis contains the credentials for the external data source. It could be a REST API or a database (MySQL, PostgreSQL or MongoDB).\n\n\n\n\nadapter\n: This tells us which driver we need to use to extract data. Right now, the options available are \nmysql\n, \npostgresql\n, \nmongodb\n, or \nservice\n.\n\n\ntype\n: Right now this is always \nforeign\n, but in future it could tell us what type of credential this is.\n\n\n\n\nLogging\n\n\nWe are using (Ardanlabs Log\ns package)[https://github.com/ardanlabs/kit/tree/master/log] for all of the tools we are developing in Go.\n\n\nLogging levels:\n\n\n\n\nDev\n: To be outputted in development environment only.\n\n\nUser\n (prod): To be outputted in dev and production environments.\n\n\n\n\nAll logs should contain:\n\n\n\n\nContext uuid to identify a particular execution (aka, run of Sponge or a Request/Response execution from a web server).\n\n\nThe name of the function that is executing.\n\n\nA readable message including relevant data.\n\n\n\n\nLogs should write to \nstdout\n so that they can be flexibly directed.\n\n\nRoadmap\n\n\nThere are features we would like to incorporate into Sponge at a future date, but that we haven\nt yet prioritized into issues or releases.\n\n\nAPI Import\n\n\nPull data from HTTP(S) sources:\n\n\n\n\nDisqus - https://disqus.com/api/docs/\n\n\nWordpress Core - https://codex.wordpress.org/XML-RPC_WordPress_API/Comments\n\n\nLyvewire - http://answers.livefyre.com/developers/api-reference/\n\n\nFacebook - https://developers.facebook.com/docs/graph-api/reference/v2.5/comment\n\n\n\n\nRate Limit Counter\n\n\nIn order to protect source databases, we want to be able to throttle the number of queries that Sponge is making.\n\n\n\n\nKeep a sliding count of how many requests were made in the past time frame based on the strategy.\n\n\nExpose isOkToQuery() to determine if we are currently at the limit.\n\n\nEach request will send a message to this routine each time a request is made.\n\n\n\n\nSynchronization\n\n\nAn internal mechanism that regularly polls the source and imports any updates.\n\n\nBasic polling specification\n\n\nThe main loop that keeps the data up to date.  Gets \nslices\n of records based on \nupdated_at\n timestamps to account for changing records.\n\n\nFor each table or api in the strategy:\n\n\n\n\nEnsure maximum rate limit is not met\n\n\nDetermine which slice of data to get next\n\n\nFind the last updated timestamp in the \nlog collection\n (or the collection itself?)\n\n\n\n\n\n\nUse the strategy to request the slice (either db query or api call)\n\n\nUpdate the rate limit counter\n\n\n\n\n\n\nFor each record returned\n\n\nCheck to ensure the document isn\nt already added\n\n\nIf not, add the document and kick off \nimport actions\n\n\nIf it\ns there, update the document\n\n\nUpdate the \nlog collection", 
            "title": "Sponge"
        }, 
        {
            "location": "/developer/sponge/#introduction", 
            "text": "Sponge is a data import service used to get your existing community (comments, authors, assets, and other entities) into the Coral ecosystem.  It is an Extract, Transform, and Load command line tool designed to:   Read data from a foreign source,  Translate the schema into Coral conventions, and  POST entities to our service layer for insertion.   Sponge uses strategy files to assist with data import. Strategy files are JSON files that are used to tell Sponge where to get the data, and how to translate it. You can read more about  strategy files here , including information on their structure and examples.", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/sponge/#godoc-source-code-documentation", 
            "text": "Sponge has automatically generated  GoDoc generated documentation  available, which you can view  here . GoDoc generates documentation from Go source code.", 
            "title": "GoDoc source code documentation"
        }, 
        {
            "location": "/developer/sponge/#composition", 
            "text": "Sponge is made up of several different packages, and you can read more about them on the  included packages section . They work together as shown in the diagram below:", 
            "title": "Composition"
        }, 
        {
            "location": "/developer/sponge/#data-import-sources-supported", 
            "text": "Sponge currently only supports importing data from mySQL, PostgreSQL, MongoDB or web services with REST APIs.", 
            "title": "Data import sources supported"
        }, 
        {
            "location": "/developer/sponge/#command-line-tool", 
            "text": "", 
            "title": "Command line tool"
        }, 
        {
            "location": "/developer/sponge/#usage", 
            "text": "sponge --flag [command]", 
            "title": "Usage:"
        }, 
        {
            "location": "/developer/sponge/#available-commands", 
            "text": "import : Import data to the coral database.  index : Work with indexes in the coral database.  show : Read the report on errors.  version : Print the version number of Sponge.  all : Import and Create Indexes.", 
            "title": "Available Commands:"
        }, 
        {
            "location": "/developer/sponge/#flags", 
            "text": "--dbname= report.db : set the name for the db to read\n--filepath= report.db : set the file path for the report on errors (default is report.db)\n-h, --help[=false]: help for sponge\n--limit=9999999999: number of rows that we are going to import (default is 9999999999)\n--offset=0: offset for rows to import (default is 0)\n--onlyfails[=false]: import only the the records that failed in the last import(default is import all)\n--orderby= : order by field on the external source (default is not ordered)\n--query= : query on the external table (where condition on mysql, query document on mongodb). It only works with a specific --type. Example updated_date  '2003-12-31 01:02:03'\n--report[=false]: create report on records that fail importing (default is do not report)\n--type= : import or create indexes for only these types of data (default is everything)", 
            "title": "Flags"
        }, 
        {
            "location": "/developer/sponge/#sponge-installation", 
            "text": "", 
            "title": "Sponge installation"
        }, 
        {
            "location": "/developer/sponge/#before-you-begin", 
            "text": "", 
            "title": "Before you begin"
        }, 
        {
            "location": "/developer/sponge/#pillar", 
            "text": "You will need to have an instance of  Pillar  running, where your translated data will be sent. Instructions on installing Pillar  can be found here .", 
            "title": "Pillar"
        }, 
        {
            "location": "/developer/sponge/#external-database-source", 
            "text": "You will also have your external database running. This external database is the source of your existing comment data that will be extracted by Sponge and sent to Pillar, which will then load it into the Coral ecosystem.  The external sources we currently support are: PostgreSQL, MySQL, MongoDB, and REST APIs.", 
            "title": "External database source"
        }, 
        {
            "location": "/developer/sponge/#vendoring-dependencies", 
            "text": "You should be vendoring the packages you choose to use ( vendoring  is the moving of all third party items such as packages into the  /vendor  directory). We recommend using  govendor . This tool will manage your dependencies from the vendor folder associated with this project repository.", 
            "title": "Vendoring dependencies"
        }, 
        {
            "location": "/developer/sponge/#install-from-source", 
            "text": "", 
            "title": "Install from source"
        }, 
        {
            "location": "/developer/sponge/#before-you-begin_1", 
            "text": "If you want to install from source, you will need to have Go installed.  First  install Go . The  installation and setup instructions  on the Go website are pretty good. Ensure that you have exported your $GOPATH environment variable, as detailed in the  installation instructions .  If you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.  export GO15VENDOREXPERIMENT=1  If you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/developer/sponge/#get-the-source-code", 
            "text": "You can install the source code via using the  go get  command, or by manually cloning the code.", 
            "title": "Get the source code"
        }, 
        {
            "location": "/developer/sponge/#using-the-go-get-command", 
            "text": "go get github.com/coralproject/sponge  If you see a message about  no buildable Go source files  like the below, you can ignore it. It simply means that there are buildable source files in subdirectories, just not the uppermost sponge directory.  package github.com/coralproject/sponge: no buildable Go source files in [directory]", 
            "title": "Using the go get command"
        }, 
        {
            "location": "/developer/sponge/#cloning-manually", 
            "text": "You can also clone the code manually.  mkdir $GOPATH/src/github.com/coralproject/sponge\ncd $GOPATH/src/github.com/coralproject/sponge\n\ngit clone https://github.com/coralproject/sponge.git", 
            "title": "Cloning manually"
        }, 
        {
            "location": "/developer/sponge/#set-up-your-strategyjson-file", 
            "text": "You can read about  strategy files in depth here .  The strategy.json file tells Sponge how to do the transformation between the publisher s existing data and the Coral data schema. It also tells us how to connect to the external publisher s source data. We currently support the following sources: PostgreSQL, MySQL, MongoDB, and REST APIs.  We have example strategy.json files for each of those source types. You can see those example strategy.json files in the  examples  folder:  $GOPATH/src/github.com/coralproject/sponge/examples  To copy one of the example strategy.json files to another folder, where you can then customize it:  cp $GOPATH/src/github.com/coralproject/sponge/examples/strategy.json.example $GOPATH/src/github.com/coralproject/sponge/strategy/strategy.json", 
            "title": "Set up your strategy.json file"
        }, 
        {
            "location": "/developer/sponge/#set-your-environment-variables", 
            "text": "Setting your environment variables tells Sponge which strategy file you want to use, and the URL for the  Pillar  instance you are pushing data to.  Make your own copy of the  config/dev.cfg  file (you can edit this configuration file with your own values, and then ensure that you don t commit it back to the repository). Call your config file whatever you like; we ll call it  custom  in this example.  cd $GOPATH/src/github.com/coralproject/sponge\ncp config/dev.cfg config/custom.cfg  Now edit the values in your custom.cfg file:  export STRATEGY_CONF=/path/to/my/strategy.json\nexport PILLAR_URL=http://localhost:8080   STRATEGY_CONF : Specifies the path to your strategy.json file.  PILLAR_URL : Specifies the URL where your Pillar instance is running. If you installed Pillar locally from source, this will probably be  http://localhost:8080 .   Once you ve edited and saved your custom.cfg file, source it:  source $GOPATH/src/github.com/coralproject/sponge/config/custom.cfg", 
            "title": "Set your environment variables"
        }, 
        {
            "location": "/developer/sponge/#run-sponge", 
            "text": "You can either run Sponge using Go, or via a CLI tool.", 
            "title": "Run Sponge"
        }, 
        {
            "location": "/developer/sponge/#running-sponge-using-go-run", 
            "text": "cd $GOPATH/src/github.com/coralproject/sponge/cmd/sponge\ngo run main.go", 
            "title": "Running Sponge using go run"
        }, 
        {
            "location": "/developer/sponge/#running-sponge-using-the-cli-tool", 
            "text": "First build the CLI tool:  cd $GOPATH/src/github.com/coralproject/cmd/cmd/sponge\ngo build  Then run the CLI tool  ./sponge -h", 
            "title": "Running Sponge using the CLI tool"
        }, 
        {
            "location": "/developer/sponge/#install-as-a-docker-container", 
            "text": "", 
            "title": "Install as a Docker container"
        }, 
        {
            "location": "/developer/sponge/#building-image", 
            "text": "To build the docker image, run this command:  docker build -t  sponge:latest  -f Dockerfile ./", 
            "title": "Building image"
        }, 
        {
            "location": "/developer/sponge/#edit-envlist", 
            "text": "Setting your environment variables tells Sponge which strategy file you want to use, and the URL for the  Pillar  instance you are pushing data to.  PILLAR_URL=http://192.168.99.100:8080\nSTRATEGY_CONF=/strategy/strategy_psql.json\n\n# DATABASE\n# (optional if you want to overwrite strategy file values)\nDB_database=  \nDB_username=  \nDB_password=  \nDB_host=  \nDB_port=  \n\n# WEB SERVICE\n# (optional if you want to overwrite strategy file values)\nWS_appkey=  \nWS_endpoint=  \nWS_records=  \nWS_pagination=  \nWS_useragent=  \nWS_attributes=    Required edits:   STRATEGY_CONF : Specifies the path to your strategy.json file.  PILLAR_URL : Specifies the URL where your Pillar instance is running. If you installed Pillar locally from source, this will probably be  http://localhost:8080 .", 
            "title": "Edit env.list"
        }, 
        {
            "location": "/developer/sponge/#running-the-container", 
            "text": "Spinning up the container will start importing everything setup in the  strategy file .  docker run --env-file env.list -d sponge", 
            "title": "Running the container"
        }, 
        {
            "location": "/developer/sponge/#packages-included-in-sponge", 
            "text": "Strategy  reads the translations file.  Source  performs the extraction of data from the external data source.  Fiddler  performs the transformation of data.  Coral  sends data to Pillar.  Sponge  ties all the pieces together.", 
            "title": "Packages included in Sponge"
        }, 
        {
            "location": "/developer/sponge/#strategy", 
            "text": "import  github.com/coralproject/sponge/pkg/strategy   The Strategy package reads in the external  strategy JSON file  and creates a structure containing translation information.", 
            "title": "Strategy"
        }, 
        {
            "location": "/developer/sponge/#variables", 
            "text": "var pillarURL string : URL that points to the Pillar instance, where the data will be sent.  This is initialized by the  PILLAR_URL  environment variable.    var uuid string : Universally Unique Identifier used for the logs.   To read more about strategy JSON files, you can read  our section on strategy files .", 
            "title": "Variables"
        }, 
        {
            "location": "/developer/sponge/#source", 
            "text": "import  github.com/coralproject/sponge/pkg/source   The Source package contains the drivers that we use to connect to the external source and retrieve data. The credentials for the external data source are set up in the  strategy file .", 
            "title": "Source"
        }, 
        {
            "location": "/developer/sponge/#variables_1", 
            "text": "var strategy str.Strategy : Holds the credentials for the external source, as well as all the entities that need to be extracted.  var uuid string : Universally Unique Identifier used for the logs.  var credential str.Credential : Credential for the external source (database or web service).", 
            "title": "Variables"
        }, 
        {
            "location": "/developer/sponge/#sourcer-interface", 
            "text": "This is the interface that needs to be implemented by any driver that connects to an external data source.", 
            "title": "Sourcer interface"
        }, 
        {
            "location": "/developer/sponge/#func-getdata", 
            "text": "GetData(string, *Options) ([]map[string]interface{}, error)  Returns all the data (query by options in Options) in the format  []map[string]interface{}", 
            "title": "func GetData"
        }, 
        {
            "location": "/developer/sponge/#func-iswebservice", 
            "text": "IsWebService() bool  Returns true if the implementation of Sourcer is a web service.", 
            "title": "func IsWebService"
        }, 
        {
            "location": "/developer/sponge/#func-new", 
            "text": "func New(d string) (Sourcer, error)  Returns a structure with the connection to the external source that implements the interface Sourcer.", 
            "title": "func New"
        }, 
        {
            "location": "/developer/sponge/#func-getentities", 
            "text": "func GetEntities() ([]string, error)  Gets all of the entity names from the external data source.", 
            "title": "func GetEntities"
        }, 
        {
            "location": "/developer/sponge/#func-getforeignentity", 
            "text": "func GetForeignEntity(name string) string  Gets a single foreign entity s name.", 
            "title": "func GetforeignEntity"
        }, 
        {
            "location": "/developer/sponge/#mysql-driver", 
            "text": "The mySQL driver is contained in the  mysql.go  file. It has a mySQL struct that implements the Sourcer interface, and enables data extraction from a mySQL database.", 
            "title": "mySQL driver"
        }, 
        {
            "location": "/developer/sponge/#postgresql-driver", 
            "text": "The PostgreSQL driver is contained in the  postgresql.go  file. It has a PostgreSQL struct that implements the Sourcer interface, and enables data extraction from a PostgreSQL database.", 
            "title": "PostgreSQL driver"
        }, 
        {
            "location": "/developer/sponge/#mongodb-driver", 
            "text": "The MongoDB driver is contained in the  mongodb.go  file. It has a MongoDB struct that implements the Sourcer interface, and enables data extraction from a MongoDB database.", 
            "title": "MongoDB driver"
        }, 
        {
            "location": "/developer/sponge/#api-driver", 
            "text": "The API driver is contained in the  api.go  file. It has an API struct that implements the Sourcer interface, and enables data extraction from an API interface.", 
            "title": "API driver"
        }, 
        {
            "location": "/developer/sponge/#how-to-add-a-new-source", 
            "text": "Currently, we offer the four drivers listed above (mySQL, PostgreSQL, MongoDB, and REST API). If you need to add a new type of external source, you can write your own driver. To write your own driver, you will implement the Sourcer interface for your type of external data source.", 
            "title": "How to add a new source"
        }, 
        {
            "location": "/developer/sponge/#fiddler", 
            "text": "import  github.com/coralproject/sponge/pkg/fiddler   The Fiddler package performs the translation from the external database schema into Coral s database schema.", 
            "title": "Fiddler"
        }, 
        {
            "location": "/developer/sponge/#variables_2", 
            "text": "strategy   str.Strategy  Holds the translation, in JSON form, to apply to the data.  dateLayout string  Date Layout as specified in the strategy file.  uuid string  Universally Unique Identifier used for the logs.", 
            "title": "Variables"
        }, 
        {
            "location": "/developer/sponge/#functions", 
            "text": "", 
            "title": "Functions"
        }, 
        {
            "location": "/developer/sponge/#func-getid", 
            "text": "func GetID(modelName string) string  Returns the field that is the identifier for that model", 
            "title": "func GetID"
        }, 
        {
            "location": "/developer/sponge/#func-getcollections", 
            "text": "func GetCollections() []string  Returns the names of all the collections in the strategy file.", 
            "title": "func GetCollections"
        }, 
        {
            "location": "/developer/sponge/#func-transformrow", 
            "text": "func TransformRow(row map[string]interface{}, coralName string) (interface{}, []map[string]interface{}, error)  Applies the coral schema to a row of data from the external source.", 
            "title": "func TransformRow"
        }, 
        {
            "location": "/developer/sponge/#coral", 
            "text": "Note : The  Coral  package is not to be confused with the Coral ecosystem as a whole. In this instance, this is merely the name of a package included in the Sponge app.  import  github.com/coralproject/sponge/pkg/coral   Coral interacts with Pillar endpoints to import data into the Coral system.", 
            "title": "Coral"
        }, 
        {
            "location": "/developer/sponge/#constants", 
            "text": "retryTimes int    = 3  Determines how many times to retry communication with Pillar, if it initially fails.  methodGet  string = \"GET\"  methodPost string = \"POST\"", 
            "title": "Constants"
        }, 
        {
            "location": "/developer/sponge/#variables_3", 
            "text": "endpoints map[string]string   endpoints  is a map containing all of the services where we can send data. Right now, that is only Pillar.  uuid string  Universally Unique Identifier used for the logs.  str  strategy.Strategy  Holds the translation, in JSON form, to apply to the data.", 
            "title": "Variables"
        }, 
        {
            "location": "/developer/sponge/#functions_1", 
            "text": "", 
            "title": "Functions"
        }, 
        {
            "location": "/developer/sponge/#func-addrow", 
            "text": "func AddRow(data map[string]interface{}, tableName string) error  Adds data to the collection  tableName .", 
            "title": "func AddRow"
        }, 
        {
            "location": "/developer/sponge/#func-createindex", 
            "text": "func CreateIndex(collection string) error  Calls the service to create index for  collection .", 
            "title": "func CreateIndex"
        }, 
        {
            "location": "/developer/sponge/#sponge", 
            "text": "Note : The  Sponge  package is not to be confused with the Sponge app as a whole. In this instance, this is merely the name of a package included in the larger Sponge app.  import  github.com/coralproject/sponge/pkg/sponge   The Sponge package ties together all of the other packages, so that they all communicate and work with each other.", 
            "title": "Sponge"
        }, 
        {
            "location": "/developer/sponge/#constants_1", 
            "text": "VersionNumber = 0.1  Provides the version number of Sponge.", 
            "title": "Constants"
        }, 
        {
            "location": "/developer/sponge/#variables_4", 
            "text": "dbsource source.Sourcer  uuid     string  options  source.Options", 
            "title": "Variables"
        }, 
        {
            "location": "/developer/sponge/#functions_2", 
            "text": "", 
            "title": "Functions"
        }, 
        {
            "location": "/developer/sponge/#func-addoptions", 
            "text": "func AddOptions(limit int, offset int, orderby string, query string, types string, importonlyfailed bool, reportOnFailedRecords bool, reportdbfile string)  AddOptions  sets options for how Sponge will run. The options are:   Limit : Limit for the query.  Offset : Offset for the query.  Orderby :  Order by this field  Query :  We use this field if we want to specific a filter on WHERE for mySQL/PostgreSQL and Find for MongoDB.  Types : Specifies which entities to import (the default is  everything ).  Importonlyfailed : Import only the documents that are in the report.  ReportOnFailedRecords : Create a report with all the documents that failed the import.  Reportdbfile : Name of the file for the report on documents that fail the import.", 
            "title": "func AddOptions"
        }, 
        {
            "location": "/developer/sponge/#func-import", 
            "text": "func Import()  Gets data, transforms it and sends it to Pillar. It bases everything on the STRATEGY_CONF environment variable and the PILLAR_URL environment variable.", 
            "title": "func Import"
        }, 
        {
            "location": "/developer/sponge/#func-createindex_1", 
            "text": "func CreateIndex(collection string)  Creates index on the collection  collection . This feature creates indexes on the Coral database, depending on the data in the strategy file.  For example:  Index : [\n  {\n     name :  asset-url ,\n     keys : [ asseturl ],\n     unique :  true ,\n     dropdups :  true \n  }\n],  You can read more information at the  mongodb s create index definition .", 
            "title": "func CreateIndex"
        }, 
        {
            "location": "/developer/sponge/#strategy-files", 
            "text": "Strategy files are JSON configuration files that contain all the information Sponge needs to extract data from a source, translate it to the Coral schema, and send it on to Pillar and from there to the Coral MongoDB.  The external data sources we currently support are: PostgreSQL, MySQL, MongoDB, and REST APIs.  The strategy spec is still being refined. We have examples that you can view in the  examples directory .  Examples:   API example  MongoDB example  mySQL example  PostgreSQL example", 
            "title": "Strategy files"
        }, 
        {
            "location": "/developer/sponge/#fields-in-the-strategyjson-file", 
            "text": "", 
            "title": "Fields in the strategy.json file"
        }, 
        {
            "location": "/developer/sponge/#general-fields", 
            "text": "Name : The name of the strategy that we are describing.  Map : Contains all the information to map fields from the external data source to our local Coral database.  Foreign : Describes the type of external database source (for example,  mysql  or  mongodb ).  DateTimeFormat : Tells us how to parse date/time fields in the external data source. You should populate this field with the date and time of  2006 Mon Jan 2 15:04:05 , written in the format that appears in your external database.", 
            "title": "General fields"
        }, 
        {
            "location": "/developer/sponge/#entity-fields", 
            "text": "Entities  is a JSON object that describes all of the different entities in the Coral database, and how to perform the transformation for that entity.   Foreign : The name of the foreign entity.  Local : The collection into which we are importing this entity.  Priority : This is a number that specifies which entity to import first (the highest priority is 0).  OrderBy : The field to order the results by when querying the foreign source.  ID : The identifier field for the foreign entity. We use this field when we need to import only some records and not the whole entity.  Endpoint : This is the  Pillar endpoint URL  where we will push the data.  Fields : All the fields that are being mapped.  foreign : The name of the field in the foreign entity.  local : The name of the field in our local database.  relation : The relationship between the foreign field and the local one. We have the following options:  Passthrough : When the value is the same.  Source : When it needs to be added to our source struct for the local collection (the original identifiers have to go into source).  ParseTimeDate : When we need to parse the foreign value as date time.  Constant : When the local field should always be the same value. In this case we will have  foreign  blank and we will have other field called  value  with the value of the local field.  SubDocument : When the local field has an array of documents in one of the fields.  Status : When the field need to be translated based on the status map that is declared in that same strategy file for the entity.    Type : The type of the value we are converting.  String  Timedate", 
            "title": "Entity fields"
        }, 
        {
            "location": "/developer/sponge/#credentials", 
            "text": "This contains the credentials for the external data source. It could be a REST API or a database (MySQL, PostgreSQL or MongoDB).   adapter : This tells us which driver we need to use to extract data. Right now, the options available are  mysql ,  postgresql ,  mongodb , or  service .  type : Right now this is always  foreign , but in future it could tell us what type of credential this is.", 
            "title": "Credentials"
        }, 
        {
            "location": "/developer/sponge/#logging", 
            "text": "We are using (Ardanlabs Log s package)[https://github.com/ardanlabs/kit/tree/master/log] for all of the tools we are developing in Go.", 
            "title": "Logging"
        }, 
        {
            "location": "/developer/sponge/#logging-levels", 
            "text": "Dev : To be outputted in development environment only.  User  (prod): To be outputted in dev and production environments.", 
            "title": "Logging levels:"
        }, 
        {
            "location": "/developer/sponge/#all-logs-should-contain", 
            "text": "Context uuid to identify a particular execution (aka, run of Sponge or a Request/Response execution from a web server).  The name of the function that is executing.  A readable message including relevant data.   Logs should write to  stdout  so that they can be flexibly directed.", 
            "title": "All logs should contain:"
        }, 
        {
            "location": "/developer/sponge/#roadmap", 
            "text": "There are features we would like to incorporate into Sponge at a future date, but that we haven t yet prioritized into issues or releases.", 
            "title": "Roadmap"
        }, 
        {
            "location": "/developer/sponge/#api-import", 
            "text": "Pull data from HTTP(S) sources:   Disqus - https://disqus.com/api/docs/  Wordpress Core - https://codex.wordpress.org/XML-RPC_WordPress_API/Comments  Lyvewire - http://answers.livefyre.com/developers/api-reference/  Facebook - https://developers.facebook.com/docs/graph-api/reference/v2.5/comment", 
            "title": "API Import"
        }, 
        {
            "location": "/developer/sponge/#rate-limit-counter", 
            "text": "In order to protect source databases, we want to be able to throttle the number of queries that Sponge is making.   Keep a sliding count of how many requests were made in the past time frame based on the strategy.  Expose isOkToQuery() to determine if we are currently at the limit.  Each request will send a message to this routine each time a request is made.", 
            "title": "Rate Limit Counter"
        }, 
        {
            "location": "/developer/sponge/#synchronization", 
            "text": "An internal mechanism that regularly polls the source and imports any updates.", 
            "title": "Synchronization"
        }, 
        {
            "location": "/developer/sponge/#basic-polling-specification", 
            "text": "The main loop that keeps the data up to date.  Gets  slices  of records based on  updated_at  timestamps to account for changing records.  For each table or api in the strategy:   Ensure maximum rate limit is not met  Determine which slice of data to get next  Find the last updated timestamp in the  log collection  (or the collection itself?)    Use the strategy to request the slice (either db query or api call)  Update the rate limit counter    For each record returned  Check to ensure the document isn t already added  If not, add the document and kick off  import actions  If it s there, update the document  Update the  log collection", 
            "title": "Basic polling specification"
        }, 
        {
            "location": "/developer/xenia/", 
            "text": "Introduction\n\n\nXenia\n is a configurable service layer that publishes endpoints against \nMongoDB aggregation pipeline\n queries.\n\n\nAggregation pipelines are chainable, allowing for the output of one endpoint to be fed into the next. Xenia provides a request syntax to allow for this, giving the requesting application an added dimension of flexibility via query control.\n\n\nSimilarly, output documents from multiple pipelines can be bundled together. This is particularly useful in the noSQL/document database paradigm, in which joins are not natively supported.\n\n\nStraightforward query creation\n\n\nXenia moves the query logic out of the application code. Front end developers, data analysts, and anyone else familiar with the simple, declarative \nMongoDB aggregation syntax\n can adjust the data requests, and create or update endpoints.\n\n\nXenia recipes\n\n\nDuring a Hackathon event, one of the Coral Project developers put together a set of interactive Xenia recipes. You can view those and play around with them \nhere\n.\n\n\nXenia installation\n\n\nXenia is a configurable service layer that publishes endpoints against \nMongoDB aggregation pipeline queries\n.\n\n\nBefore you begin\n\n\nBefore you install Xenia, you will want to have the following installed.\n\n\nMongoDB\n\n\nYou can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nThere are \ninstructions on importing sample comment data into MongoDB here\n\n\nGo\n\n\nIf you want to install from source, you will need to have Go installed.\n\n\nYou can install \ninstall Go from their website\n. The \ninstallation and setup instructions\n on the Go website are quite good. Ensure that you have exported your $GOPATH environment variable, as detailed in the \ninstallation instructions\n.\n\n\nIf you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.\n\n\nexport GO15VENDOREXPERIMENT=1\n\n\n\n\nIf you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.\n\n\nObtaining the source code\n\n\nYou can install the source code via using the \ngo get\n command, or by manually cloning the code.\n\n\nUsing the go get command\n\n\ngo get github.com/coralproject/xenia\n\n\n\n\nIf you see a message about \nno buildable Go source files\n like the below, you can ignore it. It simply means that there are buildable source files in subdirectories, just not the uppermost xenia directory.\n\n\npackage github.com/coralproject/xenia: no buildable Go source files in [directory]\n\n\n\n\nCloning manually\n\n\nYou can also clone the code manually.\n\n\nmkdir $GOPATH/src/github.com/coralproject/xenia\ncd $GOPATH/src/github.com/coralproject/xenia\n\ngit clone https://github.com/coralproject/xenia.git\n\n\n\n\nSet up your environment variables\n\n\nThis tells Xenia which database you want to use, sets your port, and sets your database password.\n\n\nMake your own copy of the \nconfig/dev.cfg\n file (this edited cfg file will contain your own values for things like your database password, and will not be committed back to the repository if you are doing development work on Xenia). Call your config file whatever you like; we\nll call it \ncustom\n in this example.\n\n\ncd $GOPATH/src/github.com/coralproject/xenia\ncp config/dev.cfg config/custom.cfg\n\n\n\n\nEdit the environment variables to reflect your MongoDB setup.\n\nRemember, you\nre entering your password here, so be sure not to commit this file to the repository!\n\n\nexport XENIA_MONGO_HOST=localhost:27017\nexport XENIA_MONGO_USER=coral-user\nexport XENIA_MONGO_AUTHDB=coral\nexport XENIA_MONGO_DB=coral\n\nexport XENIA_LOGGING_LEVEL=1\nexport XENIA_HOST=:4000\n\n# Use to have the CLI tooling hit the web service.\nexport XENIA_WEB_HOST=\nexport XENIA_WEB_AUTH=\n\n# Set host to Anvil if configured.\n# export XENIA_ANVIL_HOST=https://HOST\n\n# Use to apply extra key:value pairs to the header\n# export XENIA_HEADERS=key:value,key:value\n\n# DO NOT PUSH TO REPO\nexport XENIA_MONGO_PASS=\n\n\n\n\nRequired edits:\n\n\n\n\nXENIA_MONGO_HOST\n: set to your MongoDB where you will be communicating with.\n\n\nIf you are running MongoDB locally on your machine, you should set this to \nlocalhost:27017\n.\n\n\nIf you are pointing to a MongoDB running on a server somewhere, set this to the IP address and port of your MongoDB.\n\n\n\n\n\n\nXENIA_MONGO_DB\n: the database you are running queries against (\ncoral\n).\n\n\nXENIA_MONGO_USER\n: your MongoDB username.\n\n\nXENIA_MONGO_PASS\n: the password for your MongoDB user.\n\n\nXENIA_MONGO_AUTHDB\n: the database you are authenticating against (in most cases, should be the same \ncoral\n database as XENIA_MONGO_DB).\n\n\n\n\nOptional edits:\n\n\n\n\nXENIA_WEB_HOST\n: this is required for the CLI tool. It is the address of the Xenia web service (i.e., an instance of Xenia that you are running on a server).\n\n\nIf you are running everything locally, comment this variable out. This means that the CLI tool will connect directly to your local database, instead of connecting to a running web service.\n\n\n\n\n\n\nXENIA_HOST\n: default is \n:4000\n if this variable is not set.\n\n\nXENIA_LOGGING_LEVEL\n: default is \n2\n if this variable is not set.\n\n\nXENIA_WEB_AUTH\n: your Anvil token, if you have Anvil authentication set up. If you do not have authentication set up, leave this commented out.\n\n\nXENIA_ANVIL_HOST\n: the URL to the Anvil host, if you have Anvil authentication set up. If you do not have authentication set up, leave this commented out.\n\n\nXENIA_HEADERS\n: leave this commented out.\n\n\n\n\nOnce you\nve finished editing, source your config file using the source command:\n\n\nsource $GOPATH/src/github.com/coralproject/xenia/config/custom.cfg\n\n\n\n\nBuild the CLI tool\n\n\nXenia has a CLI tool that allows you to manage endpoints and perform other actions.\n\n\nTo build the tool:\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia\ngo build\n\n\n\n\nNote: It is best to run with logging level 0 when using the xenia command:\n\n\nexport XENIA_LOGGING_LEVEL=0\n\n\n\n\nCreating a Xenia database for the first time\n\n\nIf you are running Xenia on a MongoDB database for the first time you will need the Xenia command line tool to set up the MongoDB for use with Xenia. The CLI tool will create collections and sets of indexes that you can use to execute queries: a sort of dictionary of pre-made queries for you to use.\n\n\n1) First cd into cmd/xenia directory (this contains the CLI tool):\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia\n\n\n\n\n2) Configure the database using \ndb create\n. The database.json file contains the information necessary to create the collections and indexes.\n\n\n./xenia db create -f scrdb/database.json\n\n\n\n\nExpected output:\n\n\nConfiguring MongoDB\nCreating collection query_sets\nCreating collection query_sets_history\nCreating collection query_scripts\nCreating collection query_scripts_history\nCreating collection query_masks\nCreating collection query_masks_history\nCreating collection query_regexs\nCreating collection query_regexs_history\n\n\n\n\nTroubleshooting note #1\n\n\nIf you get a response that contains \nERROR: Invalid DB provided\n, you may have an incorrectly set environment variable. If you are running everything locally and using a local MongoDB, use \nprintev\n to see if \nXENIA_WEB_HOST\n is set:\n\n\nprintenv XENIA_WEB_HOST\n\n\n\n\nIf you are using a local MongoDB, this should not return a value. If it does return a value, unset the variable using \nunset\n, and then try step 2 again:\n\n\nunset XENIA_WEB_HOST\n\n\n\n\nTroubleshooting note #2\n\n\nInstead of the expected output shown above, you may see something like:\n\n\nConfiguring MongoDB\nCreating collection query_sets\nERROR: collection already exists\n\n\n\n\nThat\ns okay! It means that your database is already set up with Xenia. Perhaps you imported data that already had configured collections set up. Continue on to step 3.\n\n\n3) Load all the existing queries:\n\n\n./xenia query upsert -p scrquery\n\n\n\n\nExpected output:\n\n\nConfiguring MongoDB\nUpserting Set : Path[scrquery]\nUpserting Set : Upserted\n\n\n\n\n4) Load all the existing masks:\n\n\n./xenia mask upsert -p scrmask\n\n\n\n\nExpected output:\n\n\nConfiguring MongoDB\nUpserting Set : Path[scrquery]\nUpserting Set : Upserted\n\n\n\n\n5) Load all the existing regexes:\n\n\n./xenia regex upsert -p scrregex\n\n\n\n\nExpected output:\n\n\nConfiguring MongoDB\nUpserting Regex : Path[scrregex]\nUpserting Regex : Upserted\n\n\n\n\n6) That\ns it! If you are using MongoChef, you should be able to see your newly created collections, which will look something like this:\n\n\n\n\nRun the web service\n\n\n1) First cd into the directory containing the web service, xeniad (the Xenia daemon):\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xeniad\n\n\n\n\n2) Build the Xenia web service:\n\n\ngo build\n\n\n\n\n3) Run the web service:\n\n\n./xeniad\n\n\n\n\nExpected output:\n\n\n2016/06/08 10:26:38 app.go:173: USER : startup : Init :\n\nConfig Settings:\nMONGO_USER=coral-user\nMONGO_AUTHDB=coral\nMONGO_DB=coral\nHOST=:4000\nLOGGING_LEVEL=1\nMONGO_HOST=localhost:27017\n\n2016/06/08 10:26:38 main.go:24: USER : startup : Init : Revision     : \nunknown\n\n2016/06/08 10:26:38 main.go:25: USER : startup : Init : Version      : \nunknown\n\n2016/06/08 10:26:38 main.go:26: USER : startup : Init : Build Date   : \nunknown\n\n2016/06/08 10:26:38 main.go:27: USER : startup : Init : Int Version  : \n201606081030\n\n2016/06/08 10:26:38 main.go:28: USER : startup : Init : Go Version   : \ngo1.6.2\n\n2016/06/08 10:26:38 main.go:29: USER : startup : Init : Go Compiler  : \ngc\n\n2016/06/08 10:26:38 main.go:30: USER : startup : Init : Go ARCH      : \namd64\n\n2016/06/08 10:26:38 main.go:31: USER : startup : Init : Go OS        : \ndarwin\n\n\n\n\n\n4) You can test your web service by going to the following URL in your browser: \nhttp://localhost:4000/1.0/query\n.\n\n\nIn your browser, you will see some JSON displayed. In your terminal, you should see something like:\n\n\n2016/06/08 13:30:58 app.go:104: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : Request : Started : Method[GET] URL[/1.0/query] RADDR[[::1]:62121]\n2016/06/08 13:30:58 context.go:65: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : api : Respond : Started : Code[200]\n2016/06/08 13:30:58 context.go:72: USER : startup : api : Respond : Setting user headers : Access-Control-Allow-Origin:*\n2016/06/08 13:30:58 context.go:110: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : api : Respond : Completed\n2016/06/08 13:30:58 app.go:126: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : Request : Completed : Status[200] Duration[46.497305ms]\n\n\n\n\nTroubleshooting\n\n\n\n\nAuthorization\n\n\nXenia API\n\n\nThis section is under construction, and is not currently complete.\n\n\nEndpoints\n\n\nIf you set the authorization header properly in your browser (TODO) you can run the following endpoints.\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/1.0/query\n\n\nGET\n\n\nGet a list of configured queries\n\n\n\n\n\n\n/1.0/query/basic\n\n\nGET\n\n\nGet the query set document for the \nbasic\n query set\n\n\n\n\n\n\n/1.0/exec/basic\n\n\nGET\n\n\nExecute the query for the \nbasic\n query set\n\n\n\n\n\n\n/1.0/exec/basic_var\n\n\nGET\n\n\nExecute the query for the \nbasic_var\n query set with variables\n\n\n\n\n\n\n/1.0/exec\n\n\nPOST\n\n\nExecute a dynamic query set\n\n\n\n\n\n\n\n\nGet a list of configured queries\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/query\n\n\nGET\n\n\nGet a list of configured queries\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttp://localhost:4000/1.0/query\n\n\n\n\nExample response\n\n\n[\nbasic\n,\nbasic_var\n,\ntop_commenters_by_count\n]\n\n\n\n\nGet the query set document for the \nbasic\n query set\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/query/basic\n\n\nGET\n\n\nGet the query set document for the \nbasic\n query set\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttp://localhost:4000/1.0/query/basic\n\n\n\n\nExample response\n\n\n{\n   \nname\n:\nQTEST_basic\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n42021\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\n\n\n\nExecute the query for the \nbasic\n query set\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/query\n\n\nGET\n\n\nExecute the query for the basic query set\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttp://localhost:4000/1.0/exec/basic\n\n\n\n\nset:\n\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n42021\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\n\n\n\nExample response\n\n\n{\n  \nresults\n:[\n    {\n      \nName\n:\nbasic\n,\n      \nDocs\n:[\n        {\n          \nname\n:\nC14 - Pasco County Buoy, FL\n\n        }\n      ]\n    }\n  ],\n  \nerror\n:false\n}\n\n\n\n\nExecute the query for the \nbasic_var\n query set with variables\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/exec/basic_var\n\n\nGET\n\n\nExecute the query for the \nbasic_var\n query set with variables\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nRequired?\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nstation_id\n\n\nY\n\n\nTag ID\n\n\n\n\n\n\n\n\nGET\nhttp://localhost:4000/1.0/exec/basic_var?station_id=42021\n\nset:\n\n{\n   \nname\n:\nbasic_var\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasicVar\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n#string:station_id\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\noutput:\n\n{\n  \nresults\n:[\n    {\n      \nName\n:\nbasic_var\n,\n      \nDocs\n:[\n        {\n          \nname\n:\nC14 - Pasco County Buoy, FL\n\n        }\n      ]\n    }\n  ],\n  \nerror\n:false\n}\n\n\n\n\nExecute a dynamic query set\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/exec\n\n\nPOST\n\n\nExecute a dynamic query set\n\n\n\n\n\n\n\n\nPOST\nhttp://localhost:4000/1.0/exec\n\nPost Data:\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n42021\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\n\n\n\nQuery management with the command line tool\n\n\nUsing the Xenia command line tool you can manage query sets.\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia\n\n\n\n\nGet a list of saved queries:\n\n\n./xenia query list\n\noutput:\n\nbasic\nbasic_var\ntop_commenters_by_count\n\n\n\n\nLook at the details of a query:\n\n\n./xenia query get -n basic\n\noutput:\n\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n42021\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\n\n\n\nExecute a query:\n\n\n./xenia query exec -n basic\n\noutput:\n\n{\n  \nresults\n:[\n    {\n      \nName\n:\nbasic\n,\n      \nDocs\n:[\n        {\n          \nname\n:\nC14 - Pasco County Buoy, FL\n\n        }\n      ]\n    }\n  ],\n  \nerror\n:false\n}\n\n\n\n\nAdd or update a query for use:\n\n\n./xenia query upsert -p ./scrquery/basic_var.json\n\noutput:\n\nUpserting Query : Path[./scrquery/basic_var.json]\n\n\n\n\nBy convention, we store core query scripts in the \n/xenia/cmd/xenia/scrquery\n folder.  As we develop Coral features, store the JSON files there so other developers can use them (eventually, groups of query sets will be refactored to another location, but that\ns the right folder for the time being).\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia/scrquery\nls\n\n\n\n\nDirect Mongo access (optional)\n\n\nYou can look in the db at existing queries:\n\n\nmongo [flags to connect to your server]\nuse coral (or your databasename)\ndb.query_sets.find()\n\n\n\n\nWriting Sets\n\n\nWriting a set\n is essentially about creating a MongoDB aggregation pipeline. Xenia has built on top of this by providing extended functionality to make MongoDB more powerful.\n\n\nHere is a multi query set with variable substitution and date processing:\n\n\nGET\nhttp://localhost:4000/1.0/exec/basic?station_id=42021\n\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\nShows a basic multi result query.\n,\n   \nenabled\n:true,\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_bill\n,\n         \nreturn\n:true,\n         \nscripts\n:[\n            {\n$match\n: {\nstation_id\n : \n#station_id#\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      },\n      {\n         \nname\n:\nTime\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_bill\n,\n         \nreturn\n:true,\n         \nscripts\n:[\n            {\n$match\n: {\ncondition.date\n : {\n$gt\n: \n#date:2013-01-01T00:00:00.000Z\n}}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n            {\n$limit\n: 2}\n         ]\n      }\n   ]\n}\n\n\n\n\nHere is the list of commands that exist for variable substitution.\n\n\n{\nfield\n: \n#cmd:variable\n}\n\n// Basic commands.\nBefore: {\nfield\n: \n#number:variable_name\n}      After: {\nfield\n: 1234}\nBefore: {\nfield\n: \n#string:variable_name\n}      After: {\nfield\n: \nvalue\n}\nBefore: {\nfield\n: \n#date:variable_name\n}        After: {\nfield\n: time.Time}\nBefore: {\nfield\n: \n#objid:variable_name\n}       After: {\nfield\n: mgo.ObjectId}\nBefore: {\nfield\n: \n#regex:/pattern/{options}\n}  After: {\nfield\n: bson.RegEx}\n\n// data command can index into saved results.\nBefore: {\nfield\n : {\n$in\n: \n#data.*:list.station_id\n}}}   After: [{\nstation_id\n:\n42021\n}]\nBefore: {\nfield\n: \n#data.0:doc.station_id\n}               After: {\nfield\n: \n23453\n}\n\n// time command manipulates the current time.\nBefore: {\nfield\n: #time:0}                 After: {\nfield\n: time.Time(Current Time)}\nBefore: {\nfield\n: #time:-3600}             After: {\nfield\n: time.Time(3600 seconds in the past)}\nBefore: {\nfield\n: #time:3m}                After: {\nfield\n: time.Time(3 minutes in the future)}\n\nPossible duration types. Default is seconds if not provided.\n\nns\n: Nanosecond\n\nus\n: Microsecond\n\nms\n: Millisecond\n\ns\n : Second\n\nm\n : Minute\n\nh\n : Hour\n\n\n\n\nYou can save the result of one query for later use by the next.\n\n\nGET\nhttp://localhost:4000/1.0/exec/basic_save\n\n{\n   \nname\n:\nbasic_save\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nget_id_list\n,\n         \ndesc\n: \nGet the list of id's\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:false,\n         \ncommands\n:[\n            {\n$project\n: {\n_id\n: 0, \nstation_id\n: 1}},\n            {\n$limit\n: 5}\n            {\n$save\n: {\n$map\n: \nlist\n}}\n         ]\n      },\n      {\n         \nname\n:\nretrieve_stations\n,\n         \ndesc\n: \nRetrieve the list of stations\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : {\n$in\n: \n#data.*:list.station_id\n}}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n         ]\n      }\n   ]\n}\n\n\n\n\nThe \n$save\n command is an Xenia extension and currently only \n$map\n is supported.\n\n\n{\n$save\n: {\n$map\n: \nlist\n}}\n\n\n\n\nThe result will be saved in a map under the name \nlist\n.\n\n\nThe second query is using the \n#data\n command. The data command has two options. Use can use \n#data.*\n or \n#data.Idx\n.\n\n\nUse the \n*\n operator when you need an array. In this example we need to support an \n$in\n command:\n\n\n{\n   \nname\n:\nretrieve_stations\n,\n   \ndesc\n: \nRetrieve the list of stations\n,\n   \ntype\n:\npipeline\n,\n   \ncollection\n:\ntest_xenia_data\n,\n   \nreturn\n:true,\n   \ncommands\n:[\n      {\n$match\n: {\nstation_id\n : {\n$in\n: \n#data.*:list.station_id\n}}},\n      {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n   ]\n}\n\nWhen you need an array to be substituted.\nBefore: {\nfield\n : {\n$in\n: \n#data.*:list.station_id\n}}}\nAfter : {\nfield\n : {\n$in\n: [\n42021\n]}}\n    dataOp : \n*\n\n    lookup : \nlist.station_id\n\n    results: {\nlist\n: [{\nstation_id\n:\n42021\n}]}\n\n\n\n\nUse the index operator when you need a single value. Specify which document in the array of documents you want to select:\n\n\n\n{\n   \nname\n:\nretrieve_stations\n,\n   \ndesc\n: \nRetrieve the list of stations\n,\n   \ntype\n:\npipeline\n,\n   \ncollection\n:\ntest_xenia_data\n,\n   \nreturn\n:true,\n   \ncommands\n:[\n      {\n$match\n: {\nstation_id\n : \n#data.0:list.station_id\n}},\n      {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n   ]\n}\n\nWhen you need a single value to be substituted, select an index.\nBefore: {\nfield\n : \n#data.0:list.station_id\n}\nAfter : {\nfield\n : \n42021\n}\n    dataOp : 0\n    lookup : \nlist.station_id\n\n    results: {\nlist\n: [{\nstation_id\n:\n42021\n}, {\nstation_id\n:\n23567\n}]}\n\n\n\n\nYou can also replace field names in the query commands.\n\n\nVariables\n{\n  \ncond\n: \ncondition\n,\n  \ndt\n: \ndate\n\n}\n\nQuery Set\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\nShows field substitution.\n,\n   \nenabled\n:true,\n   \nqueries\n:[\n      {\n         \nname\n:\nTime\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_bill\n,\n         \nreturn\n:true,\n         \nscripts\n:[\n            {\n$match\n: {\n{cond}.{dt}\n : {\n$gt\n: \n#date:2013-01-01T00:00:00.000Z\n}}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n            {\n$limit\n: 2}\n         ]\n      }\n   ]\n}\n\n\n\n\nTesting\n\n\nYou can run tests in the \napp\n and \npkg\n folder.\n\n\nIf you plan to run tests in parallel, use this command:\n\n\ngo test -cpu 1 ./...\n\n\n\n\nYou can always run individual tests in each package using simply:\n\n\ngo test\n\n\n\n\nDo not run tests in the vendor folder.", 
            "title": "Xenia"
        }, 
        {
            "location": "/developer/xenia/#introduction", 
            "text": "Xenia  is a configurable service layer that publishes endpoints against  MongoDB aggregation pipeline  queries.  Aggregation pipelines are chainable, allowing for the output of one endpoint to be fed into the next. Xenia provides a request syntax to allow for this, giving the requesting application an added dimension of flexibility via query control.  Similarly, output documents from multiple pipelines can be bundled together. This is particularly useful in the noSQL/document database paradigm, in which joins are not natively supported.", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/xenia/#straightforward-query-creation", 
            "text": "Xenia moves the query logic out of the application code. Front end developers, data analysts, and anyone else familiar with the simple, declarative  MongoDB aggregation syntax  can adjust the data requests, and create or update endpoints.", 
            "title": "Straightforward query creation"
        }, 
        {
            "location": "/developer/xenia/#xenia-recipes", 
            "text": "During a Hackathon event, one of the Coral Project developers put together a set of interactive Xenia recipes. You can view those and play around with them  here .", 
            "title": "Xenia recipes"
        }, 
        {
            "location": "/developer/xenia/#xenia-installation", 
            "text": "Xenia is a configurable service layer that publishes endpoints against  MongoDB aggregation pipeline queries .", 
            "title": "Xenia installation"
        }, 
        {
            "location": "/developer/xenia/#before-you-begin", 
            "text": "Before you install Xenia, you will want to have the following installed.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/developer/xenia/#mongodb", 
            "text": "You can find instructions on installing MongoDB  on the MongoDB website .  There are  instructions on importing sample comment data into MongoDB here", 
            "title": "MongoDB"
        }, 
        {
            "location": "/developer/xenia/#go", 
            "text": "If you want to install from source, you will need to have Go installed.  You can install  install Go from their website . The  installation and setup instructions  on the Go website are quite good. Ensure that you have exported your $GOPATH environment variable, as detailed in the  installation instructions .  If you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.  export GO15VENDOREXPERIMENT=1  If you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.", 
            "title": "Go"
        }, 
        {
            "location": "/developer/xenia/#obtaining-the-source-code", 
            "text": "You can install the source code via using the  go get  command, or by manually cloning the code.", 
            "title": "Obtaining the source code"
        }, 
        {
            "location": "/developer/xenia/#using-the-go-get-command", 
            "text": "go get github.com/coralproject/xenia  If you see a message about  no buildable Go source files  like the below, you can ignore it. It simply means that there are buildable source files in subdirectories, just not the uppermost xenia directory.  package github.com/coralproject/xenia: no buildable Go source files in [directory]", 
            "title": "Using the go get command"
        }, 
        {
            "location": "/developer/xenia/#cloning-manually", 
            "text": "You can also clone the code manually.  mkdir $GOPATH/src/github.com/coralproject/xenia\ncd $GOPATH/src/github.com/coralproject/xenia\n\ngit clone https://github.com/coralproject/xenia.git", 
            "title": "Cloning manually"
        }, 
        {
            "location": "/developer/xenia/#set-up-your-environment-variables", 
            "text": "This tells Xenia which database you want to use, sets your port, and sets your database password.  Make your own copy of the  config/dev.cfg  file (this edited cfg file will contain your own values for things like your database password, and will not be committed back to the repository if you are doing development work on Xenia). Call your config file whatever you like; we ll call it  custom  in this example.  cd $GOPATH/src/github.com/coralproject/xenia\ncp config/dev.cfg config/custom.cfg  Edit the environment variables to reflect your MongoDB setup. Remember, you re entering your password here, so be sure not to commit this file to the repository!  export XENIA_MONGO_HOST=localhost:27017\nexport XENIA_MONGO_USER=coral-user\nexport XENIA_MONGO_AUTHDB=coral\nexport XENIA_MONGO_DB=coral\n\nexport XENIA_LOGGING_LEVEL=1\nexport XENIA_HOST=:4000\n\n# Use to have the CLI tooling hit the web service.\nexport XENIA_WEB_HOST=\nexport XENIA_WEB_AUTH=\n\n# Set host to Anvil if configured.\n# export XENIA_ANVIL_HOST=https://HOST\n\n# Use to apply extra key:value pairs to the header\n# export XENIA_HEADERS=key:value,key:value\n\n# DO NOT PUSH TO REPO\nexport XENIA_MONGO_PASS=  Required edits:   XENIA_MONGO_HOST : set to your MongoDB where you will be communicating with.  If you are running MongoDB locally on your machine, you should set this to  localhost:27017 .  If you are pointing to a MongoDB running on a server somewhere, set this to the IP address and port of your MongoDB.    XENIA_MONGO_DB : the database you are running queries against ( coral ).  XENIA_MONGO_USER : your MongoDB username.  XENIA_MONGO_PASS : the password for your MongoDB user.  XENIA_MONGO_AUTHDB : the database you are authenticating against (in most cases, should be the same  coral  database as XENIA_MONGO_DB).   Optional edits:   XENIA_WEB_HOST : this is required for the CLI tool. It is the address of the Xenia web service (i.e., an instance of Xenia that you are running on a server).  If you are running everything locally, comment this variable out. This means that the CLI tool will connect directly to your local database, instead of connecting to a running web service.    XENIA_HOST : default is  :4000  if this variable is not set.  XENIA_LOGGING_LEVEL : default is  2  if this variable is not set.  XENIA_WEB_AUTH : your Anvil token, if you have Anvil authentication set up. If you do not have authentication set up, leave this commented out.  XENIA_ANVIL_HOST : the URL to the Anvil host, if you have Anvil authentication set up. If you do not have authentication set up, leave this commented out.  XENIA_HEADERS : leave this commented out.   Once you ve finished editing, source your config file using the source command:  source $GOPATH/src/github.com/coralproject/xenia/config/custom.cfg", 
            "title": "Set up your environment variables"
        }, 
        {
            "location": "/developer/xenia/#build-the-cli-tool", 
            "text": "Xenia has a CLI tool that allows you to manage endpoints and perform other actions.  To build the tool:  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia\ngo build  Note: It is best to run with logging level 0 when using the xenia command:  export XENIA_LOGGING_LEVEL=0", 
            "title": "Build the CLI tool"
        }, 
        {
            "location": "/developer/xenia/#creating-a-xenia-database-for-the-first-time", 
            "text": "If you are running Xenia on a MongoDB database for the first time you will need the Xenia command line tool to set up the MongoDB for use with Xenia. The CLI tool will create collections and sets of indexes that you can use to execute queries: a sort of dictionary of pre-made queries for you to use.  1) First cd into cmd/xenia directory (this contains the CLI tool):  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia  2) Configure the database using  db create . The database.json file contains the information necessary to create the collections and indexes.  ./xenia db create -f scrdb/database.json  Expected output:  Configuring MongoDB\nCreating collection query_sets\nCreating collection query_sets_history\nCreating collection query_scripts\nCreating collection query_scripts_history\nCreating collection query_masks\nCreating collection query_masks_history\nCreating collection query_regexs\nCreating collection query_regexs_history", 
            "title": "Creating a Xenia database for the first time"
        }, 
        {
            "location": "/developer/xenia/#troubleshooting-note-1", 
            "text": "If you get a response that contains  ERROR: Invalid DB provided , you may have an incorrectly set environment variable. If you are running everything locally and using a local MongoDB, use  printev  to see if  XENIA_WEB_HOST  is set:  printenv XENIA_WEB_HOST  If you are using a local MongoDB, this should not return a value. If it does return a value, unset the variable using  unset , and then try step 2 again:  unset XENIA_WEB_HOST", 
            "title": "Troubleshooting note #1"
        }, 
        {
            "location": "/developer/xenia/#troubleshooting-note-2", 
            "text": "Instead of the expected output shown above, you may see something like:  Configuring MongoDB\nCreating collection query_sets\nERROR: collection already exists  That s okay! It means that your database is already set up with Xenia. Perhaps you imported data that already had configured collections set up. Continue on to step 3.  3) Load all the existing queries:  ./xenia query upsert -p scrquery  Expected output:  Configuring MongoDB\nUpserting Set : Path[scrquery]\nUpserting Set : Upserted  4) Load all the existing masks:  ./xenia mask upsert -p scrmask  Expected output:  Configuring MongoDB\nUpserting Set : Path[scrquery]\nUpserting Set : Upserted  5) Load all the existing regexes:  ./xenia regex upsert -p scrregex  Expected output:  Configuring MongoDB\nUpserting Regex : Path[scrregex]\nUpserting Regex : Upserted  6) That s it! If you are using MongoChef, you should be able to see your newly created collections, which will look something like this:", 
            "title": "Troubleshooting note #2"
        }, 
        {
            "location": "/developer/xenia/#run-the-web-service", 
            "text": "1) First cd into the directory containing the web service, xeniad (the Xenia daemon):  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xeniad  2) Build the Xenia web service:  go build  3) Run the web service:  ./xeniad  Expected output:  2016/06/08 10:26:38 app.go:173: USER : startup : Init :\n\nConfig Settings:\nMONGO_USER=coral-user\nMONGO_AUTHDB=coral\nMONGO_DB=coral\nHOST=:4000\nLOGGING_LEVEL=1\nMONGO_HOST=localhost:27017\n\n2016/06/08 10:26:38 main.go:24: USER : startup : Init : Revision     :  unknown \n2016/06/08 10:26:38 main.go:25: USER : startup : Init : Version      :  unknown \n2016/06/08 10:26:38 main.go:26: USER : startup : Init : Build Date   :  unknown \n2016/06/08 10:26:38 main.go:27: USER : startup : Init : Int Version  :  201606081030 \n2016/06/08 10:26:38 main.go:28: USER : startup : Init : Go Version   :  go1.6.2 \n2016/06/08 10:26:38 main.go:29: USER : startup : Init : Go Compiler  :  gc \n2016/06/08 10:26:38 main.go:30: USER : startup : Init : Go ARCH      :  amd64 \n2016/06/08 10:26:38 main.go:31: USER : startup : Init : Go OS        :  darwin   4) You can test your web service by going to the following URL in your browser:  http://localhost:4000/1.0/query .  In your browser, you will see some JSON displayed. In your terminal, you should see something like:  2016/06/08 13:30:58 app.go:104: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : Request : Started : Method[GET] URL[/1.0/query] RADDR[[::1]:62121]\n2016/06/08 13:30:58 context.go:65: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : api : Respond : Started : Code[200]\n2016/06/08 13:30:58 context.go:72: USER : startup : api : Respond : Setting user headers : Access-Control-Allow-Origin:*\n2016/06/08 13:30:58 context.go:110: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : api : Respond : Completed\n2016/06/08 13:30:58 app.go:126: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : Request : Completed : Status[200] Duration[46.497305ms]", 
            "title": "Run the web service"
        }, 
        {
            "location": "/developer/xenia/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/developer/xenia/#authorization", 
            "text": "", 
            "title": "Authorization"
        }, 
        {
            "location": "/developer/xenia/#xenia-api", 
            "text": "This section is under construction, and is not currently complete.", 
            "title": "Xenia API"
        }, 
        {
            "location": "/developer/xenia/#endpoints", 
            "text": "If you set the authorization header properly in your browser (TODO) you can run the following endpoints.     URL  HTTP Verb  Description      /1.0/query  GET  Get a list of configured queries    /1.0/query/basic  GET  Get the query set document for the  basic  query set    /1.0/exec/basic  GET  Execute the query for the  basic  query set    /1.0/exec/basic_var  GET  Execute the query for the  basic_var  query set with variables    /1.0/exec  POST  Execute a dynamic query set", 
            "title": "Endpoints"
        }, 
        {
            "location": "/developer/xenia/#get-a-list-of-configured-queries", 
            "text": "URL  HTTP Verb  Functionality      /1.0/query  GET  Get a list of configured queries", 
            "title": "Get a list of configured queries"
        }, 
        {
            "location": "/developer/xenia/#parameters", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/xenia/#example-call", 
            "text": "GET\nhttp://localhost:4000/1.0/query", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/xenia/#example-response", 
            "text": "[ basic , basic_var , top_commenters_by_count ]", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/xenia/#get-the-query-set-document-for-the-basic-query-set", 
            "text": "URL  HTTP Verb  Functionality      /1.0/query/basic  GET  Get the query set document for the  basic  query set", 
            "title": "Get the query set document for the basic query set"
        }, 
        {
            "location": "/developer/xenia/#parameters_1", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/xenia/#example-call_1", 
            "text": "GET\nhttp://localhost:4000/1.0/query/basic", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/xenia/#example-response_1", 
            "text": "{\n    name : QTEST_basic ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  42021 }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/xenia/#execute-the-query-for-the-basic-query-set", 
            "text": "URL  HTTP Verb  Functionality      /1.0/query  GET  Execute the query for the basic query set", 
            "title": "Execute the query for the basic query set"
        }, 
        {
            "location": "/developer/xenia/#parameters_2", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/xenia/#example-call_2", 
            "text": "GET\nhttp://localhost:4000/1.0/exec/basic  set:\n\n{\n    name : basic ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  42021 }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}", 
            "title": "Example call"
        }, 
        {
            "location": "/developer/xenia/#example-response_2", 
            "text": "{\n   results :[\n    {\n       Name : basic ,\n       Docs :[\n        {\n           name : C14 - Pasco County Buoy, FL \n        }\n      ]\n    }\n  ],\n   error :false\n}", 
            "title": "Example response"
        }, 
        {
            "location": "/developer/xenia/#execute-the-query-for-the-basic_var-query-set-with-variables", 
            "text": "URL  HTTP Verb  Functionality      /1.0/exec/basic_var  GET  Execute the query for the  basic_var  query set with variables", 
            "title": "Execute the query for the basic_var query set with variables"
        }, 
        {
            "location": "/developer/xenia/#parameters_3", 
            "text": "Name  Required?  Description      station_id  Y  Tag ID     GET\nhttp://localhost:4000/1.0/exec/basic_var?station_id=42021\n\nset:\n\n{\n    name : basic_var ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : BasicVar ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  #string:station_id }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}\n\noutput:\n\n{\n   results :[\n    {\n       Name : basic_var ,\n       Docs :[\n        {\n           name : C14 - Pasco County Buoy, FL \n        }\n      ]\n    }\n  ],\n   error :false\n}", 
            "title": "Parameters"
        }, 
        {
            "location": "/developer/xenia/#execute-a-dynamic-query-set", 
            "text": "URL  HTTP Verb  Functionality      /1.0/exec  POST  Execute a dynamic query set     POST\nhttp://localhost:4000/1.0/exec\n\nPost Data:\n{\n    name : basic ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  42021 }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}", 
            "title": "Execute a dynamic query set"
        }, 
        {
            "location": "/developer/xenia/#query-management-with-the-command-line-tool", 
            "text": "Using the Xenia command line tool you can manage query sets.  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia", 
            "title": "Query management with the command line tool"
        }, 
        {
            "location": "/developer/xenia/#get-a-list-of-saved-queries", 
            "text": "./xenia query list\n\noutput:\n\nbasic\nbasic_var\ntop_commenters_by_count", 
            "title": "Get a list of saved queries:"
        }, 
        {
            "location": "/developer/xenia/#look-at-the-details-of-a-query", 
            "text": "./xenia query get -n basic\n\noutput:\n\n{\n    name : basic ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  42021 }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}", 
            "title": "Look at the details of a query:"
        }, 
        {
            "location": "/developer/xenia/#execute-a-query", 
            "text": "./xenia query exec -n basic\n\noutput:\n\n{\n   results :[\n    {\n       Name : basic ,\n       Docs :[\n        {\n           name : C14 - Pasco County Buoy, FL \n        }\n      ]\n    }\n  ],\n   error :false\n}", 
            "title": "Execute a query:"
        }, 
        {
            "location": "/developer/xenia/#add-or-update-a-query-for-use", 
            "text": "./xenia query upsert -p ./scrquery/basic_var.json\n\noutput:\n\nUpserting Query : Path[./scrquery/basic_var.json]  By convention, we store core query scripts in the  /xenia/cmd/xenia/scrquery  folder.  As we develop Coral features, store the JSON files there so other developers can use them (eventually, groups of query sets will be refactored to another location, but that s the right folder for the time being).  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia/scrquery\nls", 
            "title": "Add or update a query for use:"
        }, 
        {
            "location": "/developer/xenia/#direct-mongo-access-optional", 
            "text": "You can look in the db at existing queries:  mongo [flags to connect to your server]\nuse coral (or your databasename)\ndb.query_sets.find()", 
            "title": "Direct Mongo access (optional)"
        }, 
        {
            "location": "/developer/xenia/#writing-sets", 
            "text": "Writing a set  is essentially about creating a MongoDB aggregation pipeline. Xenia has built on top of this by providing extended functionality to make MongoDB more powerful.  Here is a multi query set with variable substitution and date processing:  GET\nhttp://localhost:4000/1.0/exec/basic?station_id=42021\n\n{\n    name : basic ,\n    desc : Shows a basic multi result query. ,\n    enabled :true,\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_bill ,\n          return :true,\n          scripts :[\n            { $match : { station_id  :  #station_id# }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      },\n      {\n          name : Time ,\n          type : pipeline ,\n          collection : test_bill ,\n          return :true,\n          scripts :[\n            { $match : { condition.date  : { $gt :  #date:2013-01-01T00:00:00.000Z }}},\n            { $project : { _id : 0,  name : 1}},\n            { $limit : 2}\n         ]\n      }\n   ]\n}  Here is the list of commands that exist for variable substitution.  { field :  #cmd:variable }\n\n// Basic commands.\nBefore: { field :  #number:variable_name }      After: { field : 1234}\nBefore: { field :  #string:variable_name }      After: { field :  value }\nBefore: { field :  #date:variable_name }        After: { field : time.Time}\nBefore: { field :  #objid:variable_name }       After: { field : mgo.ObjectId}\nBefore: { field :  #regex:/pattern/{options} }  After: { field : bson.RegEx}\n\n// data command can index into saved results.\nBefore: { field  : { $in :  #data.*:list.station_id }}}   After: [{ station_id : 42021 }]\nBefore: { field :  #data.0:doc.station_id }               After: { field :  23453 }\n\n// time command manipulates the current time.\nBefore: { field : #time:0}                 After: { field : time.Time(Current Time)}\nBefore: { field : #time:-3600}             After: { field : time.Time(3600 seconds in the past)}\nBefore: { field : #time:3m}                After: { field : time.Time(3 minutes in the future)}\n\nPossible duration types. Default is seconds if not provided. ns : Nanosecond us : Microsecond ms : Millisecond s  : Second m  : Minute h  : Hour  You can save the result of one query for later use by the next.  GET\nhttp://localhost:4000/1.0/exec/basic_save\n\n{\n    name : basic_save ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : get_id_list ,\n          desc :  Get the list of id's ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :false,\n          commands :[\n            { $project : { _id : 0,  station_id : 1}},\n            { $limit : 5}\n            { $save : { $map :  list }}\n         ]\n      },\n      {\n          name : retrieve_stations ,\n          desc :  Retrieve the list of stations ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  : { $in :  #data.*:list.station_id }}},\n            { $project : { _id : 0,  name : 1}},\n         ]\n      }\n   ]\n}  The  $save  command is an Xenia extension and currently only  $map  is supported.  { $save : { $map :  list }}  The result will be saved in a map under the name  list .  The second query is using the  #data  command. The data command has two options. Use can use  #data.*  or  #data.Idx .  Use the  *  operator when you need an array. In this example we need to support an  $in  command:  {\n    name : retrieve_stations ,\n    desc :  Retrieve the list of stations ,\n    type : pipeline ,\n    collection : test_xenia_data ,\n    return :true,\n    commands :[\n      { $match : { station_id  : { $in :  #data.*:list.station_id }}},\n      { $project : { _id : 0,  name : 1}},\n   ]\n}\n\nWhen you need an array to be substituted.\nBefore: { field  : { $in :  #data.*:list.station_id }}}\nAfter : { field  : { $in : [ 42021 ]}}\n    dataOp :  * \n    lookup :  list.station_id \n    results: { list : [{ station_id : 42021 }]}  Use the index operator when you need a single value. Specify which document in the array of documents you want to select:  \n{\n    name : retrieve_stations ,\n    desc :  Retrieve the list of stations ,\n    type : pipeline ,\n    collection : test_xenia_data ,\n    return :true,\n    commands :[\n      { $match : { station_id  :  #data.0:list.station_id }},\n      { $project : { _id : 0,  name : 1}},\n   ]\n}\n\nWhen you need a single value to be substituted, select an index.\nBefore: { field  :  #data.0:list.station_id }\nAfter : { field  :  42021 }\n    dataOp : 0\n    lookup :  list.station_id \n    results: { list : [{ station_id : 42021 }, { station_id : 23567 }]}  You can also replace field names in the query commands.  Variables\n{\n   cond :  condition ,\n   dt :  date \n}\n\nQuery Set\n{\n    name : basic ,\n    desc : Shows field substitution. ,\n    enabled :true,\n    queries :[\n      {\n          name : Time ,\n          type : pipeline ,\n          collection : test_bill ,\n          return :true,\n          scripts :[\n            { $match : { {cond}.{dt}  : { $gt :  #date:2013-01-01T00:00:00.000Z }}},\n            { $project : { _id : 0,  name : 1}},\n            { $limit : 2}\n         ]\n      }\n   ]\n}", 
            "title": "Writing Sets"
        }, 
        {
            "location": "/developer/xenia/#testing", 
            "text": "You can run tests in the  app  and  pkg  folder.  If you plan to run tests in parallel, use this command:  go test -cpu 1 ./...  You can always run individual tests in each package using simply:  go test  Do not run tests in the vendor folder.", 
            "title": "Testing"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/", 
            "text": "Xenia Driver\n\n\nXenia-driver-js\n is a JavaScript library that performs queries to \nXenia\n from the browser, or from a Node.js application.\n\n\nExample data visualization\n\n\nDuring a Hackathon event, one of our Coral Project developers put together an example data visualization, built using the \nd3.js\n JavaScript library. You can view \nthe example here\n, and see the code the developer used \non GitHub\n.\n\n\nXenia Driver installation\n\n\n$ npm install --save xenia-driver\n\n\n\n\nImport and use\n\n\nimport XeniaDriver from 'xenia-driver'\n\n// Configure your instance\nconst xenia = XeniaDriver(baseUrl, {username: 'user', password: 'pass'})\n\n// Use the driver\nxenia()\n  .match({ 'category': 'sports' })\n  .include(['comments', 'name'])\n  .limit(14)\n  .skip(8)\n.join('my_collection')\n.exec().then(data =\n console.log(data.results))\n\n\n\n\nXenia Driver API\n\n\nList of queries\n\n\n\n\nXeniaDriver(baseURL, auth [, queryParams] [, reqParams])\n\n\naddQuery(queryData)\n\n\ncollection(name)\n\n\nexec(queryName, params)\n\n\ngetQueries()\n\n\ngetQuery(name)\n\n\nsaveQuery(name)\n\n\ndeleteQuery(name)\n\n\nlimit(n)\n\n\nskip(n)\n\n\nsample(n)\n\n\nproject(fields)\n\n\ninclude(fieldNames)\n\n\nexclude(fieldNames)\n\n\nmatch(query)\n\n\nredact(query)\n\n\nunwind(path, includeArrayIndex, preserveNullAndEmptyArrays)\n\n\ngroup(groups)\n\n\nsort(order)\n\n\njoin(collection, field, matchingField, name)\n\n\n\n\nXeniaDriver(baseURL, auth [, queryParams] [, reqParams])\n\n\nCreates a new \nXeniaDriver\n instance\n\n\n\n\nbaseURL\n (String) - Xenia server base url\n\n\nauth\n (String | Object) - basic authentication credentials. If it\ns a string it should be the Basic authentication value for the Authorization header\n\n\n[auth.username]\n (String) - Auth username\n\n\n[auth.password]\n (String) - Auth password\n\n\n[queryParams]\n (Object) - It can hold a Xenia raw query to perform before the rest of the queries\n\n\n[reqParams]\n (Object) - Add your own parameters to the request\n\n\n\n\nconst xenia = XeniaDriver('https://my-xenia-url.com', 'Basic kewlrgm;we4p3jtqpwfawmeklfdmdsadlm')\n\n\n\n\naddQuery(queryData)\n\n\nInitialize a query. When the xenia constructor runs it will call this function for you. Use it for adding more than one query in the same request.\n\n\n\n\n[queryData]\n (Object) - Provide the configuration for the new query\n\n\n\n\nxenia()\n  .limit(20).skip(10)\n  .addQuery().match({'name': 'John Doe'})\n  .exec().then(data =\n console.log(data))\n\n\n\n\ncollection(name)\n\n\nSet the current query collection\n\n\n\n\nname\n (String) - collection name\n\n\n\n\nxenia()\n  .collection('users')\n  .exclude(['_id'])\n  .exec().then(data =\n console.log(data))\n\n\n\n\nexec(queryName, params)\n\n\nExecutes the request\n\n\n\n\n[name]\n (string) - Executes a saved query by name\n\n\n[params]\n (Object) - Custom request parameters\n\n\n\n\nxenia().exec('my_saved_query').then(data =\n console.log(data))\n\n// Or\n\nxenia().limit(20).skip(10)\n  .exec().then(data =\n console.log(data))\n  .catch(err =\n console.log(err))\n\n\n\n\ngetQueries()\n\n\nGet a list of available queries\n\n\nxenia().getQueries().then(data =\n console.log(data))\n\n\n\n\ngetQuery(name)\n\n\nGet a specific query document\n\n\n\n\nname\n (String) - query name\n\n\n\n\nxenia().getQuery('my_query').then(data =\n console.log(data))\n\n\n\n\nsaveQuery(name)\n\n\nSave a new query\n\n\n\n\n[name]\n (String) - query name\n\n\n\n\nxenia()\n  .collection('users')\n  .limit(5).include(['name', 'avatar'])\n  .saveQuery('first users').then(data =\n console.log(data))\n\n\n\n\ndeleteQuery(name)\n\n\nDelete a query\n\n\n\n\n[name]\n (String) - query name\n\n\n\n\nxenia()\n  .deleteQuery('first users')\n  .then(data =\n console.log(data))\n\n\n\n\nlimit(n)\n\n\nLimit the amount of retrieved documents\n\n\n\n\n[n]\n (Number) - number of docs to retrieve, default: 20\n\n\n\n\nxenia().limit(15)\n\n\n\n\nskip(n)\n\n\nSkip the first n documents\n\n\n\n\n[n]\n (Number) - number of skipped docs, default: 0\n\n\n\n\nxenia().skip(12)\n\n\n\n\nsample(n)\n\n\nReturn a document sample from the collection\n\n\n\n\n[n]\n (Number) - number of sample docs, default: 20\n\n\n\n\nxenia().sample(50)\n\n\n\n\nproject(fields)\n\n\nInclude and exclude fields from the result using the $project aggregation pipeline operator. You\nll find out that \nXenia#include\n and \nXenia#exclude\n can be easier to use for most scenarios.\n\n\n\n\nfields\n (Object) - Aggregation fields object\n\n\n\n\nxenia()\n  .project({'name': true, '_id': false, 'comments': { 'country': true}})\n\n\n\n\ninclude(fieldNames)\n\n\nWhitelist retrieved fields\n\n\n\n\nfieldNames\n (Array) - fields you want to retrieve\n\n\n\n\nxenia().include(['name', 'avatar'])\n\n\n\n\nexclude(fieldNames)\n\n\nBlacklist retrieved fields\n\n\n\n\nfieldNames\n (Array) - fields you don\nt want to retrieve\n\n\n\n\nxenia().exclude(['age', 'gender'])\n\n\n\n\nmatch(query)\n\n\nPerforms a match command on the aggregation pipeline\n\n\n\n\nquery\n (Object) - Match parameters\n\n\n\n\nxenia().match({ 'name': 'John', 'status': { '$in' : ['user', 'admin']} })\n\n\n\n\nredact(query)\n\n\nPerforms a redact command on the aggregation pipeline\n\n\n\n\nquery\n (Object) - Redact parameters\n\n\n\n\nxenia().redact({ $cond: {\n  if: { $gt: [ { $size: { $setIntersection: [ \n$tags\n, userAccess ] } }, 0 ] },\n  then: \n$$DESCEND\n,\n  else: \n$$PRUNE\n\n}})\n\n\n\n\nunwind(path, includeArrayIndex, preserveNullAndEmptyArrays)\n\n\nPerforms a unwind command on the aggregation pipeline - Deconstructs an array field from the input documents to output a document for each element\n\n\n\n\npath\n (Object | String) - Field path\n\n\n[includeArrayIndex]\n (String) - arrayIndex name\n\n\n[preserveNullAndEmptyArrays]\n (Boolean) - preserve null and empty arrays, default false\n\n\n\n\nxenia().unwind('$comments')\n\n\n\n\ngroup(groups)\n\n\nGroup documents\n\n\n\n\ngroups\n (Object) - group object\n\n\n\n\nxenia().group({ _id : { month: { $month: '$date' } })\n\n\n\n\nsort(order)\n\n\nSort documents by fields\n\n\n\n\norder\n (Object|Array) - how to sort the data\n\n\n\n\nxenia().sort(['name', 1])\n\n// Or\n\nxenia.sort({'name': 1, 'statistics.comments.count': -1})\n\n\n\n\njoin(collection, field, matchingField, name)\n\n\nCreates a new query joining the actual one using the save method from Xenia\n\n\n\n\ncollection\n (String) - The collection you want to join\n\n\n[field]\n (String) - The matching field in the collection you want to join, default: _id\n\n\n[matchingField]\n (String) - The field to match in your actual collection, default: same as field parameter\n\n\n[name]\n (String) - The field name on the results, default: list\n\n\n\n\nxenia().collection('comments')\n.include(['body', 'asset_id']).limit(5)\n\n.join('assets', '_id', 'asset_id', 'asset')\n\n.include(['section']).exec()\n\n\n\n\nDevelopment\n\n\n$ npm start\n\n\n\nTest\n\n\n$ npm test", 
            "title": "Xenia Driver"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#xenia-driver", 
            "text": "Xenia-driver-js  is a JavaScript library that performs queries to  Xenia  from the browser, or from a Node.js application.", 
            "title": "Xenia Driver"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#example-data-visualization", 
            "text": "During a Hackathon event, one of our Coral Project developers put together an example data visualization, built using the  d3.js  JavaScript library. You can view  the example here , and see the code the developer used  on GitHub .", 
            "title": "Example data visualization"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#xenia-driver-installation", 
            "text": "$ npm install --save xenia-driver", 
            "title": "Xenia Driver installation"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#import-and-use", 
            "text": "import XeniaDriver from 'xenia-driver'\n\n// Configure your instance\nconst xenia = XeniaDriver(baseUrl, {username: 'user', password: 'pass'})\n\n// Use the driver\nxenia()\n  .match({ 'category': 'sports' })\n  .include(['comments', 'name'])\n  .limit(14)\n  .skip(8)\n.join('my_collection')\n.exec().then(data =  console.log(data.results))", 
            "title": "Import and use"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#xenia-driver-api", 
            "text": "", 
            "title": "Xenia Driver API"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#list-of-queries", 
            "text": "XeniaDriver(baseURL, auth [, queryParams] [, reqParams])  addQuery(queryData)  collection(name)  exec(queryName, params)  getQueries()  getQuery(name)  saveQuery(name)  deleteQuery(name)  limit(n)  skip(n)  sample(n)  project(fields)  include(fieldNames)  exclude(fieldNames)  match(query)  redact(query)  unwind(path, includeArrayIndex, preserveNullAndEmptyArrays)  group(groups)  sort(order)  join(collection, field, matchingField, name)", 
            "title": "List of queries"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#xeniadriverbaseurl-auth-queryparams-reqparams", 
            "text": "Creates a new  XeniaDriver  instance   baseURL  (String) - Xenia server base url  auth  (String | Object) - basic authentication credentials. If it s a string it should be the Basic authentication value for the Authorization header  [auth.username]  (String) - Auth username  [auth.password]  (String) - Auth password  [queryParams]  (Object) - It can hold a Xenia raw query to perform before the rest of the queries  [reqParams]  (Object) - Add your own parameters to the request   const xenia = XeniaDriver('https://my-xenia-url.com', 'Basic kewlrgm;we4p3jtqpwfawmeklfdmdsadlm')", 
            "title": "XeniaDriver(baseURL, auth [, queryParams] [, reqParams])"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#addqueryquerydata", 
            "text": "Initialize a query. When the xenia constructor runs it will call this function for you. Use it for adding more than one query in the same request.   [queryData]  (Object) - Provide the configuration for the new query   xenia()\n  .limit(20).skip(10)\n  .addQuery().match({'name': 'John Doe'})\n  .exec().then(data =  console.log(data))", 
            "title": "addQuery(queryData)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#collectionname", 
            "text": "Set the current query collection   name  (String) - collection name   xenia()\n  .collection('users')\n  .exclude(['_id'])\n  .exec().then(data =  console.log(data))", 
            "title": "collection(name)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#execqueryname-params", 
            "text": "Executes the request   [name]  (string) - Executes a saved query by name  [params]  (Object) - Custom request parameters   xenia().exec('my_saved_query').then(data =  console.log(data))\n\n// Or\n\nxenia().limit(20).skip(10)\n  .exec().then(data =  console.log(data))\n  .catch(err =  console.log(err))", 
            "title": "exec(queryName, params)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#getqueries", 
            "text": "Get a list of available queries  xenia().getQueries().then(data =  console.log(data))", 
            "title": "getQueries()"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#getqueryname", 
            "text": "Get a specific query document   name  (String) - query name   xenia().getQuery('my_query').then(data =  console.log(data))", 
            "title": "getQuery(name)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#savequeryname", 
            "text": "Save a new query   [name]  (String) - query name   xenia()\n  .collection('users')\n  .limit(5).include(['name', 'avatar'])\n  .saveQuery('first users').then(data =  console.log(data))", 
            "title": "saveQuery(name)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#deletequeryname", 
            "text": "Delete a query   [name]  (String) - query name   xenia()\n  .deleteQuery('first users')\n  .then(data =  console.log(data))", 
            "title": "deleteQuery(name)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#limitn", 
            "text": "Limit the amount of retrieved documents   [n]  (Number) - number of docs to retrieve, default: 20   xenia().limit(15)", 
            "title": "limit(n)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#skipn", 
            "text": "Skip the first n documents   [n]  (Number) - number of skipped docs, default: 0   xenia().skip(12)", 
            "title": "skip(n)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#samplen", 
            "text": "Return a document sample from the collection   [n]  (Number) - number of sample docs, default: 20   xenia().sample(50)", 
            "title": "sample(n)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#projectfields", 
            "text": "Include and exclude fields from the result using the $project aggregation pipeline operator. You ll find out that  Xenia#include  and  Xenia#exclude  can be easier to use for most scenarios.   fields  (Object) - Aggregation fields object   xenia()\n  .project({'name': true, '_id': false, 'comments': { 'country': true}})", 
            "title": "project(fields)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#includefieldnames", 
            "text": "Whitelist retrieved fields   fieldNames  (Array) - fields you want to retrieve   xenia().include(['name', 'avatar'])", 
            "title": "include(fieldNames)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#excludefieldnames", 
            "text": "Blacklist retrieved fields   fieldNames  (Array) - fields you don t want to retrieve   xenia().exclude(['age', 'gender'])", 
            "title": "exclude(fieldNames)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#matchquery", 
            "text": "Performs a match command on the aggregation pipeline   query  (Object) - Match parameters   xenia().match({ 'name': 'John', 'status': { '$in' : ['user', 'admin']} })", 
            "title": "match(query)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#redactquery", 
            "text": "Performs a redact command on the aggregation pipeline   query  (Object) - Redact parameters   xenia().redact({ $cond: {\n  if: { $gt: [ { $size: { $setIntersection: [  $tags , userAccess ] } }, 0 ] },\n  then:  $$DESCEND ,\n  else:  $$PRUNE \n}})", 
            "title": "redact(query)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#unwindpath-includearrayindex-preservenullandemptyarrays", 
            "text": "Performs a unwind command on the aggregation pipeline - Deconstructs an array field from the input documents to output a document for each element   path  (Object | String) - Field path  [includeArrayIndex]  (String) - arrayIndex name  [preserveNullAndEmptyArrays]  (Boolean) - preserve null and empty arrays, default false   xenia().unwind('$comments')", 
            "title": "unwind(path, includeArrayIndex, preserveNullAndEmptyArrays)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#groupgroups", 
            "text": "Group documents   groups  (Object) - group object   xenia().group({ _id : { month: { $month: '$date' } })", 
            "title": "group(groups)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#sortorder", 
            "text": "Sort documents by fields   order  (Object|Array) - how to sort the data   xenia().sort(['name', 1])\n\n// Or\n\nxenia.sort({'name': 1, 'statistics.comments.count': -1})", 
            "title": "sort(order)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#joincollection-field-matchingfield-name", 
            "text": "Creates a new query joining the actual one using the save method from Xenia   collection  (String) - The collection you want to join  [field]  (String) - The matching field in the collection you want to join, default: _id  [matchingField]  (String) - The field to match in your actual collection, default: same as field parameter  [name]  (String) - The field name on the results, default: list   xenia().collection('comments')\n.include(['body', 'asset_id']).limit(5)\n\n.join('assets', '_id', 'asset_id', 'asset')\n\n.include(['section']).exec()", 
            "title": "join(collection, field, matchingField, name)"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#development", 
            "text": "$ npm start", 
            "title": "Development"
        }, 
        {
            "location": "/developer/xenia/xenia-driver-js/#test", 
            "text": "$ npm test", 
            "title": "Test"
        }, 
        {
            "location": "/contribute/", 
            "text": "Contributing to the Coral Project\n\n\nWelcome! We\nre delighted to have you contribute to the Coral Project. Before you get started, be sure to review our \nCode of Conduct\n, which governs all development and project contributions.\n\n\nThere are a number of ways that you can contribute to the Coral Project: you don\nt have to be a developer to help out.\n\n\nContributing without programming\n\n\nWe need help with a number of non-programming tasks:\n\n\n\n\nReport bugs\n\n\nRequest features\n\n\nWrite and edit documentation\n\n\n\n\nContributing by coding\n\n\nIf you are a developer, especially if you know Go or Node.js, we would love your help in fixing bugs and developing new features and plug-ins.\n\n\n\n\nWrite code\n\n\n\n\nContributing to the community\n\n\n\n\nJoin us in our community forum\n to discuss online communities, comment sections, and journalism. Offer suggestions, ask questions!\n\n\nSign up to our newsletter\n.\n\n\nWe are also on \nTwitter\n.\n\n\nPlay our \nCards Against Community\n card game!", 
            "title": "Introduction"
        }, 
        {
            "location": "/contribute/#contributing-to-the-coral-project", 
            "text": "Welcome! We re delighted to have you contribute to the Coral Project. Before you get started, be sure to review our  Code of Conduct , which governs all development and project contributions.  There are a number of ways that you can contribute to the Coral Project: you don t have to be a developer to help out.", 
            "title": "Contributing to the Coral Project"
        }, 
        {
            "location": "/contribute/#contributing-without-programming", 
            "text": "We need help with a number of non-programming tasks:   Report bugs  Request features  Write and edit documentation", 
            "title": "Contributing without programming"
        }, 
        {
            "location": "/contribute/#contributing-by-coding", 
            "text": "If you are a developer, especially if you know Go or Node.js, we would love your help in fixing bugs and developing new features and plug-ins.   Write code", 
            "title": "Contributing by coding"
        }, 
        {
            "location": "/contribute/#contributing-to-the-community", 
            "text": "Join us in our community forum  to discuss online communities, comment sections, and journalism. Offer suggestions, ask questions!  Sign up to our newsletter .  We are also on  Twitter .  Play our  Cards Against Community  card game!", 
            "title": "Contributing to the community"
        }, 
        {
            "location": "/contribute/writing_code/", 
            "text": "Writing Code\n\n\nSo you\u2019d like to write some code to improve the Coral Project? Splendid! A few things you can contribute are bug fixes, new features, and plug-ins or extensions.\n\n\nBefore you begin\n\n\nBefore you begin, ensure that the work you\nre going to be doing has a GitHub issue associated with it.\n\n\n\n\nIf there isn\nt already someone working on it, then leave a comment to let everyone know that you are starting work on it.\n\n\nIf someone is already working on it, consider collaborating with them.\n\n\n\n\nIf there isn\nt already an GitHub issue, then create an issue for it. You can find more information on writing a detailed issue \nhere\n.\n\n\nCoding style guide\n\n\nAs you\nre working, refer to our \ncoding style guide\n to make sure your code conforms to our standards.\n\n\nWorking With GitHub\n\n\nThis section explains how open source contributors can contribute code to the Coral Project via pull requests.\n\n\nFor a general primer on contributing to open source projects, GitHub has created \na nice guide to contributing to open source\n.\n\n\nThe fundamentals (which are expanded on below) are:\n\n\n\n\nFork the project \n clone locally.\n\n\nCreate an upstream remote and sync your local copy before you branch.\n\n\nBranch for each separate piece of work.\n\n\nDo the work, and write good commit messages.\n\n\nPush to your origin repository.\n\n\nCreate a new PR in GitHub.\n\n\nRespond to any code review feedback.\n\n\n\n\nInstalling Git\n\n\nFirst, \ndownload and install Git\n. You can read more about Git on \ntheir website\n.\n\n\nAfter installing Git, the first thing you should do is setup your name and email:\n\n\ngit config --global user.name \nYour Real Name\n\ngit config --global user.email \nyou@email.com\n\n\n\n\n\nNote that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.\n\n\nSetting up a local repository\n\n\nFirst, you need to fork the project: navigate to to the repo in GitHub you want to contribute to and press the \nFork\n button. This will create a copy of the repository in your own GitHub account and you\nll see a note that it\ns been forked underneath the project name.\n\n\nNow create a local copy of that fork (in this example, the \ndocs\n repository is the one being cloned):\n\n\ngit clone https://github.com/coralproject/docs.git\n\n\n\n\nThis will create a new directory \ndocs\n, containing a clone of your forked GitHub repository. Switch to the project\ns new directory:\n\n\ncd docs\n\n\n\n\nYou will now need to setup coralproject/docs as an \nupstream\n remote. This connects your local repository to the original \nupstream\n source repository (essentially, telling Git that the original reference repository is the source of your local forked copy).\n\n\ngit remote add upstream https://github.com/coralproject/docs.git\ngit fetch upstream\n\n\n\n\nIt\ns a good idea to regularly pull in changes from \nupstream\n so that when you submit your pull request, merge conflicts will be less likely. You can find more detailed instructions on \nsyncing a fork from GitHub\n.    \n\n\nWork on an issue\n\n\nWhen working on an issue, create a new branch for the work. Name the branch for the issue you are working on, capitalizing the word \nIssue\n (for example, \nIssue#82\n).\n\n\ngit checkout master\ngit pull upstream master \n git push origin master\ngit checkout -b Issue#82\n\n\n\n\nWhat this does: First, we ensure we\nre on the master branch. Then, the git pull command will sync our local copy with the upstream project and the git push syncs it to our forked GitHub project. Finally, we create our new branch.\n\n\nNow you can start coding! Ensure that you are only changing code related to the issue you are working on.\n\n\nCommitting\n\n\nWhen committing, be sure to commit in logical blocks and add meaningful commit messages.\n\n\ngit commit -m 'Added instructions for commit messages'\n\n\n\n\nSome guidelines to follow:\n\n\n\n\nNever force-push your changes.\n\n\nWrite your commit messages in the past tense, not present tense.\n\n\nGood: \nAdded instructions for commit messages\n\n\nBad: \nAdd instructions for commit messages\n\n\n\n\n\n\nFor commits to a branch, prefix the commit message with the branch name. For example: \u201cIssue#82 Added instructions for commit messages.\u201d\n\n\n\n\nCreate the pull request\n\n\nTo create a PR you first need to push your branch to the origin remote.\n\n\nTo push a new branch:\n\n\ngit push origin Issue#82\n\n\n\n\nWhen you go to your GitHub page, you will notice that a new branch has been created, along with a button that says \nCompare and Pull Request.\n When you feel ready to create a pull request, go ahead and push the button.\n\n\nOn the \nOpen a pull request\n page, ensure that the \nbase fork\n points to the correct repository and branch. Then ensure that you provide a good, brief title for your pull request and explain why you have created it in the description box.\n\n\nScroll down to see the diff of your changes. Double check that it contains what you expect.\n\n\nOnce you are happy, press the \nCreate pull request\n button.\n\n\nReview by the maintainers\n\n\nOnce you\nve created your pull request, ping a code reviewer to take a look.\n\n\nThe reviewer will review and potentially offer suggestions. If that happens, make the suggested changes, commit, and push your changes. You may go through several cycles of reviews, changes, and updates.\n\n\nOnce both of you agree that the code is done, it\ns time to merge.\n\n\nMerging\n\n\nThe code reviewer will merge the pull request.\n\n\nOnce the merge is complete, the branch can be deleted.", 
            "title": "Contribute code"
        }, 
        {
            "location": "/contribute/writing_code/#writing-code", 
            "text": "So you\u2019d like to write some code to improve the Coral Project? Splendid! A few things you can contribute are bug fixes, new features, and plug-ins or extensions.", 
            "title": "Writing Code"
        }, 
        {
            "location": "/contribute/writing_code/#before-you-begin", 
            "text": "Before you begin, ensure that the work you re going to be doing has a GitHub issue associated with it.   If there isn t already someone working on it, then leave a comment to let everyone know that you are starting work on it.  If someone is already working on it, consider collaborating with them.   If there isn t already an GitHub issue, then create an issue for it. You can find more information on writing a detailed issue  here .", 
            "title": "Before you begin"
        }, 
        {
            "location": "/contribute/writing_code/#coding-style-guide", 
            "text": "As you re working, refer to our  coding style guide  to make sure your code conforms to our standards.", 
            "title": "Coding style guide"
        }, 
        {
            "location": "/contribute/writing_code/#working-with-github", 
            "text": "This section explains how open source contributors can contribute code to the Coral Project via pull requests.  For a general primer on contributing to open source projects, GitHub has created  a nice guide to contributing to open source .  The fundamentals (which are expanded on below) are:   Fork the project   clone locally.  Create an upstream remote and sync your local copy before you branch.  Branch for each separate piece of work.  Do the work, and write good commit messages.  Push to your origin repository.  Create a new PR in GitHub.  Respond to any code review feedback.", 
            "title": "Working With GitHub"
        }, 
        {
            "location": "/contribute/writing_code/#installing-git", 
            "text": "First,  download and install Git . You can read more about Git on  their website .  After installing Git, the first thing you should do is setup your name and email:  git config --global user.name  Your Real Name \ngit config --global user.email  you@email.com   Note that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.", 
            "title": "Installing Git"
        }, 
        {
            "location": "/contribute/writing_code/#setting-up-a-local-repository", 
            "text": "First, you need to fork the project: navigate to to the repo in GitHub you want to contribute to and press the  Fork  button. This will create a copy of the repository in your own GitHub account and you ll see a note that it s been forked underneath the project name.  Now create a local copy of that fork (in this example, the  docs  repository is the one being cloned):  git clone https://github.com/coralproject/docs.git  This will create a new directory  docs , containing a clone of your forked GitHub repository. Switch to the project s new directory:  cd docs  You will now need to setup coralproject/docs as an  upstream  remote. This connects your local repository to the original  upstream  source repository (essentially, telling Git that the original reference repository is the source of your local forked copy).  git remote add upstream https://github.com/coralproject/docs.git\ngit fetch upstream  It s a good idea to regularly pull in changes from  upstream  so that when you submit your pull request, merge conflicts will be less likely. You can find more detailed instructions on  syncing a fork from GitHub .", 
            "title": "Setting up a local repository"
        }, 
        {
            "location": "/contribute/writing_code/#work-on-an-issue", 
            "text": "When working on an issue, create a new branch for the work. Name the branch for the issue you are working on, capitalizing the word  Issue  (for example,  Issue#82 ).  git checkout master\ngit pull upstream master   git push origin master\ngit checkout -b Issue#82  What this does: First, we ensure we re on the master branch. Then, the git pull command will sync our local copy with the upstream project and the git push syncs it to our forked GitHub project. Finally, we create our new branch.  Now you can start coding! Ensure that you are only changing code related to the issue you are working on.", 
            "title": "Work on an issue"
        }, 
        {
            "location": "/contribute/writing_code/#committing", 
            "text": "When committing, be sure to commit in logical blocks and add meaningful commit messages.  git commit -m 'Added instructions for commit messages'  Some guidelines to follow:   Never force-push your changes.  Write your commit messages in the past tense, not present tense.  Good:  Added instructions for commit messages  Bad:  Add instructions for commit messages    For commits to a branch, prefix the commit message with the branch name. For example: \u201cIssue#82 Added instructions for commit messages.\u201d", 
            "title": "Committing"
        }, 
        {
            "location": "/contribute/writing_code/#create-the-pull-request", 
            "text": "To create a PR you first need to push your branch to the origin remote.  To push a new branch:  git push origin Issue#82  When you go to your GitHub page, you will notice that a new branch has been created, along with a button that says  Compare and Pull Request.  When you feel ready to create a pull request, go ahead and push the button.  On the  Open a pull request  page, ensure that the  base fork  points to the correct repository and branch. Then ensure that you provide a good, brief title for your pull request and explain why you have created it in the description box.  Scroll down to see the diff of your changes. Double check that it contains what you expect.  Once you are happy, press the  Create pull request  button.", 
            "title": "Create the pull request"
        }, 
        {
            "location": "/contribute/writing_code/#review-by-the-maintainers", 
            "text": "Once you ve created your pull request, ping a code reviewer to take a look.  The reviewer will review and potentially offer suggestions. If that happens, make the suggested changes, commit, and push your changes. You may go through several cycles of reviews, changes, and updates.  Once both of you agree that the code is done, it s time to merge.", 
            "title": "Review by the maintainers"
        }, 
        {
            "location": "/contribute/writing_code/#merging", 
            "text": "The code reviewer will merge the pull request.  Once the merge is complete, the branch can be deleted.", 
            "title": "Merging"
        }, 
        {
            "location": "/contribute/docs_style_guide/", 
            "text": "Documentation style guide\n\n\nThe key thing to remember when writing documentation is to be extremely explicit and detailed. Do not assume knowledge!\n\n\nWriting style\n\n\n\n\nWhen in doubt about a grammatical or syntactical point, refer to the \nAssociated Press\ns (AP) Style Guide\n.\n\n\nThough we value good style, please don\u2019t worry too much about getting everything perfect when contributing to the documentation. We prefer imperfectly styled documentation to no documentation at all.\n\n\nIn general, try to write in short, simple, clear sentences. Brief, three-to-five sentence paragraphs are easy to read and scan.\n\n\nPronouns\n:\n\n\nUse gender-neutral pronouns (they/their/them) rather than \nhe or she\n.\n\n\nFirst and second person pronouns are fine. Use \u201cwe\u201d to refer to Coral and \u201cyou\u201d to refer to the user.\n\n\n\n\n\n\nUse \nfor instance\n or \nfor example\n instead of \ni.e.\n\n\nSection headers and page headers should follow sentence case formatting (first word capitalized, following words uncapitalized) rather than title case (each word in the header capitalized).\n\n\nWhenever possible, include a section at the beginning of the page that describes what is contained within that page (with hyperlinks to the relevant sections). Sure, usually this will also appear on the Table of Contents in the side navigation section, but it\ns also useful to have it displayed within the text itself.\n\n\n\n\nDo not assume knowledge\n\n\n\n\nDon\nt be afraid to explain something that might seem very basic or self-explanatory to you; it may not be so basic to someone else.\n\n\nWhenever possible, include an actual, specific instruction and (if required) command.\n\n\nBad: \nClone the repository to your machine.\n\n\nGood: \nClone the docs repository to your local machine, using the command \ngit clone https://github.com/coralproject/docs.git\n\n\n\n\n\n\nIf there are command line instructions involved, include the precise command line instruction. Instructions that users can copy/paste into the command line are great!\n\n\nShow \nexpected results\n wherever possible.\n\n\nIf a command line instruction should return a certain result, show that expected result.\n\n\nIf the result output is quite long, show a key portion of it to avoid cluttering the page.\n\n\nIf there is a URL you can visit to test whether or not something is working, provide that URL as a link.\n\n\n\n\n\n\nIf there are variables to configure, explicitly state the purpose of the variables. This should be explained in a comment in the configuration file, but you should also provide an explanation in your instructions.\n\n\nDo not merely explain HOW to do something, but also, whenever possible, WHY you are doing it in that way. This makes it easier for users to troubleshoot issues.\n\n\n\n\nImages\n\n\n\n\nWhen you need to add an image, try to make the file size as small as possible.\n\n\nImages should go in the \nimages\n directory.\n\n\nThe preferred file format for images is PNG, but GIF and JPG are also acceptable.\n\n\nUse arrows or rectangles to highlight the specific area of the UI you are referring to. While red is a popular color for these notations, be sure that it doesn\nt blend in with the Coral colors. Use blue if necessary.\n\n\nInclude a descriptive alt-text for the graphic, to aid with accessibility. This is included in the Markdown code in the brackets.\n\n\n\n\n![TrustLoginScreen](/images/trustloginscreen.png)\n\n\n\n\n\n\nWhen taking screenshots to use as illustrative images, include a decent amount of \nsurrounding area\n to provide context and geography for the feature you\nre discussing. A screenshot of a button, for instance, isn\nt very useful when you can\nt figure out where the button is located.\n\n\n\n\nSizing images\n\n\nYour screenshots should be actual size. If you have a Retina or other high resolution display, you may encounter issues when taking screenshots (namely, a screenshot that appears \nactual size\n when viewed on your machine will become double sized when embedded into a web page). Mac users can find instructions on how to fix this problem \non this StackExchange page\n (it involves creating an Automator workflow file).\n\n\nDiagrams\n\n\nArchitectural diagrams to show application structure and process flow are really useful. You can view examples on the \narchitectural overview\n page.\n\n\nWe use the application \ndraw.io\n to draw our diagrams. It\ns easy and free: just go to the site, select \nCreate New Diagram,\n and get started.\n\n\n\n\nUse the \nBasic\n blank diagram template.\n\n\nApplication components are represented using the \nrounded rectangle\n shape.\n\n\nDatabases are represented with the \ncylinder\n shape.\n\n\nLabels for the application components use Helvetica font, size 18 pt, center aligned.\n\n\nDouble-headed arrows or single-headed arrows are used to show data flow. Each arrow should be accompanied by a text label that explains what data is being transferred and/or what request is being made.\n\n\n\n\nExporting diagrams\n\n\nWhen you export the diagram for use in the documentation, export it both as an SVG and as an XML. The XML will be the file that future contributors can edit, and the SVG will be the image displayed on the documentation page.\n\n\n\n\nFor both XML and SVG, keep the default values in the \nExport\n window.\n\n\nAt the \nSave as\n window, choose \nDownload.\n\n\nMove the SVG into the \nimages directory\n.\n\n\nMove the XML into the \ndiagrams directory\n.\n\n\n\n\nEmbedding diagrams\n\n\nWhen embedding diagrams, use the Markdown image tag:\n\n\n![TestDiagram](/images/testdiagram.svg)\n\n\n\n\nThird-party components\n\n\nIs there a third-party component the user needs to set up (for instance, MongoDB)?\n\n\n\n\nYou don\nt have to include all setup instructions, but do link to the setup instructions on the website of the third-party app in question (hopefully the third-party app is well-documented; if not, you may have to fill in the gaps).\n\n\nBe sure to detail any specific instructions they will need to integrate this third-party component into the system.\n\n\nCurrently, much of this \nthird party setup\n information resides in the \nDeveloper Setup\n document. This reduces duplication if there is a component that needs to be set up for multiple items.\n\n\n\n\nWriting installation instructions\n\n\n\n\nBe sure to include \nevery single step\n.\n\n\nInclude screenshots when it makes sense to do so.\n\n\nIf there are command line instructions, include the exact instruction in a code block so that users can copy/paste.\n\n\n\n\nWriting API documentation\n\n\nWhen documenting a REST-style API, such as the \nPillar API\n, there are certain pieces of information to include. The \nPillar API documentation\n is a useful template.\n\n\n\n\nCreate an initial table that lists endpoints, which contains:\n\n\nThe endpoint URL.\n\n\nThe HTTP verb for that endpoint (GET, POST).\n\n\nThe basic functionality description for that endpoint. Make this into a targeted link that jumps to the full description for that endpoint.\n\n\n\n\n\n\nCreate a full description for each endpoint. You can see the \nImport User\n Pillar endpoint for an example). Each description should include:\n\n\nThe parameters for the endpoint (include the parameter name, whether it is required or optional, the type, and the description).\n\n\nAn example call.\n\n\nThe response for the example call (whether that is a JSON object, or simply a status response).\n\n\n\n\n\n\n\n\nUser Guide documentation\n\n\nWhen documenting \nUser Guides\n, it is important to remember that the people reading them may not have in-depth technical knowledge. Keep your audience in mind.\n\n\nWriting User Guide tutorials\n\n\n\n\nTutorials take the reader by the hand through a series of steps to create or achieve something.\n\n\nTutorials should be \nresults oriented\n: by the end of the tutorial, the user will have achieved something.\n\n\n\n\nStructure\n\n\n\n\nThe tutorials for each product are all contained on the product page under the \nTutorials\n section.\n\n\nAt the top of the Product page is a list of the tutorials available on that page. Each has a description in the form of a user story (i.e., \nI would like to\n).\n\n\nThe goal of a tutorial is to walk the user through a scenario (such as \nidentify trolls within the Business section\n), that they can then tailor to their own needs (\nidentify trolls within the Health section\n).\n\n\n\n\nFormat\n\n\n\n\nTutorials follow a numbered step-by-step format.\n\n\nYou do not have to use the Markdown \nnumbered list\n formatting (in which the numbered list is written \n1.\n for auto-formatting). In fact, it is probably better if you don\nt: things get a bit wonky when you start inserting images in between the numbered steps.\n\n\n\n\n\n\n\n\nTerminology\n\n\n\n\nGit is capitalized.\n\n\nGitHub capitalizes both the G and the H.\n\n\n\n\nHere are some commonly used terms:\n\n\nSoftware specific\n\n\n\n\nCoral\n: Refers to the Coral product, which includes the three components Trust, Ask, and Talk.\n\n\nCoral Project\n: Refers to the project of building and crafting the Coral product.\n\n\nCoral Ecosystem\n: Refers to all of the pieces that make up Coral from a more technical or development perspective: includes all the technical components such as Pillar, Sponge, and Cay.\n\n\n\n\nUsers\n\n\n\n\nDevelopers\n: Refers to the technical users of Coral who will be installing Coral and working with the backend. Also refers to open-source contributors.\n\n\nEnd Users\n: Refers to anyone who will be interacting with the Coral front end. Examples of end users are publishers, moderators, journalists, and readers.\n\n\n\n\nMarkup specific style\n\n\nCommands and code blocks\n\n\n\n\nEnclose commands and code blocks in triple-tick blocks (```). Yes, Markdown supports indentation to delineate code blocks, but the triple-ticks make things more explicit.\n\n\nBe sure you are using universal command line commands, not shortcuts available in some shells.\n\n\nGood: \nmkdir exampledirectory\n\n\nBad: \nmd exampledirectory\n\n\n\n\n\n\n\n\nHeaders\n\n\n\n\nWhen adding headlines and section dividers, keep in mind that the Table of Contents displayed in the side navigation bar to the left is only two levels deep. So, H1 (#) and H2 (##) text will show up in the Table of Contents. H3 (###) and below will not.\n\n\nTo avoid making the Table of Contents too cluttered, try to only use H2 (##) for key large sections.\n\n\n\n\nAttribution: Style Guide adapted from the Django project documentation and Docker project documentation.", 
            "title": "Contribute to moderation style guide"
        }, 
        {
            "location": "/contribute/docs_style_guide/#documentation-style-guide", 
            "text": "The key thing to remember when writing documentation is to be extremely explicit and detailed. Do not assume knowledge!", 
            "title": "Documentation style guide"
        }, 
        {
            "location": "/contribute/docs_style_guide/#writing-style", 
            "text": "When in doubt about a grammatical or syntactical point, refer to the  Associated Press s (AP) Style Guide .  Though we value good style, please don\u2019t worry too much about getting everything perfect when contributing to the documentation. We prefer imperfectly styled documentation to no documentation at all.  In general, try to write in short, simple, clear sentences. Brief, three-to-five sentence paragraphs are easy to read and scan.  Pronouns :  Use gender-neutral pronouns (they/their/them) rather than  he or she .  First and second person pronouns are fine. Use \u201cwe\u201d to refer to Coral and \u201cyou\u201d to refer to the user.    Use  for instance  or  for example  instead of  i.e.  Section headers and page headers should follow sentence case formatting (first word capitalized, following words uncapitalized) rather than title case (each word in the header capitalized).  Whenever possible, include a section at the beginning of the page that describes what is contained within that page (with hyperlinks to the relevant sections). Sure, usually this will also appear on the Table of Contents in the side navigation section, but it s also useful to have it displayed within the text itself.", 
            "title": "Writing style"
        }, 
        {
            "location": "/contribute/docs_style_guide/#do-not-assume-knowledge", 
            "text": "Don t be afraid to explain something that might seem very basic or self-explanatory to you; it may not be so basic to someone else.  Whenever possible, include an actual, specific instruction and (if required) command.  Bad:  Clone the repository to your machine.  Good:  Clone the docs repository to your local machine, using the command  git clone https://github.com/coralproject/docs.git    If there are command line instructions involved, include the precise command line instruction. Instructions that users can copy/paste into the command line are great!  Show  expected results  wherever possible.  If a command line instruction should return a certain result, show that expected result.  If the result output is quite long, show a key portion of it to avoid cluttering the page.  If there is a URL you can visit to test whether or not something is working, provide that URL as a link.    If there are variables to configure, explicitly state the purpose of the variables. This should be explained in a comment in the configuration file, but you should also provide an explanation in your instructions.  Do not merely explain HOW to do something, but also, whenever possible, WHY you are doing it in that way. This makes it easier for users to troubleshoot issues.", 
            "title": "Do not assume knowledge"
        }, 
        {
            "location": "/contribute/docs_style_guide/#images", 
            "text": "When you need to add an image, try to make the file size as small as possible.  Images should go in the  images  directory.  The preferred file format for images is PNG, but GIF and JPG are also acceptable.  Use arrows or rectangles to highlight the specific area of the UI you are referring to. While red is a popular color for these notations, be sure that it doesn t blend in with the Coral colors. Use blue if necessary.  Include a descriptive alt-text for the graphic, to aid with accessibility. This is included in the Markdown code in the brackets.   ![TrustLoginScreen](/images/trustloginscreen.png)   When taking screenshots to use as illustrative images, include a decent amount of  surrounding area  to provide context and geography for the feature you re discussing. A screenshot of a button, for instance, isn t very useful when you can t figure out where the button is located.", 
            "title": "Images"
        }, 
        {
            "location": "/contribute/docs_style_guide/#sizing-images", 
            "text": "Your screenshots should be actual size. If you have a Retina or other high resolution display, you may encounter issues when taking screenshots (namely, a screenshot that appears  actual size  when viewed on your machine will become double sized when embedded into a web page). Mac users can find instructions on how to fix this problem  on this StackExchange page  (it involves creating an Automator workflow file).", 
            "title": "Sizing images"
        }, 
        {
            "location": "/contribute/docs_style_guide/#diagrams", 
            "text": "Architectural diagrams to show application structure and process flow are really useful. You can view examples on the  architectural overview  page.  We use the application  draw.io  to draw our diagrams. It s easy and free: just go to the site, select  Create New Diagram,  and get started.   Use the  Basic  blank diagram template.  Application components are represented using the  rounded rectangle  shape.  Databases are represented with the  cylinder  shape.  Labels for the application components use Helvetica font, size 18 pt, center aligned.  Double-headed arrows or single-headed arrows are used to show data flow. Each arrow should be accompanied by a text label that explains what data is being transferred and/or what request is being made.", 
            "title": "Diagrams"
        }, 
        {
            "location": "/contribute/docs_style_guide/#exporting-diagrams", 
            "text": "When you export the diagram for use in the documentation, export it both as an SVG and as an XML. The XML will be the file that future contributors can edit, and the SVG will be the image displayed on the documentation page.   For both XML and SVG, keep the default values in the  Export  window.  At the  Save as  window, choose  Download.  Move the SVG into the  images directory .  Move the XML into the  diagrams directory .", 
            "title": "Exporting diagrams"
        }, 
        {
            "location": "/contribute/docs_style_guide/#embedding-diagrams", 
            "text": "When embedding diagrams, use the Markdown image tag:  ![TestDiagram](/images/testdiagram.svg)", 
            "title": "Embedding diagrams"
        }, 
        {
            "location": "/contribute/docs_style_guide/#third-party-components", 
            "text": "Is there a third-party component the user needs to set up (for instance, MongoDB)?   You don t have to include all setup instructions, but do link to the setup instructions on the website of the third-party app in question (hopefully the third-party app is well-documented; if not, you may have to fill in the gaps).  Be sure to detail any specific instructions they will need to integrate this third-party component into the system.  Currently, much of this  third party setup  information resides in the  Developer Setup  document. This reduces duplication if there is a component that needs to be set up for multiple items.", 
            "title": "Third-party components"
        }, 
        {
            "location": "/contribute/docs_style_guide/#writing-installation-instructions", 
            "text": "Be sure to include  every single step .  Include screenshots when it makes sense to do so.  If there are command line instructions, include the exact instruction in a code block so that users can copy/paste.", 
            "title": "Writing installation instructions"
        }, 
        {
            "location": "/contribute/docs_style_guide/#writing-api-documentation", 
            "text": "When documenting a REST-style API, such as the  Pillar API , there are certain pieces of information to include. The  Pillar API documentation  is a useful template.   Create an initial table that lists endpoints, which contains:  The endpoint URL.  The HTTP verb for that endpoint (GET, POST).  The basic functionality description for that endpoint. Make this into a targeted link that jumps to the full description for that endpoint.    Create a full description for each endpoint. You can see the  Import User  Pillar endpoint for an example). Each description should include:  The parameters for the endpoint (include the parameter name, whether it is required or optional, the type, and the description).  An example call.  The response for the example call (whether that is a JSON object, or simply a status response).", 
            "title": "Writing API documentation"
        }, 
        {
            "location": "/contribute/docs_style_guide/#user-guide-documentation", 
            "text": "When documenting  User Guides , it is important to remember that the people reading them may not have in-depth technical knowledge. Keep your audience in mind.", 
            "title": "User Guide documentation"
        }, 
        {
            "location": "/contribute/docs_style_guide/#writing-user-guide-tutorials", 
            "text": "Tutorials take the reader by the hand through a series of steps to create or achieve something.  Tutorials should be  results oriented : by the end of the tutorial, the user will have achieved something.", 
            "title": "Writing User Guide tutorials"
        }, 
        {
            "location": "/contribute/docs_style_guide/#structure", 
            "text": "The tutorials for each product are all contained on the product page under the  Tutorials  section.  At the top of the Product page is a list of the tutorials available on that page. Each has a description in the form of a user story (i.e.,  I would like to ).  The goal of a tutorial is to walk the user through a scenario (such as  identify trolls within the Business section ), that they can then tailor to their own needs ( identify trolls within the Health section ).", 
            "title": "Structure"
        }, 
        {
            "location": "/contribute/docs_style_guide/#format", 
            "text": "Tutorials follow a numbered step-by-step format.  You do not have to use the Markdown  numbered list  formatting (in which the numbered list is written  1.  for auto-formatting). In fact, it is probably better if you don t: things get a bit wonky when you start inserting images in between the numbered steps.", 
            "title": "Format"
        }, 
        {
            "location": "/contribute/docs_style_guide/#terminology", 
            "text": "Git is capitalized.  GitHub capitalizes both the G and the H.   Here are some commonly used terms:", 
            "title": "Terminology"
        }, 
        {
            "location": "/contribute/docs_style_guide/#software-specific", 
            "text": "Coral : Refers to the Coral product, which includes the three components Trust, Ask, and Talk.  Coral Project : Refers to the project of building and crafting the Coral product.  Coral Ecosystem : Refers to all of the pieces that make up Coral from a more technical or development perspective: includes all the technical components such as Pillar, Sponge, and Cay.", 
            "title": "Software specific"
        }, 
        {
            "location": "/contribute/docs_style_guide/#users", 
            "text": "Developers : Refers to the technical users of Coral who will be installing Coral and working with the backend. Also refers to open-source contributors.  End Users : Refers to anyone who will be interacting with the Coral front end. Examples of end users are publishers, moderators, journalists, and readers.", 
            "title": "Users"
        }, 
        {
            "location": "/contribute/docs_style_guide/#markup-specific-style", 
            "text": "", 
            "title": "Markup specific style"
        }, 
        {
            "location": "/contribute/docs_style_guide/#commands-and-code-blocks", 
            "text": "Enclose commands and code blocks in triple-tick blocks (```). Yes, Markdown supports indentation to delineate code blocks, but the triple-ticks make things more explicit.  Be sure you are using universal command line commands, not shortcuts available in some shells.  Good:  mkdir exampledirectory  Bad:  md exampledirectory", 
            "title": "Commands and code blocks"
        }, 
        {
            "location": "/contribute/docs_style_guide/#headers", 
            "text": "When adding headlines and section dividers, keep in mind that the Table of Contents displayed in the side navigation bar to the left is only two levels deep. So, H1 (#) and H2 (##) text will show up in the Table of Contents. H3 (###) and below will not.  To avoid making the Table of Contents too cluttered, try to only use H2 (##) for key large sections.   Attribution: Style Guide adapted from the Django project documentation and Docker project documentation.", 
            "title": "Headers"
        }, 
        {
            "location": "/contribute/writing_documentation/", 
            "text": "Writing Documentation\n\n\nThis section explains how the community can contribute to the Coral Project documentation.\n\n\nYou can contribute to the documentation by editing existing documents for clarity or correcting errors. Additionally, any new features or changes to the software should be thoroughly documented.\n\n\nHere is, briefly, how our documentation works:\n\n\n\n\nThe source documentation lives in GitHub at \nhttps://github.com/coralproject/docs/\n.\n\n\nThe documentation is hosted on \nHeroku\n.\n\n\nThe documentation is built using \nMkDocs\n, a Markdown-based static site generator (geared towards building project documentation).\n\n\nThe document is deployed using a simple Mkdocs command that builds the documentation, and then the resulting generated site is pushed to Heroku.\n\n\n\n\nStyle Guide\n\n\nThere is a separate page for the \ndocumentation style guide\n, that covers guidelines for how to organize and write instructions and tutorials, how to format text for consistency, and terminology.\n\n\nHow the documentation is organized\n\n\nThe documentation is organized into several categories:\n\n\n\n\nIntroduction\n: This offers a general overview of the Coral Project and its different components.\n\n\nDeveloper Guide\n: This provides information for technical users of the Coral Project. It offers installation instructions for the Coral Ecosystem as a whole, as well as installation instructions for each individual component.\n\n\nUser Guide\n: This provides information for end users (publishers, journalists, moderators, readers) on how to use the features of Coral. It includes tutorials and how-to guides.\n\n\nContribute\n: This provides information on how to contribute to the Coral Project through open source. There are sections for the developers (how to work with GitHub, etc.), as well as sections for those who want to contribute to other pieces of the Coral Project (such as the documentation!).\n\n\nFAQ\n\n\n\n\nHow to obtain, write, and deploy documentation\n\n\nOur documentation is hosted and deployed through GitHub. This guide will take you step by step through the process of getting the documentation on to your local machine, editing the documentation, and submitting your changes. If you\nve never worked with Git before, it might seem a little intimidating, but we\nve broken it down for you into manageable chunks.\n\n\nBriefly, the process is as follows:\n\n\n\n\nFirst, you will get the documentation source code, using Git.\n\n\nThen, you will work on the documentation. You will use Mkdocs and Markdown to write the documentation.\n\n\nThen, you will push your changes to GitHub.\n\n\nFinally, you will deploy the documentation. The documentation is deployed using a simple Mkdocs command that builds the documentation, and then the resulting generated site is pushed to Heroku.\n\n\n\n\nInstall and set up Git\n\n\nIf you don\nt already have Git installed, you\nll want to get that set up first. You\nll have to \ndownload and install Git\n. You can read more about Git on \ntheir website\n.\n\n\nYou will also have to \ncreate a GitHub account\n, which is a very straightforward process.\n\n\nAfter installing Git, the first thing you should do is setup your name and email using the following commands:\n\n\ngit config --global user.name \nYour Real Name\n\ngit config --global user.email \nyou@email.com\n\n\n\n\n\nNote that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.\n\n\nInstall MkDocs\n\n\nThe Coral Project\ns documentation uses the \nMkDocs\n documentation system, which uses \nMarkdown\n to format text. Before you can get started on writing and editing the documentation, you will need to have MkDocs installed.\n\n\nYou can \ndownload and install MkDocs\n using the instructions on their website. The \nMkDocs website\n also contains a lot of good information on writing documentation in MkDocs, and there are plenty of decent Markdown cheatsheets floating around, \nlike this one\n.\n\n\nGetting the documentation\n\n\nAll of the documentation for the Coral Project \nresides in GitHub\n in the \ndocs\n repository.\n\n\nTo get a local version of the documentation, clone the repository using this command:\n\n\ngit clone https://github.com/coralproject/docs.git\n\n\n\n\nYou now have a local copy of the documentation on your local machine, that you can modify and add to.\n\n\nNote\n: If you already have a local copy of the documentation repository on your computer, be sure to perform a \ngit pull\n before you start editing. This will ensure that you are working on the most recent available version of the documentation, which will prevent potential merge conflicts when you\nre ready to commit your changes.\n\n\nWriting and editing the documentation\n\n\nThe documents you\nll be editing are the .md Markdown files located in the \ndocs_dir\n directory. \nDO NOT edit the files in the \nsite\n directory.\n Those files are the static HTML files generated by MkDocs and pushed to Heroku. If you edit the static HTML files, those changes won\nt get saved to the Markdown files.\n\n\nAs you are writing and editing the documentation, refer to the \nDocumentation Style Guide\n to make sure you are remaining consistent with our current documentation standards, and writing the best and clearest documentation possible.\n\n\nCommit your changes\n\n\nOnce you\nve finished your edits, it\ns time to commit your changes back up to the remote repository on GitHub.\n\n\nFirst, you\nll add your changes, where \nfilename\n is the name of the file or files that you have changed.\n\n\ngit add \nfilename\n\n\n\n\n\nThen, you\nll commit your changes. Be sure to add a commit message (the portion within the single quotations) to let everyone know what it is that you\nve changed. The \n-m\n flag is what tells Git that you\nre adding a commit message.\n\n\ngit commit -m 'Updated the Ask tutorial'\n\n\n\n\nFinally, push your changes up to the remote repository:\n\n\ngit push origin master\n\n\n\n\nDeploy the documentation\n\n\nNow that the documentation has been updated and committed to the repository, you can deploy the documentation. The documentation is hosted on Heroku, so in order to deploy it, we need to first build the files that make up the site, and then push those files up to Heroku.\n\n\nFirst ensure that you have the latest version of the documentation on your local machine:\n\n\ngit pull\n\n\n\n\nThen, run the following command:\n\n\nmkdocs build --clean\n\n\n\n\nThe \nbuild\n command builds the documentation, creating the HTML pages that make up the site, and places those files in the \nsite\n directory.\n\n\nNow you\nll add the changed files using Git, in preparation for pushing them to Heroku to deploy them. Add a meaningful commit message.\n\n\ngit add site\n\n\n\n\nThere is one file that you have to \nunadd\n before you push to Heroku: the \nsite/index.php\n file. Put briefly, it\ns a file that Heroku needs to serve up the site, but that the \nmkdocs build\n process deletes.\n\n\ngit reset HEAD site/index.php\n\n\n\n\nNow commit your changes, adding a meaningful commit message.\n\n\ngit commit -m \nUpdated writing documentation page\n\n\n\n\n\nNow you\nll push the \nsite\n directory, containing the pages that make up the website, to Heroku.\n\n\ngit subtree push --prefix site heroku master\n\n\n\n\nYou should see a series of messages from Heroku, ending with this:\n\n\nremote: Verifying deploy... done.\nTo https://git.heroku.com/coralprojectdocs.git\n   676aaa0..7e019f8  7e019f85487fe84efeb7cebcb33f9dff6782c8fb -\n master", 
            "title": "Write documentation"
        }, 
        {
            "location": "/contribute/writing_documentation/#writing-documentation", 
            "text": "This section explains how the community can contribute to the Coral Project documentation.  You can contribute to the documentation by editing existing documents for clarity or correcting errors. Additionally, any new features or changes to the software should be thoroughly documented.  Here is, briefly, how our documentation works:   The source documentation lives in GitHub at  https://github.com/coralproject/docs/ .  The documentation is hosted on  Heroku .  The documentation is built using  MkDocs , a Markdown-based static site generator (geared towards building project documentation).  The document is deployed using a simple Mkdocs command that builds the documentation, and then the resulting generated site is pushed to Heroku.", 
            "title": "Writing Documentation"
        }, 
        {
            "location": "/contribute/writing_documentation/#style-guide", 
            "text": "There is a separate page for the  documentation style guide , that covers guidelines for how to organize and write instructions and tutorials, how to format text for consistency, and terminology.", 
            "title": "Style Guide"
        }, 
        {
            "location": "/contribute/writing_documentation/#how-the-documentation-is-organized", 
            "text": "The documentation is organized into several categories:   Introduction : This offers a general overview of the Coral Project and its different components.  Developer Guide : This provides information for technical users of the Coral Project. It offers installation instructions for the Coral Ecosystem as a whole, as well as installation instructions for each individual component.  User Guide : This provides information for end users (publishers, journalists, moderators, readers) on how to use the features of Coral. It includes tutorials and how-to guides.  Contribute : This provides information on how to contribute to the Coral Project through open source. There are sections for the developers (how to work with GitHub, etc.), as well as sections for those who want to contribute to other pieces of the Coral Project (such as the documentation!).  FAQ", 
            "title": "How the documentation is organized"
        }, 
        {
            "location": "/contribute/writing_documentation/#how-to-obtain-write-and-deploy-documentation", 
            "text": "Our documentation is hosted and deployed through GitHub. This guide will take you step by step through the process of getting the documentation on to your local machine, editing the documentation, and submitting your changes. If you ve never worked with Git before, it might seem a little intimidating, but we ve broken it down for you into manageable chunks.  Briefly, the process is as follows:   First, you will get the documentation source code, using Git.  Then, you will work on the documentation. You will use Mkdocs and Markdown to write the documentation.  Then, you will push your changes to GitHub.  Finally, you will deploy the documentation. The documentation is deployed using a simple Mkdocs command that builds the documentation, and then the resulting generated site is pushed to Heroku.", 
            "title": "How to obtain, write, and deploy documentation"
        }, 
        {
            "location": "/contribute/writing_documentation/#install-and-set-up-git", 
            "text": "If you don t already have Git installed, you ll want to get that set up first. You ll have to  download and install Git . You can read more about Git on  their website .  You will also have to  create a GitHub account , which is a very straightforward process.  After installing Git, the first thing you should do is setup your name and email using the following commands:  git config --global user.name  Your Real Name \ngit config --global user.email  you@email.com   Note that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.", 
            "title": "Install and set up Git"
        }, 
        {
            "location": "/contribute/writing_documentation/#install-mkdocs", 
            "text": "The Coral Project s documentation uses the  MkDocs  documentation system, which uses  Markdown  to format text. Before you can get started on writing and editing the documentation, you will need to have MkDocs installed.  You can  download and install MkDocs  using the instructions on their website. The  MkDocs website  also contains a lot of good information on writing documentation in MkDocs, and there are plenty of decent Markdown cheatsheets floating around,  like this one .", 
            "title": "Install MkDocs"
        }, 
        {
            "location": "/contribute/writing_documentation/#getting-the-documentation", 
            "text": "All of the documentation for the Coral Project  resides in GitHub  in the  docs  repository.  To get a local version of the documentation, clone the repository using this command:  git clone https://github.com/coralproject/docs.git  You now have a local copy of the documentation on your local machine, that you can modify and add to.  Note : If you already have a local copy of the documentation repository on your computer, be sure to perform a  git pull  before you start editing. This will ensure that you are working on the most recent available version of the documentation, which will prevent potential merge conflicts when you re ready to commit your changes.", 
            "title": "Getting the documentation"
        }, 
        {
            "location": "/contribute/writing_documentation/#writing-and-editing-the-documentation", 
            "text": "The documents you ll be editing are the .md Markdown files located in the  docs_dir  directory.  DO NOT edit the files in the  site  directory.  Those files are the static HTML files generated by MkDocs and pushed to Heroku. If you edit the static HTML files, those changes won t get saved to the Markdown files.  As you are writing and editing the documentation, refer to the  Documentation Style Guide  to make sure you are remaining consistent with our current documentation standards, and writing the best and clearest documentation possible.", 
            "title": "Writing and editing the documentation"
        }, 
        {
            "location": "/contribute/writing_documentation/#commit-your-changes", 
            "text": "Once you ve finished your edits, it s time to commit your changes back up to the remote repository on GitHub.  First, you ll add your changes, where  filename  is the name of the file or files that you have changed.  git add  filename   Then, you ll commit your changes. Be sure to add a commit message (the portion within the single quotations) to let everyone know what it is that you ve changed. The  -m  flag is what tells Git that you re adding a commit message.  git commit -m 'Updated the Ask tutorial'  Finally, push your changes up to the remote repository:  git push origin master", 
            "title": "Commit your changes"
        }, 
        {
            "location": "/contribute/writing_documentation/#deploy-the-documentation", 
            "text": "Now that the documentation has been updated and committed to the repository, you can deploy the documentation. The documentation is hosted on Heroku, so in order to deploy it, we need to first build the files that make up the site, and then push those files up to Heroku.  First ensure that you have the latest version of the documentation on your local machine:  git pull  Then, run the following command:  mkdocs build --clean  The  build  command builds the documentation, creating the HTML pages that make up the site, and places those files in the  site  directory.  Now you ll add the changed files using Git, in preparation for pushing them to Heroku to deploy them. Add a meaningful commit message.  git add site  There is one file that you have to  unadd  before you push to Heroku: the  site/index.php  file. Put briefly, it s a file that Heroku needs to serve up the site, but that the  mkdocs build  process deletes.  git reset HEAD site/index.php  Now commit your changes, adding a meaningful commit message.  git commit -m  Updated writing documentation page   Now you ll push the  site  directory, containing the pages that make up the website, to Heroku.  git subtree push --prefix site heroku master  You should see a series of messages from Heroku, ending with this:  remote: Verifying deploy... done.\nTo https://git.heroku.com/coralprojectdocs.git\n   676aaa0..7e019f8  7e019f85487fe84efeb7cebcb33f9dff6782c8fb -  master", 
            "title": "Deploy the documentation"
        }, 
        {
            "location": "/contribute/coding_style_guide/", 
            "text": "Coding style guide\n\n\nIf you are planning to contribute to the Coral code base, you should familiarize yourself with our coding standards. This helps to avoid common errors, improves code readability, and ensures that your PRs have a better chance of getting accepted and merged.\n\n\nThe coding style guide consists of the following sections:\n\n\n\n\nCore code principles\n\n\nWorking with repositories (naming, describing, etc.)\n\n\nWorking with Git (creating good commit messages)\n\n\nGo coding style\n\n\nNode.js / Javascript coding style\n\n\nAdditional resources\n\n\n\n\nCore code principles\n\n\nThese are the four basic principles that guide how we shape and build our code. All Coral Project software is conceived from the ground up to be:\n\n\n\n\nConfigurable\n: We strive to use configuration to deliver as much business logic, data modeling, and other aspects of our systems as \nis practical.\n Doing so gives us the ability to quickly configure precise UI experiences, data structures, and data science analysis with minimal need for coding, upgrades, server work, etc. Ultimately, we want the community managers who run our software to feel like they are designing their own house. This means trying things to see how they feel, looking at the results, and quickly making changes based on what they learn. We take our inspiration from the ever-changing, adaptable ecosystems of coral reefs.\n\n\nModular\n: Coral products can be used together to form a fully functioning community platform, or be used in pieces to complement existing software. In order to accomplish this, we are building core API features, message passing and import/export strategies in everything we do. We are also refining, documenting, and publishing deployment strategies for each of our products both in isolation as well as together as groups of our products configured to work in concert.\n\n\nPrivacy Minded\n: There is an implicit act of trust involved in registration for and engagement in an online community. Maintaining that trust is a top priority for us. Privacy for us begins with security concerns, and stretches deep into our product thinking. Whenever information is entered into our systems, we want to make it clear who will be able to see that information and how it will be used. We want to build safe, comfortable places that allow for conversations of varying levels of exposure, without false expectations or nasty surprises.\n\n\nSecure, Stable and Scalable\n: Our deployment recommendations, if followed, provide usable and secure environments. Each piece of our software has internal checks to catch any error states and trigger alarms, as well as external restart mechanisms. All of our platforms have proven records for stability and well-known upgrade paths. We will publish auto-scaling deployment workflows where appropriate for large sites with varying loads.\n\n\n\n\nWorking with repositories\n\n\nRepository naming\n\n\nAs you may have guessed, each component of Coral is named after a different type of coral. We like to match up some traits of the particular type of coral with the functionality of the component, but that\ns not always possible.\n\n\nChoose a variety of coral to name your repo. Make sure that there isn\nt already a repo named something similar.\n\n\nRepository descriptions\n\n\nThe description of a repo tells the public what is contained in the repo itself. If you have multiple repositories for the same project, it\ns better to describe what is contained in the repo itself instead of describing the project. Repo descriptions should be clear, concise, and descriptive.\n\n\nIf your repo is not in active development, it\u2019s helpful to let users know this so they don\u2019t make contributions to a non-active repository. We suggest adding the word DEPRECATED before your repo description.\n\n\nGo coding style\n\n\nFor our Go code, we follow all coding guidelines laid out by the Go community, as detailed in their \nEffective Go\n guide. This helps us to maintain a consistent code base. We also use the \nGo Code Review Comments\n as a guide.\n\n\nAlthough not all of our code may comply 100% with the \nEffective Go\n guidelines, we\nre not looking for an overhaul of our code to make everything comply. Rather, all new contributions should comply with the guidelines. The ultimate goal is to make the code base easier for humans to navigate and understand.\n\n\nA few specific rules we follow\n\n\n\n\nAll code should be formatted with \ngofmt -s\n. (Read more about \ngofmt here\n.)\n\n\nAll code should pass the default levels of\n   \ngolint\n.\n\n\nComment the code. Tell us the why, the history and the context.\n\n\nDocument \nall\n declarations and methods, even private ones. Declare expectations, caveats and anything else that may be important. If a type gets exported, having the comments already there will ensure it\ns ready.\n\n\nThe length of a variable names should be proportional to its context, and preferably relatively short. In practice, short methods will have short variable names and globals will have longer names.\n\n\nBad: \nnoCommaALongVariableNameLikeThisIsNotMoreClearWhenASimpleCommentWouldDo\n.\n\n\n\n\n\n\nNo underscores in package names. If you need a compound name, step back, and re-examine why you need a compound name. If you still think you need a compound name, lose the underscore.\n\n\nNo utils or helper packages. If a function is not general enough to warrant its own package, it has not been written generally enough to be a part of a util package. Just leave it unexported and well-documented.\n\n\nAll tests should run with \ngo test\n and outside tooling should not be required. No, we don\nt need another unit testing framework. Assertion packages are acceptable if they provide \nreal\n incremental value.\n\n\nEven though we call these \nrules\n above, they are actually just guidelines. Since you\nve read all the rules, you now know that.\n\n\n\n\nUseful tools when developing in Go\n\n\n\n\ngolint\n: a linter for Go code.\n\n\ngofmt\n: a command that formats Go programs.\n\n\ngoimports\n: a command that updates your Go import lines.\n\n\nvet\n: a tool that examines Go code and reports suspicious constructs.\n\n\nerrcheck\n: a tool that checks for unchecked errors in Go programs.\n\n\n\n\nNode.js / Javascript coding style\n\n\nWe use the \nAirbnb React/JSX Style Guide\n when working with Javascript.\n\n\nCommenting\n\n\nCode commenting is crucial to maintaining a readable code base that future developers can understand and build upon. You can find a nice \nprimer on good commenting practice here\n.\n\n\n\n\nDocument \nall\n declarations and methods, even private ones. Explain expectations, caveats and any other information that could be important.\n\n\nKeep everything readable: simple, brief, and clear.\n\n\nWhitespace is important.\n\n\nComment while you code.\n\n\n\n\nResources\n\n\nSome further reading, particularly on the subject of Go:\n\n\n\n\nGo Code Review Comments\n\n\nBest Practices for Production Environments\n\n\n12 Factor App\n\n\nTools for working with Go Code\n\n\n\n\nAttribution: Go Coding Style adopted from the Docker project.", 
            "title": "Code best practices"
        }, 
        {
            "location": "/contribute/coding_style_guide/#coding-style-guide", 
            "text": "If you are planning to contribute to the Coral code base, you should familiarize yourself with our coding standards. This helps to avoid common errors, improves code readability, and ensures that your PRs have a better chance of getting accepted and merged.  The coding style guide consists of the following sections:   Core code principles  Working with repositories (naming, describing, etc.)  Working with Git (creating good commit messages)  Go coding style  Node.js / Javascript coding style  Additional resources", 
            "title": "Coding style guide"
        }, 
        {
            "location": "/contribute/coding_style_guide/#core-code-principles", 
            "text": "These are the four basic principles that guide how we shape and build our code. All Coral Project software is conceived from the ground up to be:   Configurable : We strive to use configuration to deliver as much business logic, data modeling, and other aspects of our systems as  is practical.  Doing so gives us the ability to quickly configure precise UI experiences, data structures, and data science analysis with minimal need for coding, upgrades, server work, etc. Ultimately, we want the community managers who run our software to feel like they are designing their own house. This means trying things to see how they feel, looking at the results, and quickly making changes based on what they learn. We take our inspiration from the ever-changing, adaptable ecosystems of coral reefs.  Modular : Coral products can be used together to form a fully functioning community platform, or be used in pieces to complement existing software. In order to accomplish this, we are building core API features, message passing and import/export strategies in everything we do. We are also refining, documenting, and publishing deployment strategies for each of our products both in isolation as well as together as groups of our products configured to work in concert.  Privacy Minded : There is an implicit act of trust involved in registration for and engagement in an online community. Maintaining that trust is a top priority for us. Privacy for us begins with security concerns, and stretches deep into our product thinking. Whenever information is entered into our systems, we want to make it clear who will be able to see that information and how it will be used. We want to build safe, comfortable places that allow for conversations of varying levels of exposure, without false expectations or nasty surprises.  Secure, Stable and Scalable : Our deployment recommendations, if followed, provide usable and secure environments. Each piece of our software has internal checks to catch any error states and trigger alarms, as well as external restart mechanisms. All of our platforms have proven records for stability and well-known upgrade paths. We will publish auto-scaling deployment workflows where appropriate for large sites with varying loads.", 
            "title": "Core code principles"
        }, 
        {
            "location": "/contribute/coding_style_guide/#working-with-repositories", 
            "text": "", 
            "title": "Working with repositories"
        }, 
        {
            "location": "/contribute/coding_style_guide/#repository-naming", 
            "text": "As you may have guessed, each component of Coral is named after a different type of coral. We like to match up some traits of the particular type of coral with the functionality of the component, but that s not always possible.  Choose a variety of coral to name your repo. Make sure that there isn t already a repo named something similar.", 
            "title": "Repository naming"
        }, 
        {
            "location": "/contribute/coding_style_guide/#repository-descriptions", 
            "text": "The description of a repo tells the public what is contained in the repo itself. If you have multiple repositories for the same project, it s better to describe what is contained in the repo itself instead of describing the project. Repo descriptions should be clear, concise, and descriptive.  If your repo is not in active development, it\u2019s helpful to let users know this so they don\u2019t make contributions to a non-active repository. We suggest adding the word DEPRECATED before your repo description.", 
            "title": "Repository descriptions"
        }, 
        {
            "location": "/contribute/coding_style_guide/#go-coding-style", 
            "text": "For our Go code, we follow all coding guidelines laid out by the Go community, as detailed in their  Effective Go  guide. This helps us to maintain a consistent code base. We also use the  Go Code Review Comments  as a guide.  Although not all of our code may comply 100% with the  Effective Go  guidelines, we re not looking for an overhaul of our code to make everything comply. Rather, all new contributions should comply with the guidelines. The ultimate goal is to make the code base easier for humans to navigate and understand.", 
            "title": "Go coding style"
        }, 
        {
            "location": "/contribute/coding_style_guide/#a-few-specific-rules-we-follow", 
            "text": "All code should be formatted with  gofmt -s . (Read more about  gofmt here .)  All code should pass the default levels of\n    golint .  Comment the code. Tell us the why, the history and the context.  Document  all  declarations and methods, even private ones. Declare expectations, caveats and anything else that may be important. If a type gets exported, having the comments already there will ensure it s ready.  The length of a variable names should be proportional to its context, and preferably relatively short. In practice, short methods will have short variable names and globals will have longer names.  Bad:  noCommaALongVariableNameLikeThisIsNotMoreClearWhenASimpleCommentWouldDo .    No underscores in package names. If you need a compound name, step back, and re-examine why you need a compound name. If you still think you need a compound name, lose the underscore.  No utils or helper packages. If a function is not general enough to warrant its own package, it has not been written generally enough to be a part of a util package. Just leave it unexported and well-documented.  All tests should run with  go test  and outside tooling should not be required. No, we don t need another unit testing framework. Assertion packages are acceptable if they provide  real  incremental value.  Even though we call these  rules  above, they are actually just guidelines. Since you ve read all the rules, you now know that.", 
            "title": "A few specific rules we follow"
        }, 
        {
            "location": "/contribute/coding_style_guide/#useful-tools-when-developing-in-go", 
            "text": "golint : a linter for Go code.  gofmt : a command that formats Go programs.  goimports : a command that updates your Go import lines.  vet : a tool that examines Go code and reports suspicious constructs.  errcheck : a tool that checks for unchecked errors in Go programs.", 
            "title": "Useful tools when developing in Go"
        }, 
        {
            "location": "/contribute/coding_style_guide/#nodejs-javascript-coding-style", 
            "text": "We use the  Airbnb React/JSX Style Guide  when working with Javascript.", 
            "title": "Node.js / Javascript coding style"
        }, 
        {
            "location": "/contribute/coding_style_guide/#commenting", 
            "text": "Code commenting is crucial to maintaining a readable code base that future developers can understand and build upon. You can find a nice  primer on good commenting practice here .   Document  all  declarations and methods, even private ones. Explain expectations, caveats and any other information that could be important.  Keep everything readable: simple, brief, and clear.  Whitespace is important.  Comment while you code.", 
            "title": "Commenting"
        }, 
        {
            "location": "/contribute/coding_style_guide/#resources", 
            "text": "Some further reading, particularly on the subject of Go:   Go Code Review Comments  Best Practices for Production Environments  12 Factor App  Tools for working with Go Code   Attribution: Go Coding Style adopted from the Docker project.", 
            "title": "Resources"
        }, 
        {
            "location": "/contribute/reporting_bugs/", 
            "text": "Reporting bugs and requesting features\n\n\nBefore reporting a bug or requesting a new feature, make sure you\nve done these first:\n\n\n\n\nCheck that someone hasn\u2019t already filed the bug or feature request by searching the \nIssues\n for the repo in question, or in the \nReef\n repository.\n\n\nIf it\ns for Ask, check the features in \nour Trello board\n.\n\n\nDon\u2019t reopen issues that have been marked \u201cwontfix\u201d by a core developer.\n\n\n\n\nReporting bugs\n\n\nWe use GitHub Issues to track bugs. Each Coral component app has its own repository, but since it may not be clear precisely which component the bug is originating from, we use the \nReef repository\n to track bugs.\n\n\nComplete, reproducible, specific bug reports are very helpful. When writing a bug report, be sure to include the following:\n\n\n\n\nA clear description of the issue.\n\n\nA set of instructions for replicating it.\n\n\n\n\nAdd as much additional information as you can, such as code snippets, logs, and screenshots. A small test case is ideal.\n\n\nReporting user interface bugs and features\n\n\nIf your bug or feature request involves the user interface, include screenshots in your ticket. Try to make the screenshots small enough to only show the relevant area of the screen, but large enough to provide context for that area.\n\n\nRequesting features\n\n\nWe want your help in deciding what to build! We have a section of our community dedicated to each of our main software products:\n\n\n\n\nTrust\n\n\nAsk\n\n\nTalk\n\n\n\n\nWhen submitting a feature request, try to adhere to these guidelines:\n\n\n\n\nDescribe clearly what the feature is and how you\u2019d like to see it implemented.\n\n\nExplain why you\u2019d like the feature.\n\n\nIf the feature can be developed as a plug-in or extension to Coral, consider \ndeveloping it yourself\n as a plug-in and adding it to our code base.", 
            "title": "Submit feature requests"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-bugs-and-requesting-features", 
            "text": "Before reporting a bug or requesting a new feature, make sure you ve done these first:   Check that someone hasn\u2019t already filed the bug or feature request by searching the  Issues  for the repo in question, or in the  Reef  repository.  If it s for Ask, check the features in  our Trello board .  Don\u2019t reopen issues that have been marked \u201cwontfix\u201d by a core developer.", 
            "title": "Reporting bugs and requesting features"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-bugs", 
            "text": "We use GitHub Issues to track bugs. Each Coral component app has its own repository, but since it may not be clear precisely which component the bug is originating from, we use the  Reef repository  to track bugs.  Complete, reproducible, specific bug reports are very helpful. When writing a bug report, be sure to include the following:   A clear description of the issue.  A set of instructions for replicating it.   Add as much additional information as you can, such as code snippets, logs, and screenshots. A small test case is ideal.", 
            "title": "Reporting bugs"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-user-interface-bugs-and-features", 
            "text": "If your bug or feature request involves the user interface, include screenshots in your ticket. Try to make the screenshots small enough to only show the relevant area of the screen, but large enough to provide context for that area.", 
            "title": "Reporting user interface bugs and features"
        }, 
        {
            "location": "/contribute/reporting_bugs/#requesting-features", 
            "text": "We want your help in deciding what to build! We have a section of our community dedicated to each of our main software products:   Trust  Ask  Talk   When submitting a feature request, try to adhere to these guidelines:   Describe clearly what the feature is and how you\u2019d like to see it implemented.  Explain why you\u2019d like the feature.  If the feature can be developed as a plug-in or extension to Coral, consider  developing it yourself  as a plug-in and adding it to our code base.", 
            "title": "Requesting features"
        }, 
        {
            "location": "/contribute/reporting_bugs/", 
            "text": "Reporting bugs and requesting features\n\n\nBefore reporting a bug or requesting a new feature, make sure you\nve done these first:\n\n\n\n\nCheck that someone hasn\u2019t already filed the bug or feature request by searching the \nIssues\n for the repo in question, or in the \nReef\n repository.\n\n\nIf it\ns for Ask, check the features in \nour Trello board\n.\n\n\nDon\u2019t reopen issues that have been marked \u201cwontfix\u201d by a core developer.\n\n\n\n\nReporting bugs\n\n\nWe use GitHub Issues to track bugs. Each Coral component app has its own repository, but since it may not be clear precisely which component the bug is originating from, we use the \nReef repository\n to track bugs.\n\n\nComplete, reproducible, specific bug reports are very helpful. When writing a bug report, be sure to include the following:\n\n\n\n\nA clear description of the issue.\n\n\nA set of instructions for replicating it.\n\n\n\n\nAdd as much additional information as you can, such as code snippets, logs, and screenshots. A small test case is ideal.\n\n\nReporting user interface bugs and features\n\n\nIf your bug or feature request involves the user interface, include screenshots in your ticket. Try to make the screenshots small enough to only show the relevant area of the screen, but large enough to provide context for that area.\n\n\nRequesting features\n\n\nWe want your help in deciding what to build! We have a section of our community dedicated to each of our main software products:\n\n\n\n\nTrust\n\n\nAsk\n\n\nTalk\n\n\n\n\nWhen submitting a feature request, try to adhere to these guidelines:\n\n\n\n\nDescribe clearly what the feature is and how you\u2019d like to see it implemented.\n\n\nExplain why you\u2019d like the feature.\n\n\nIf the feature can be developed as a plug-in or extension to Coral, consider \ndeveloping it yourself\n as a plug-in and adding it to our code base.", 
            "title": "Report bugs"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-bugs-and-requesting-features", 
            "text": "Before reporting a bug or requesting a new feature, make sure you ve done these first:   Check that someone hasn\u2019t already filed the bug or feature request by searching the  Issues  for the repo in question, or in the  Reef  repository.  If it s for Ask, check the features in  our Trello board .  Don\u2019t reopen issues that have been marked \u201cwontfix\u201d by a core developer.", 
            "title": "Reporting bugs and requesting features"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-bugs", 
            "text": "We use GitHub Issues to track bugs. Each Coral component app has its own repository, but since it may not be clear precisely which component the bug is originating from, we use the  Reef repository  to track bugs.  Complete, reproducible, specific bug reports are very helpful. When writing a bug report, be sure to include the following:   A clear description of the issue.  A set of instructions for replicating it.   Add as much additional information as you can, such as code snippets, logs, and screenshots. A small test case is ideal.", 
            "title": "Reporting bugs"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-user-interface-bugs-and-features", 
            "text": "If your bug or feature request involves the user interface, include screenshots in your ticket. Try to make the screenshots small enough to only show the relevant area of the screen, but large enough to provide context for that area.", 
            "title": "Reporting user interface bugs and features"
        }, 
        {
            "location": "/contribute/reporting_bugs/#requesting-features", 
            "text": "We want your help in deciding what to build! We have a section of our community dedicated to each of our main software products:   Trust  Ask  Talk   When submitting a feature request, try to adhere to these guidelines:   Describe clearly what the feature is and how you\u2019d like to see it implemented.  Explain why you\u2019d like the feature.  If the feature can be developed as a plug-in or extension to Coral, consider  developing it yourself  as a plug-in and adding it to our code base.", 
            "title": "Requesting features"
        }, 
        {
            "location": "/contribute/code_of_conduct/", 
            "text": "The Coral Project Code of Conduct\n\n\nUpdated 12/9/2015\n\n\nWe expect everyone contributing to The Coral Project to follow this code of conduct. That means the team, contractors we employ, contributors, as well as anyone posting to our public or internal-facing channels.\n\n\nWe created it not because we anticipate any unacceptable behavior, but because we believe that articulating our values and obligations to one another reinforces the already exceptional level of respect among the team, and because having a code provides us with clear avenues to correct our culture should it ever stray from that course.\n\n\nWe make this code public in the hopes of contributing to the ongoing conversation about inclusion in the tech, design, and media communities and encourage other teams to fork it and make it their own.\n\n\nWe commit to enforce and evolve this code over the duration of the project.\n\n\nExpected behavior\n\n\nBe supportive of each other.\n Offer to help if you see someone struggling or otherwise in need of assistance (taking care not to be patronizing or disrespectful). If someone approaches you looking for help, be generous with your time; if you\u2019re under a deadline, direct them to someone else who may be of assistance. Go out of your way to include people in team jokes or memes, recognizing that we want to build an environment free of cliques.\n\n\nBe collaborative.\n Involve your colleagues in brainstorms, sketching sessions, code reviews, planning documents, and the like. It\u2019s not only okay to ask for help or feedback often, it\u2019s unacceptable not to do so\n\n\nBe generous and kind in both giving and accepting critique.\n Critique is a natural and important part of our culture. Good critiques are kind, respectful, clear, and constructive, focused on goals and requirements rather than personal preferences. You are expected to give and receive criticism with grace.\n\n\nBe humane.\n Be polite and friendly in all forms of communication, especially remote communication, where opportunities for misunderstanding are greater. Use sarcasm carefully. Tone is hard to decipher online; make judicious use of emoji to aid in communication.\n\n\nBe considerate.\n\n\nBe tolerant.\n\n\nRespect people\ns boundaries.\n\n\nDo not make it personal.\n\n\nUnacceptable behavior\n\n\nWe are committed to providing a welcoming and safe environment for people of all races, gender identities, gender expressions, sexual orientations, physical abilities, physical appearances, socioeconomic backgrounds, nationalities, ages, religions, and beliefs.\n\n\nWe expect that you will refrain from demeaning, discriminatory, or harassing behavior and speech.\n\n\nHarassment includes, but is not limited to: deliberate intimidation; stalking; unwanted photography or recording; sustained or willful disruption of talks or other events; inappropriate physical contact; use of sexual or discriminatory imagery, comments, or jokes; and unwelcome sexual attention.\n\n\nFurthermore, any behavior or language which is unwelcoming\u2014whether or not it rises to the level of harassment\u2014is also strongly discouraged. Much exclusionary behavior takes the form of microaggressions\u2014subtle put-downs which may be unconsciously delivered. Regardless of intent, microaggressions can have a significant negative impact on victims and have no place on our team.\n\n\nOther inappropriate behavior:\n\n\nThreats\n\n\nSlurs\n\n\nPornography\n\n\nSpam\n\n\nBullying\n\n\nCopyright infringement\n\n\nImpersonation of someone else\n\n\nViolating someone\ns privacy\n\n\nIf you feel that someone has harassed you or otherwise treated you or someone else inappropriately, please alert the project lead at andrewl@mozillafoundation.org\n\n\nReporting a problem\n\n\nThese guidelines are ambitious, and we\u2019re not always going to succeed in meeting them. When something goes wrong\u2014whether it\u2019s a microaggression or an instance of harassment\u2014there are a number of things you can do to address the situation. Depending on your comfort level and the severity of the situation, here are some suggestions:\n\n\nAddress it directly.\n If you\u2019re comfortable bringing up the incident with the person who instigated it, pull them aside to discuss how it affected you. Be sure to approach these conversations in a forgiving spirit: an angry or tense conversation will not do either of you any good. If you\u2019re unsure how to go about that, try discussing with your manager or with the people and culture team first\u2014they might have some advice about how to make this conversation happen.\n\n\nIf you\u2019re too frustrated to have a direct conversation, there are a number of alternate routes you can take.\n\n\nTalk to a peer or mentor.\n Your colleagues are likely to have personal and professional experience on which to draw that could be of use to you. If you have someone you\nre comfortable approaching, reach out and discuss the situation with them. They may be able to advise on how they would handle it, or direct you to someone who can. The flip side of this, of course, is that you should also be available when your colleagues reach out to you.\n\n\nTalk to Andrew or David.\n We will work with you to help you figure out how to ensure that any conflict with a colleague doesn\u2019t interfere with your work, in confidence if you would prefer.\n\n\nTalk to Dan Sinker.\n Dan oversees the project. He can be contacted at dan@mozillafoundation.org\n\n\nIf you feel you have been unfairly accused of violating this code of conduct, you should contact Dan with a concise description of your grievance.\n\n\nConclusion\n\n\nWe welcome your feedback on this and every other aspect of what we do as The Coral Project, and we thank you for working with us to make it a safe, enjoyable, and friendly experience for everyone involved in the project and what we do.\n\n\nAbove text is licensed CC BY-SA 4.0, adapted from the SRCCON code of conduct, FreeBSD\ns code of conduct, Vox Media\ns product team code of conduct, and Medium\ns code of conduct.", 
            "title": "Our Code of Conduct"
        }, 
        {
            "location": "/contribute/code_of_conduct/#the-coral-project-code-of-conduct", 
            "text": "Updated 12/9/2015  We expect everyone contributing to The Coral Project to follow this code of conduct. That means the team, contractors we employ, contributors, as well as anyone posting to our public or internal-facing channels.  We created it not because we anticipate any unacceptable behavior, but because we believe that articulating our values and obligations to one another reinforces the already exceptional level of respect among the team, and because having a code provides us with clear avenues to correct our culture should it ever stray from that course.  We make this code public in the hopes of contributing to the ongoing conversation about inclusion in the tech, design, and media communities and encourage other teams to fork it and make it their own.  We commit to enforce and evolve this code over the duration of the project.", 
            "title": "The Coral Project Code of Conduct"
        }, 
        {
            "location": "/contribute/code_of_conduct/#expected-behavior", 
            "text": "Be supportive of each other.  Offer to help if you see someone struggling or otherwise in need of assistance (taking care not to be patronizing or disrespectful). If someone approaches you looking for help, be generous with your time; if you\u2019re under a deadline, direct them to someone else who may be of assistance. Go out of your way to include people in team jokes or memes, recognizing that we want to build an environment free of cliques.  Be collaborative.  Involve your colleagues in brainstorms, sketching sessions, code reviews, planning documents, and the like. It\u2019s not only okay to ask for help or feedback often, it\u2019s unacceptable not to do so  Be generous and kind in both giving and accepting critique.  Critique is a natural and important part of our culture. Good critiques are kind, respectful, clear, and constructive, focused on goals and requirements rather than personal preferences. You are expected to give and receive criticism with grace.  Be humane.  Be polite and friendly in all forms of communication, especially remote communication, where opportunities for misunderstanding are greater. Use sarcasm carefully. Tone is hard to decipher online; make judicious use of emoji to aid in communication.  Be considerate.  Be tolerant.  Respect people s boundaries.  Do not make it personal.", 
            "title": "Expected behavior"
        }, 
        {
            "location": "/contribute/code_of_conduct/#unacceptable-behavior", 
            "text": "We are committed to providing a welcoming and safe environment for people of all races, gender identities, gender expressions, sexual orientations, physical abilities, physical appearances, socioeconomic backgrounds, nationalities, ages, religions, and beliefs.  We expect that you will refrain from demeaning, discriminatory, or harassing behavior and speech.  Harassment includes, but is not limited to: deliberate intimidation; stalking; unwanted photography or recording; sustained or willful disruption of talks or other events; inappropriate physical contact; use of sexual or discriminatory imagery, comments, or jokes; and unwelcome sexual attention.  Furthermore, any behavior or language which is unwelcoming\u2014whether or not it rises to the level of harassment\u2014is also strongly discouraged. Much exclusionary behavior takes the form of microaggressions\u2014subtle put-downs which may be unconsciously delivered. Regardless of intent, microaggressions can have a significant negative impact on victims and have no place on our team.  Other inappropriate behavior:  Threats  Slurs  Pornography  Spam  Bullying  Copyright infringement  Impersonation of someone else  Violating someone s privacy  If you feel that someone has harassed you or otherwise treated you or someone else inappropriately, please alert the project lead at andrewl@mozillafoundation.org", 
            "title": "Unacceptable behavior"
        }, 
        {
            "location": "/contribute/code_of_conduct/#reporting-a-problem", 
            "text": "These guidelines are ambitious, and we\u2019re not always going to succeed in meeting them. When something goes wrong\u2014whether it\u2019s a microaggression or an instance of harassment\u2014there are a number of things you can do to address the situation. Depending on your comfort level and the severity of the situation, here are some suggestions:  Address it directly.  If you\u2019re comfortable bringing up the incident with the person who instigated it, pull them aside to discuss how it affected you. Be sure to approach these conversations in a forgiving spirit: an angry or tense conversation will not do either of you any good. If you\u2019re unsure how to go about that, try discussing with your manager or with the people and culture team first\u2014they might have some advice about how to make this conversation happen.  If you\u2019re too frustrated to have a direct conversation, there are a number of alternate routes you can take.  Talk to a peer or mentor.  Your colleagues are likely to have personal and professional experience on which to draw that could be of use to you. If you have someone you re comfortable approaching, reach out and discuss the situation with them. They may be able to advise on how they would handle it, or direct you to someone who can. The flip side of this, of course, is that you should also be available when your colleagues reach out to you.  Talk to Andrew or David.  We will work with you to help you figure out how to ensure that any conflict with a colleague doesn\u2019t interfere with your work, in confidence if you would prefer.  Talk to Dan Sinker.  Dan oversees the project. He can be contacted at dan@mozillafoundation.org  If you feel you have been unfairly accused of violating this code of conduct, you should contact Dan with a concise description of your grievance.", 
            "title": "Reporting a problem"
        }, 
        {
            "location": "/contribute/code_of_conduct/#conclusion", 
            "text": "We welcome your feedback on this and every other aspect of what we do as The Coral Project, and we thank you for working with us to make it a safe, enjoyable, and friendly experience for everyone involved in the project and what we do.  Above text is licensed CC BY-SA 4.0, adapted from the SRCCON code of conduct, FreeBSD s code of conduct, Vox Media s product team code of conduct, and Medium s code of conduct.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/contact/support/", 
            "text": "Need help with your install?\n\n\nIn addition to our online documentation, \nnews rooms can contact Jeff Nelson\n, THe Coral Project integration engineer. His job is to help you set up and install Coral Project products at your organization.", 
            "title": "Technical Support"
        }, 
        {
            "location": "/contact/support/#need-help-with-your-install", 
            "text": "In addition to our online documentation,  news rooms can contact Jeff Nelson , THe Coral Project integration engineer. His job is to help you set up and install Coral Project products at your organization.", 
            "title": "Need help with your install?"
        }, 
        {
            "location": "/contact/faq/", 
            "text": "FAQ\n\n\nProject background\n\n\nWhat is the Coral Project?\n\n\nThe Coral Project is a collaborative effort to improve community on news sites through open-source software. You can read more about it on \nour website\n.\n\n\nWhat do you do?\n\n\nWe\u2019re creating open-source software to facilitate the importing, storage, moderation, and display of contributions to news websites. That includes images, video, and text such as comments, annotations, and blog posts.\n\n\nWho\u2019s behind the project?\n\n\nIt\u2019s led by a team from Mozilla, The New York Times, and The Washington Post. It\u2019s funded by a two-year grant by the John S. and James L. Knight Foundation. The ideas guiding it are coming from readers, contributors, journalists, community managers, researchers, and developers. \nAnd you, if the mood strikes you\n.\n\n\nThis is that comment system that Mozilla is building for the Times and the Post, right?\n\n\nNot exactly. All three organizations are working together, and we\u2019re focusing on many kinds of text contributions, as well as images and video. We\u2019ll be creating software that publishers \u2014 or anyone, really \u2014 can use to better connect with their community. And that contributors can use to better connect with publishers.\n\n\nWhat about digital community do you want to improve?\n\n\nWe want to give publishers the ability to better understand their contributors and control the level of discourse on their sites; empower contributors to manage their identities and data; and provide readers with a more productive discussion about current events.\n\n\nDevelopment process\n\n\nSo you\u2019ll release your software in two years?\n\n\nNo, we\u2019ll be creating software throughout our grant period and working with contributors, publishers, academics, and readers to iterate on it.\n\n\nHow long has the project been going?\n\n\nWe had a research phase in early 2014, our grant was approved in June 2014, and we\u2019ve been planning and building our team in the time since.\n\n\nHow will the software work?\n\n\nWe\u2019ll be building a flexible core system and a series of plugins, all connected through APIs. Publishers \u2014 or anyone, really \u2014 can choose to use everything we deploy or pick and choose plugins that fit specific needs.\n\n\nWill it work on mobile?\n\n\nWe\u2019re developing for all browsers and devices.\n\n\nIs this for me?\n\n\nI\u2019m a regular commenter on news sites. What\u2019s in it for me?\n\n\nWe want to give you tools to own and manage your identity and contributions across websites and analytics that allow you to understand who\u2019s interacting with the content you create.\n\n\nI work at a news site that\u2019s smaller than The Post and The Times. Will this work for us?\n\n\nOur aim is to make the software we create easy to manage for publishers large and small. If you\u2019ve got specific needs you\u2019d like to talk about, please [email link]get in touch with us[/email link].\n\n\nHow can I keep up with what you\u2019re doing?\n\n\nWatch this website. We\u2019ll be posting updates regularly once our development begins in earnest.\n\n\nI\u2019ve got a few ideas to share with you. How can I get in touch?\n\n\nPlease get in touch with us here\n. We\u2019re eager to hear from you.\n\n\nData sources\n\n\nWhich external data sources are supported?\n\n\nWe currently support mySQL, PostgreSQL, MondoDB, and REST APIs.\n\n\nWe use Elasticsearch. Can we connect to that?\n\n\nNot yet. Our currently supported external data sources are mySQL, PostgreSQL, MongoDB, and REST APIs. However, you can write your own driver to connect to Elasticsearch. The drivers are part of the \nSponge\n app, and you can find out more about the driver components \nhere\n.\n\n\nHow often does the data refresh in the Trust app?\n\n\nThe data in the Trust app refreshes every 24 hours.\n\n\nInstallation\n\n\nHow would we get started?\n\n\nYou can learn more about the different installation options on our \ndeveloper overview page\n. The quickest and easiest way to get started is probably the \nAll-in-One Docker installation\n, but you can read about each available option (and whether it is likely to be the best option for you) on the \ndeveloper overview page\n.\n\n\nDo you have dummy data that we can use?\n\n\nYes. Our dummy data consists of real comments data, thoroughly scrubbed and anonymized.\n\n\nIf you install Coral through the \nAll-in-One Docker installation\n, you should automatically have the dummy data set up for you in your MongoDB.\n\n\nIf you want to manually import sample data (for example, if you\nve installed Coral from source code), you can read more about how to do that \non the developer setup page\n.", 
            "title": "FAQ"
        }, 
        {
            "location": "/contact/faq/#faq", 
            "text": "", 
            "title": "FAQ"
        }, 
        {
            "location": "/contact/faq/#project-background", 
            "text": "", 
            "title": "Project background"
        }, 
        {
            "location": "/contact/faq/#what-is-the-coral-project", 
            "text": "The Coral Project is a collaborative effort to improve community on news sites through open-source software. You can read more about it on  our website .", 
            "title": "What is the Coral Project?"
        }, 
        {
            "location": "/contact/faq/#what-do-you-do", 
            "text": "We\u2019re creating open-source software to facilitate the importing, storage, moderation, and display of contributions to news websites. That includes images, video, and text such as comments, annotations, and blog posts.", 
            "title": "What do you do?"
        }, 
        {
            "location": "/contact/faq/#whos-behind-the-project", 
            "text": "It\u2019s led by a team from Mozilla, The New York Times, and The Washington Post. It\u2019s funded by a two-year grant by the John S. and James L. Knight Foundation. The ideas guiding it are coming from readers, contributors, journalists, community managers, researchers, and developers.  And you, if the mood strikes you .", 
            "title": "Who\u2019s behind the project?"
        }, 
        {
            "location": "/contact/faq/#this-is-that-comment-system-that-mozilla-is-building-for-the-times-and-the-post-right", 
            "text": "Not exactly. All three organizations are working together, and we\u2019re focusing on many kinds of text contributions, as well as images and video. We\u2019ll be creating software that publishers \u2014 or anyone, really \u2014 can use to better connect with their community. And that contributors can use to better connect with publishers.", 
            "title": "This is that comment system that Mozilla is building for the Times and the Post, right?"
        }, 
        {
            "location": "/contact/faq/#what-about-digital-community-do-you-want-to-improve", 
            "text": "We want to give publishers the ability to better understand their contributors and control the level of discourse on their sites; empower contributors to manage their identities and data; and provide readers with a more productive discussion about current events.", 
            "title": "What about digital community do you want to improve?"
        }, 
        {
            "location": "/contact/faq/#development-process", 
            "text": "", 
            "title": "Development process"
        }, 
        {
            "location": "/contact/faq/#so-youll-release-your-software-in-two-years", 
            "text": "No, we\u2019ll be creating software throughout our grant period and working with contributors, publishers, academics, and readers to iterate on it.", 
            "title": "So you\u2019ll release your software in two years?"
        }, 
        {
            "location": "/contact/faq/#how-long-has-the-project-been-going", 
            "text": "We had a research phase in early 2014, our grant was approved in June 2014, and we\u2019ve been planning and building our team in the time since.", 
            "title": "How long has the project been going?"
        }, 
        {
            "location": "/contact/faq/#how-will-the-software-work", 
            "text": "We\u2019ll be building a flexible core system and a series of plugins, all connected through APIs. Publishers \u2014 or anyone, really \u2014 can choose to use everything we deploy or pick and choose plugins that fit specific needs.", 
            "title": "How will the software work?"
        }, 
        {
            "location": "/contact/faq/#will-it-work-on-mobile", 
            "text": "We\u2019re developing for all browsers and devices.", 
            "title": "Will it work on mobile?"
        }, 
        {
            "location": "/contact/faq/#is-this-for-me", 
            "text": "", 
            "title": "Is this for me?"
        }, 
        {
            "location": "/contact/faq/#im-a-regular-commenter-on-news-sites-whats-in-it-for-me", 
            "text": "We want to give you tools to own and manage your identity and contributions across websites and analytics that allow you to understand who\u2019s interacting with the content you create.", 
            "title": "I\u2019m a regular commenter on news sites. What\u2019s in it for me?"
        }, 
        {
            "location": "/contact/faq/#i-work-at-a-news-site-thats-smaller-than-the-post-and-the-times-will-this-work-for-us", 
            "text": "Our aim is to make the software we create easy to manage for publishers large and small. If you\u2019ve got specific needs you\u2019d like to talk about, please [email link]get in touch with us[/email link].", 
            "title": "I work at a news site that\u2019s smaller than The Post and The Times. Will this work for us?"
        }, 
        {
            "location": "/contact/faq/#how-can-i-keep-up-with-what-youre-doing", 
            "text": "Watch this website. We\u2019ll be posting updates regularly once our development begins in earnest.", 
            "title": "How can I keep up with what you\u2019re doing?"
        }, 
        {
            "location": "/contact/faq/#ive-got-a-few-ideas-to-share-with-you-how-can-i-get-in-touch", 
            "text": "Please get in touch with us here . We\u2019re eager to hear from you.", 
            "title": "I\u2019ve got a few ideas to share with you. How can I get in touch?"
        }, 
        {
            "location": "/contact/faq/#data-sources", 
            "text": "", 
            "title": "Data sources"
        }, 
        {
            "location": "/contact/faq/#which-external-data-sources-are-supported", 
            "text": "We currently support mySQL, PostgreSQL, MondoDB, and REST APIs.", 
            "title": "Which external data sources are supported?"
        }, 
        {
            "location": "/contact/faq/#we-use-elasticsearch-can-we-connect-to-that", 
            "text": "Not yet. Our currently supported external data sources are mySQL, PostgreSQL, MongoDB, and REST APIs. However, you can write your own driver to connect to Elasticsearch. The drivers are part of the  Sponge  app, and you can find out more about the driver components  here .", 
            "title": "We use Elasticsearch. Can we connect to that?"
        }, 
        {
            "location": "/contact/faq/#how-often-does-the-data-refresh-in-the-trust-app", 
            "text": "The data in the Trust app refreshes every 24 hours.", 
            "title": "How often does the data refresh in the Trust app?"
        }, 
        {
            "location": "/contact/faq/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/contact/faq/#how-would-we-get-started", 
            "text": "You can learn more about the different installation options on our  developer overview page . The quickest and easiest way to get started is probably the  All-in-One Docker installation , but you can read about each available option (and whether it is likely to be the best option for you) on the  developer overview page .", 
            "title": "How would we get started?"
        }, 
        {
            "location": "/contact/faq/#do-you-have-dummy-data-that-we-can-use", 
            "text": "Yes. Our dummy data consists of real comments data, thoroughly scrubbed and anonymized.  If you install Coral through the  All-in-One Docker installation , you should automatically have the dummy data set up for you in your MongoDB.  If you want to manually import sample data (for example, if you ve installed Coral from source code), you can read more about how to do that  on the developer setup page .", 
            "title": "Do you have dummy data that we can use?"
        }
    ]
}