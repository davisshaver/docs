{
    "docs": [
        {
            "location": "/", 
            "text": "This is a work in progress. Some sections are missing or incomplete.\n\n\nWelcome to the Coral Project documentation! This site aims to familiarize you with the Coral Project, how it works, and how you can help.\n\n\nWhat is the Coral Project?\n\n\nThe Coral Project is an open source project to help publishers of all sizes build better communities around their journalism. We\nre creating tools that allow everyone feel safe, respected, and heard.\n\n\nIf you\nd like to learn more about the Coral Project from a high-level perspective, \nthe main Coral Project website\n is the best place to do that. You can find information there about the project, our goals, and the individual products.\n\n\nHow the documentation is organized\n\n\nThe documentation is organized into sections based on what you want to do with Coral.\n\n\n\n\nThe \nDeveloper Guide\n section contains information geared towards a technical audience: those who want to install Coral, those who want to learn about how the various components of Coral fit together,\n\n\nThe \nUser Guide\n section contains information geared towards a less-technical audience. It has overviews and tutorials for those who want to use the Coral products like Trust, Ask, and Talk. If you\nre a publisher, moderator, journalist, or reader who wants to learn how to use Coral, this section is for you.\n\n\nThe \nContribute\n section contains information for those who want to contribute to the Coral Project. You don\nt have to be a developer to contribute! There are a number of ways you can help out, which are outlined on the \nIntroduction\n page.\n\n\n\n\nLearn more\n\n\nFor more information about us and to see our blog, please visit \nour website\n and \nsign up to our newsletter\n. We are also on \nTwitter\n.\n\n\nThe Coral Project is a collaboration between \nThe Mozilla Foundation\n, \nThe New York Times\n, and \nThe Washington Post\n, and is funded by a grant from \nThe John S. and James L. Knight Foundation\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#what-is-the-coral-project", 
            "text": "The Coral Project is an open source project to help publishers of all sizes build better communities around their journalism. We re creating tools that allow everyone feel safe, respected, and heard.  If you d like to learn more about the Coral Project from a high-level perspective,  the main Coral Project website  is the best place to do that. You can find information there about the project, our goals, and the individual products.", 
            "title": "What is the Coral Project?"
        }, 
        {
            "location": "/#how-the-documentation-is-organized", 
            "text": "The documentation is organized into sections based on what you want to do with Coral.   The  Developer Guide  section contains information geared towards a technical audience: those who want to install Coral, those who want to learn about how the various components of Coral fit together,  The  User Guide  section contains information geared towards a less-technical audience. It has overviews and tutorials for those who want to use the Coral products like Trust, Ask, and Talk. If you re a publisher, moderator, journalist, or reader who wants to learn how to use Coral, this section is for you.  The  Contribute  section contains information for those who want to contribute to the Coral Project. You don t have to be a developer to contribute! There are a number of ways you can help out, which are outlined on the  Introduction  page.", 
            "title": "How the documentation is organized"
        }, 
        {
            "location": "/#learn-more", 
            "text": "For more information about us and to see our blog, please visit  our website  and  sign up to our newsletter . We are also on  Twitter .  The Coral Project is a collaboration between  The Mozilla Foundation ,  The New York Times , and  The Washington Post , and is funded by a grant from  The John S. and James L. Knight Foundation .", 
            "title": "Learn more"
        }, 
        {
            "location": "/developer/", 
            "text": "Introduction\n\n\nWelcome! This is the place to be if you want to learn more about Coral from the standpoint of a developer or a technical user. Here you can learn about the inner workings of Coral, how to install the products, how to use the APIs, and more.\n\n\nIf you are a developer who is interested in contributing to our code, great! You can read more about contributing in our \nContribute section\n.\n\n\nThe Coral Ecosystem\n\n\nCoral is made up of a number of component apps that work together to power three products (Trust, Ask, and Talk). You can read more about how this ecosystem fits together \nhere\n.\n\n\nInstallation\n\n\nThere are a few different installation options to choose from. Which one is right for you?\n\n\nInstall a fully functioning single-server Coral Ecosystem, using Docker.\n\n\nThis is a quick, easy, packaged solution that requires few steps and should get all components up and running quickly. The downside is that this may not scale well, as everything is installed on one server. After a certain number of users (perhaps 50 or so), the server could become overloaded.\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space required: 4GB\n\n\n\n\nYou can find instructions on how to install Coral as a single Docker Compose installation \nhere\n.\n\n\nProbably best for you if:\n\n\n\n\nYou want to install Coral to perform a demo.\n\n\nYou want to get Coral running on your local machine to get a sense of its functionality and capabilities.\n\n\nYou want to get Coral up and running, and aren\nt worried about scaling right now.\n\n\n\n\nInstalling each component individually, using Docker.\n\n\nThis will install each component on a separate server, which allows for scaling up in future. It does require some more work to get each component talking and interacting with each other, but will scale better.\n\n\nIf you choose this option, you can visit the installation page for each Coral component, which has installation instructions for Docker and source.\n\n\n\n\nCay installation instructions\n\n\nElkhorn installation instructions\n\n\nPillar installation instructions\n\n\nSponge installation instructions\n\n\nXenia installation instructions\n\n\n\n\nProbably best for you if:\n\n\n\n\nYou have multiple servers, and are concerned about scalability.\n\n\nYou have a sysadmin to help manage installation and maintenance.\n\n\n\n\nInstalling each component individually from source code.\n\n\nThis option will have you install each component individually from source code, which will either be Go (most components) or Node.js.\n\n\nIf you choose this option, you can visit the installation page for each Coral component, which has installation instructions for Docker and source.\n\n\n\n\nCay installation instructions\n\n\nElkhorn installation instructions\n\n\nPillar installation instructions\n\n\nSponge installation instructions\n\n\nXenia installation instructions\n\n\n\n\nProbably best for you if:\n\n\n\n\nYou are a developer that wants to work on Coral and potentially \ncontribute to our code base\n (thank you!).", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/#introduction", 
            "text": "Welcome! This is the place to be if you want to learn more about Coral from the standpoint of a developer or a technical user. Here you can learn about the inner workings of Coral, how to install the products, how to use the APIs, and more.  If you are a developer who is interested in contributing to our code, great! You can read more about contributing in our  Contribute section .", 
            "title": "Introduction"
        }, 
        {
            "location": "/developer/#the-coral-ecosystem", 
            "text": "Coral is made up of a number of component apps that work together to power three products (Trust, Ask, and Talk). You can read more about how this ecosystem fits together  here .", 
            "title": "The Coral Ecosystem"
        }, 
        {
            "location": "/developer/#installation", 
            "text": "There are a few different installation options to choose from. Which one is right for you?", 
            "title": "Installation"
        }, 
        {
            "location": "/developer/#install-a-fully-functioning-single-server-coral-ecosystem-using-docker", 
            "text": "This is a quick, easy, packaged solution that requires few steps and should get all components up and running quickly. The downside is that this may not scale well, as everything is installed on one server. After a certain number of users (perhaps 50 or so), the server could become overloaded.  You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space required: 4GB   You can find instructions on how to install Coral as a single Docker Compose installation  here .  Probably best for you if:   You want to install Coral to perform a demo.  You want to get Coral running on your local machine to get a sense of its functionality and capabilities.  You want to get Coral up and running, and aren t worried about scaling right now.", 
            "title": "Install a fully functioning single-server Coral Ecosystem, using Docker."
        }, 
        {
            "location": "/developer/#installing-each-component-individually-using-docker", 
            "text": "This will install each component on a separate server, which allows for scaling up in future. It does require some more work to get each component talking and interacting with each other, but will scale better.  If you choose this option, you can visit the installation page for each Coral component, which has installation instructions for Docker and source.   Cay installation instructions  Elkhorn installation instructions  Pillar installation instructions  Sponge installation instructions  Xenia installation instructions   Probably best for you if:   You have multiple servers, and are concerned about scalability.  You have a sysadmin to help manage installation and maintenance.", 
            "title": "Installing each component individually, using Docker."
        }, 
        {
            "location": "/developer/#installing-each-component-individually-from-source-code", 
            "text": "This option will have you install each component individually from source code, which will either be Go (most components) or Node.js.  If you choose this option, you can visit the installation page for each Coral component, which has installation instructions for Docker and source.   Cay installation instructions  Elkhorn installation instructions  Pillar installation instructions  Sponge installation instructions  Xenia installation instructions   Probably best for you if:   You are a developer that wants to work on Coral and potentially  contribute to our code base  (thank you!).", 
            "title": "Installing each component individually from source code."
        }, 
        {
            "location": "/developer/architectural_overview/", 
            "text": "Architectural overview\n\n\nOver the course of the project, we are building an ecosystem of products, tools and practices. These elements will work together and/or integrate with existing community tools.\n\n\nCoral Ecosystem\n\n\nThe Coral Ecosystem consists of five apps working together with the Coral MongoDB database. You can see how these apps communicate with each other in the diagram below.\n\n\n\n\nCay\n is the front end application for Coral.\n\n\nElkhorn\n is the embeddable form builder. Cay sends a form specification in JSON format to Elkhorn, and Elkhorn sends back a rendered reader-facing form.\n\n\nPillar\n is the primary service that interacts with the Coral database. It works with Sponge to import external data, and performs CRUD (Create, Read, Update, Delete) operations on the Coral database.\n\n\nSponge\n is the data import service that extracts data from an external data source, and passes that data on to Pillar.\n\n\nXenia\n is a service layer that performs aggregated pipelines queries on the data in the Coral database.\n\n\n\n\n\n\nAsk\n\n\nAsk\n is a product that enables editors to create embeddable calls for contributions, including text, photo, video, audio.\n\n\n\n\nTrust\n\n\nTrust\n is a product that enables newsroom users to identify different kinds of end users in order to take actions (for instance, \nI want to block these trolls on this author,\n or \nI want to highlight the best commenters on this subject\n). It allows newsrooms to make manual or automated lists of users via a series of filters.", 
            "title": "Architectural overview"
        }, 
        {
            "location": "/developer/architectural_overview/#architectural-overview", 
            "text": "Over the course of the project, we are building an ecosystem of products, tools and practices. These elements will work together and/or integrate with existing community tools.", 
            "title": "Architectural overview"
        }, 
        {
            "location": "/developer/architectural_overview/#coral-ecosystem", 
            "text": "The Coral Ecosystem consists of five apps working together with the Coral MongoDB database. You can see how these apps communicate with each other in the diagram below.   Cay  is the front end application for Coral.  Elkhorn  is the embeddable form builder. Cay sends a form specification in JSON format to Elkhorn, and Elkhorn sends back a rendered reader-facing form.  Pillar  is the primary service that interacts with the Coral database. It works with Sponge to import external data, and performs CRUD (Create, Read, Update, Delete) operations on the Coral database.  Sponge  is the data import service that extracts data from an external data source, and passes that data on to Pillar.  Xenia  is a service layer that performs aggregated pipelines queries on the data in the Coral database.", 
            "title": "Coral Ecosystem"
        }, 
        {
            "location": "/developer/architectural_overview/#ask", 
            "text": "Ask  is a product that enables editors to create embeddable calls for contributions, including text, photo, video, audio.", 
            "title": "Ask"
        }, 
        {
            "location": "/developer/architectural_overview/#trust", 
            "text": "Trust  is a product that enables newsroom users to identify different kinds of end users in order to take actions (for instance,  I want to block these trolls on this author,  or  I want to highlight the best commenters on this subject ). It allows newsrooms to make manual or automated lists of users via a series of filters.", 
            "title": "Trust"
        }, 
        {
            "location": "/quickstart/install/", 
            "text": "All-in-One Docker Compose Installation\n\n\nThe all-in-one Docker Compose installation is a quick, easy, packaged solution that requires few steps and should get all components up and running quickly. The downside is that this may not scale well, as everything is installed on one server. After a certain number of users (perhaps 50 or so), the server could become overloaded.\n\n\nYou can read about the different types of installation options on the \ndeveloper introduction page\n.\n\n\nBefore you begin\n\n\nYou must have the following items installed and running:\n\n\n\n\nMongoDB Server\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nRabbitMQ\n: You can find instructions on installing RabbitMQ \non the RabbitMQ website\n.\n\n\n\n\nYou should also have the following resources on your machine before installing:\n\n\n\n\nMinimum CPU: 2.0 GHz\n\n\nMinimum RAM: 4GB\n\n\nMinimum disk space required: 4GB\n\n\n\n\nInstall Docker Toolbox\n\n\nIf you do not already have Docker installed, do that first. You can install Docker Toolbox using the Docker instructions \nlocated here\n.\n\n\nIf you do have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker version\n.\n\n\nGet the source code\n\n\nClone the Proxy repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.\n\n\ngit clone https://github.com/coralproject/Proxy.git\n\n\n\n\nThen cd into the Proxy directory.\n\n\ncd Proxy\n\n\n\n\nSet environment variables\n\n\nThe \nenv.conf\n file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral frontend will have, as well as other information such as your MongoDB username and password.\n\n\nexport FRONTEND_HOST=\n\nexport GAID_VALUE=xxxx\nexport AUTH_TOKEN_VALUE=xxxx\nexport RABBIT_USER=rabbitmq\nexport RABBIT_PASS=welcome\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral\n\n#elkhorn\nexport accessKeyId=xxx\nexport secretAccessKey=xxx\nexport pillarHost=xxx\nexport basicAuthorization=xxx\nexport bucket=xxx\nexport region=xxx\n# sponge:\nexport STRATEGY_CONF=/usr/local/strategy.json\n\n\n\n\nRequired edits:\n\n\n\n\nFRONTEND_HOST\n: set to your desired IP address for the front end. For this example, we will use \n192.168.99.100\n.\n\n\n\n\nOptional edits:\n\n\n\n\nGAID_VALUE=xxxx\n: If you\nre using Google Analytics, set your token at \nexport GAID_VALUE=xxxx\n. Otherwise, delete or comment out this line.\n\n\nexport AUTH_TOKEN_VALUE=xxxx\n: If you\nre using a custom auth token, set that at \nexport AUTH_TOKEN_VALUE=xxxx\n. Otherwise, delete or comment out this line.\n\n\n\n\nFinally, while inside the \nProxy\n directory, run the following command to export your edited variables and set the environment variables.\n\n\nsource env.conf\n\n\n\n\nSpin up the Docker container\n\n\nThe very first time that you spin up the Docker container, this will be a multi-step process:\n\n\n1. Spin up the Docker container:\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nThe \ndocker-compose.yml\n file contained in the docker-setup directory contains all the instructions that Docker Compose needs to set up the Coral Ecosystem.\n\n\n2. \nNote:\n If this is your first time spinning up the Docker container, Docker is going to download and install a number of Docker images first. These can be fairly large (~500MB per image), so it may take a few minutes.\n\n\n3. Once all Docker images have been downloaded, you\nll see something like the following in your terminal:\n\n\nCreating proxy_mongodata_1\nCreating proxy_sponge_1\nCreating proxy_rabbitmq_1\nCreating proxy_atollapp_1\nCreating proxy_xeniaapp_1\nCreating proxy_pillarapp_1\nCreating proxy_cayapp_1\nCreating proxy_proxy_1\n\n\n\n\n4. Now, shut everything down with the Docker \ndown\n command. This up-down-up sequence initializes authentication on MongoDB.\n\n\ndocker-compose -f docker-compose.yml down\n\n\n\n\n5. Finally, start the Docker container back up. In future (now that the Docker images have all been downloaded and set up), you can simply use this command to start your Docker container.\n\n\ndocker-compose -f docker-compose.yml up -d\n\n\n\n\nTest it out\n\n\nTo make sure it\ns working, try to hit the front-end URL in your browser. This is the URL you specified as \nFRONTEND_HOST\n in the \nenv.conf\n setup above; in this case, \nhttps://192.168.99.100\n.\n\n\nTroubleshooting\n\n\nViewing running Docker containers\n\n\nTo see all of the Docker containers currently running, use the command \ndocker ps\n (you can read more about this command and its options at the \nDocker website\n).\n\n\ndocker ps\n\n\n\n\nYou should have all of the following containers running:\n\n\n\n\nnginx:stable-alpine\n\n\ncoralproject/cay\n\n\ncoralproject/elkhorn\n\n\ncoralproject/pillar\n\n\ncoralproject/atoll\n\n\ncoralproject/xenia\n\n\ncoralproject/sponge\n\n\nrabbitmq:management\n\n\ncoralproject/mongodata\n\n\n\n\nViewing installed Docker images\n\n\nTo see all of the Docker images you have installed, use the command \ndocker images\n (you can read more about this command and its options at the \nDocker website\n).\n\n\ndocker images\n\n\n\n\nViewing Docker logs\n\n\nTo view Docker logs for a container, use the command \ndocker logs \ncontainer id\n (you can read more about this command and its options at the \nDocker website\n).\n\n\nFirst you have to find the container id:\n\n\ndocker ps\n\n\n\n\nThen use the container id to view the logs:\n\n\ndocker logs e0bbd7be19c7\n\n\n\n\nOperating system requirements\n\n\nOn Mac, we support OS X El Capitan (10.11) or newer. If you are on an older OS, you may have to upgrade.\n\n\nUninstalling Docker images", 
            "title": "Installing Coral Ecosystem"
        }, 
        {
            "location": "/quickstart/install/#all-in-one-docker-compose-installation", 
            "text": "The all-in-one Docker Compose installation is a quick, easy, packaged solution that requires few steps and should get all components up and running quickly. The downside is that this may not scale well, as everything is installed on one server. After a certain number of users (perhaps 50 or so), the server could become overloaded.  You can read about the different types of installation options on the  developer introduction page .", 
            "title": "All-in-One Docker Compose Installation"
        }, 
        {
            "location": "/quickstart/install/#before-you-begin", 
            "text": "You must have the following items installed and running:   MongoDB Server : You can find instructions on installing MongoDB  on the MongoDB website .  RabbitMQ : You can find instructions on installing RabbitMQ  on the RabbitMQ website .   You should also have the following resources on your machine before installing:   Minimum CPU: 2.0 GHz  Minimum RAM: 4GB  Minimum disk space required: 4GB", 
            "title": "Before you begin"
        }, 
        {
            "location": "/quickstart/install/#install-docker-toolbox", 
            "text": "If you do not already have Docker installed, do that first. You can install Docker Toolbox using the Docker instructions  located here .  If you do have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker version .", 
            "title": "Install Docker Toolbox"
        }, 
        {
            "location": "/quickstart/install/#get-the-source-code", 
            "text": "Clone the Proxy repository. This repository contains a number of setup files that you can edit, and will help you easily spin up a Docker container.  git clone https://github.com/coralproject/Proxy.git  Then cd into the Proxy directory.  cd Proxy", 
            "title": "Get the source code"
        }, 
        {
            "location": "/quickstart/install/#set-environment-variables", 
            "text": "The  env.conf  file contains environment variables you need to set. Setting your environment variables tells Docker which IP address your Coral frontend will have, as well as other information such as your MongoDB username and password.  export FRONTEND_HOST=\n\nexport GAID_VALUE=xxxx\nexport AUTH_TOKEN_VALUE=xxxx\nexport RABBIT_USER=rabbitmq\nexport RABBIT_PASS=welcome\n# mongo:\nexport MONGO_AUTHDB=admin\nexport MONGO_USER=coral-user\nexport MONGO_PASS=welcome\nexport MONGO_DB=coral\n\n#elkhorn\nexport accessKeyId=xxx\nexport secretAccessKey=xxx\nexport pillarHost=xxx\nexport basicAuthorization=xxx\nexport bucket=xxx\nexport region=xxx\n# sponge:\nexport STRATEGY_CONF=/usr/local/strategy.json  Required edits:   FRONTEND_HOST : set to your desired IP address for the front end. For this example, we will use  192.168.99.100 .   Optional edits:   GAID_VALUE=xxxx : If you re using Google Analytics, set your token at  export GAID_VALUE=xxxx . Otherwise, delete or comment out this line.  export AUTH_TOKEN_VALUE=xxxx : If you re using a custom auth token, set that at  export AUTH_TOKEN_VALUE=xxxx . Otherwise, delete or comment out this line.   Finally, while inside the  Proxy  directory, run the following command to export your edited variables and set the environment variables.  source env.conf", 
            "title": "Set environment variables"
        }, 
        {
            "location": "/quickstart/install/#spin-up-the-docker-container", 
            "text": "The very first time that you spin up the Docker container, this will be a multi-step process:  1. Spin up the Docker container:  docker-compose -f docker-compose.yml up -d  The  docker-compose.yml  file contained in the docker-setup directory contains all the instructions that Docker Compose needs to set up the Coral Ecosystem.  2.  Note:  If this is your first time spinning up the Docker container, Docker is going to download and install a number of Docker images first. These can be fairly large (~500MB per image), so it may take a few minutes.  3. Once all Docker images have been downloaded, you ll see something like the following in your terminal:  Creating proxy_mongodata_1\nCreating proxy_sponge_1\nCreating proxy_rabbitmq_1\nCreating proxy_atollapp_1\nCreating proxy_xeniaapp_1\nCreating proxy_pillarapp_1\nCreating proxy_cayapp_1\nCreating proxy_proxy_1  4. Now, shut everything down with the Docker  down  command. This up-down-up sequence initializes authentication on MongoDB.  docker-compose -f docker-compose.yml down  5. Finally, start the Docker container back up. In future (now that the Docker images have all been downloaded and set up), you can simply use this command to start your Docker container.  docker-compose -f docker-compose.yml up -d", 
            "title": "Spin up the Docker container"
        }, 
        {
            "location": "/quickstart/install/#test-it-out", 
            "text": "To make sure it s working, try to hit the front-end URL in your browser. This is the URL you specified as  FRONTEND_HOST  in the  env.conf  setup above; in this case,  https://192.168.99.100 .", 
            "title": "Test it out"
        }, 
        {
            "location": "/quickstart/install/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/quickstart/install/#viewing-running-docker-containers", 
            "text": "To see all of the Docker containers currently running, use the command  docker ps  (you can read more about this command and its options at the  Docker website ).  docker ps  You should have all of the following containers running:   nginx:stable-alpine  coralproject/cay  coralproject/elkhorn  coralproject/pillar  coralproject/atoll  coralproject/xenia  coralproject/sponge  rabbitmq:management  coralproject/mongodata", 
            "title": "Viewing running Docker containers"
        }, 
        {
            "location": "/quickstart/install/#viewing-installed-docker-images", 
            "text": "To see all of the Docker images you have installed, use the command  docker images  (you can read more about this command and its options at the  Docker website ).  docker images", 
            "title": "Viewing installed Docker images"
        }, 
        {
            "location": "/quickstart/install/#viewing-docker-logs", 
            "text": "To view Docker logs for a container, use the command  docker logs  container id  (you can read more about this command and its options at the  Docker website ).  First you have to find the container id:  docker ps  Then use the container id to view the logs:  docker logs e0bbd7be19c7", 
            "title": "Viewing Docker logs"
        }, 
        {
            "location": "/quickstart/install/#operating-system-requirements", 
            "text": "On Mac, we support OS X El Capitan (10.11) or newer. If you are on an older OS, you may have to upgrade.", 
            "title": "Operating system requirements"
        }, 
        {
            "location": "/quickstart/install/#uninstalling-docker-images", 
            "text": "", 
            "title": "Uninstalling Docker images"
        }, 
        {
            "location": "/developer/developer_setup/", 
            "text": "Developer tools setup\n\n\nIn order to install and work on Coral, there are a number of tools and software components you\nll need to install first. You may not need everything on this page, but we\nve collected all of the setup information here in one place for convenience.\n\n\nGit\n\n\nIf you don\nt already have Git installed, you\nll want to get that set up first. You\nll have to \ndownload and install Git\n. You can read more about Git on \ntheir website\n.\n\n\nYou will also have to \ncreate a GitHub account\n, which is a very straightforward process.\n\n\nAfter installing Git, the first thing you should do is setup your name and email using the following commands:\n\n\ngit config --global user.name \nYour Real Name\n\ngit config --global user.email \nyou@email.com\n\n\n\n\n\nNote that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.\n\n\nGo\n\n\nYou will need to have Go installed if you want to work on and/or install Coral components written in Go (these include Pillar, Sponge, and Xenia).\n\n\nYou can \ndownload and install Go from their website\n. The \ninstallation and setup instructions\n on the Go website are quite good.\n\n\nEnsure that you have exported your $GOPATH environment variable, as detailed in the \ninstallation instructions\n.\n\n\nIf you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.\n\n\nexport GO15VENDOREXPERIMENT=1\n\n\n\n\nIf you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.\n\n\nNode.js\n\n\nYou will need to have Node.js installed if you want to work on and/or install Coral components written in Node.js (these include Cay, Elkhorn, and Xenia Driver).\n\n\nYou can \ndownload and install Node.js from their website\n.\n\n\n\n\nYou must be running version 5.0.0 or higher of node. You can check your current version of node with the command \nnode --version\n\n\nWe recommend using \nnvm\n to manage your node installations.\n\n\n\n\nDocker\n\n\nIf you want to install Coral or Coral components using Docker, you will have to install Docker.\n\n\nYou can install Docker Toolbox using the Docker instructions \nlocated here\n.\n\n\nIf you do have Docker installed, you\nll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command \ndocker version\n.)\n\n\nMongoDB\n\n\nUsing sample data with MongoDB\n\n\nIf you are installing locally, you will want to have a local MongoDB running with sample data. When you install the all-in-one Docker Compose installation, this portion is taken care of for you. However, if you are running from source, for example, you will want to set up your local MongoDB and import sample data.\n\n\nDownload a sample data dump\n\n\nWe have provided an anonymized comments data dump for MongoDB, available to downlaod here: \nMongoDB data dump\n.\nThis data dump is 100MB. Download it to your computer.\n\n\nDownload and install MongoDB\n\n\nFirst, download and set up MongoDB. The MongoDB website offers \ninstructions on how to download and install\n.\n\n\nA nice GUI tool you can use with MongoDB is \nMongoChef\n, and it\ns quite easy to install and set up.\n\n\nCreate your local coral database\n\n\nTODO: add here\n\n\nImport data\n\n\nThe simplest way to do this is from the command line. First ensure you have MongoDB running.\n\n\nThen, take the dump.tar.gz file you downloaded, place it in a folder, and extract it. Copy the directory path to the coral directory within the extracted file.\n\n\nThen, run the below command (filling in your own directory path):\n\n\nmongorestore -d coral /yourpath/dump/coral/\n\n\n\n\nThis will import all the data from the data dump into your own local MongoDB.", 
            "title": "Developer tools setup"
        }, 
        {
            "location": "/developer/developer_setup/#developer-tools-setup", 
            "text": "In order to install and work on Coral, there are a number of tools and software components you ll need to install first. You may not need everything on this page, but we ve collected all of the setup information here in one place for convenience.", 
            "title": "Developer tools setup"
        }, 
        {
            "location": "/developer/developer_setup/#git", 
            "text": "If you don t already have Git installed, you ll want to get that set up first. You ll have to  download and install Git . You can read more about Git on  their website .  You will also have to  create a GitHub account , which is a very straightforward process.  After installing Git, the first thing you should do is setup your name and email using the following commands:  git config --global user.name  Your Real Name \ngit config --global user.email  you@email.com   Note that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.", 
            "title": "Git"
        }, 
        {
            "location": "/developer/developer_setup/#go", 
            "text": "You will need to have Go installed if you want to work on and/or install Coral components written in Go (these include Pillar, Sponge, and Xenia).  You can  download and install Go from their website . The  installation and setup instructions  on the Go website are quite good.  Ensure that you have exported your $GOPATH environment variable, as detailed in the  installation instructions .  If you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.  export GO15VENDOREXPERIMENT=1  If you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.", 
            "title": "Go"
        }, 
        {
            "location": "/developer/developer_setup/#nodejs", 
            "text": "You will need to have Node.js installed if you want to work on and/or install Coral components written in Node.js (these include Cay, Elkhorn, and Xenia Driver).  You can  download and install Node.js from their website .   You must be running version 5.0.0 or higher of node. You can check your current version of node with the command  node --version  We recommend using  nvm  to manage your node installations.", 
            "title": "Node.js"
        }, 
        {
            "location": "/developer/developer_setup/#docker", 
            "text": "If you want to install Coral or Coral components using Docker, you will have to install Docker.  You can install Docker Toolbox using the Docker instructions  located here .  If you do have Docker installed, you ll want to make sure that you have Docker Compose version 1.7 or later. You can check your version using the command  docker version .)", 
            "title": "Docker"
        }, 
        {
            "location": "/developer/developer_setup/#mongodb", 
            "text": "", 
            "title": "MongoDB"
        }, 
        {
            "location": "/developer/developer_setup/#using-sample-data-with-mongodb", 
            "text": "If you are installing locally, you will want to have a local MongoDB running with sample data. When you install the all-in-one Docker Compose installation, this portion is taken care of for you. However, if you are running from source, for example, you will want to set up your local MongoDB and import sample data.", 
            "title": "Using sample data with MongoDB"
        }, 
        {
            "location": "/developer/developer_setup/#download-a-sample-data-dump", 
            "text": "We have provided an anonymized comments data dump for MongoDB, available to downlaod here:  MongoDB data dump .\nThis data dump is 100MB. Download it to your computer.", 
            "title": "Download a sample data dump"
        }, 
        {
            "location": "/developer/developer_setup/#download-and-install-mongodb", 
            "text": "First, download and set up MongoDB. The MongoDB website offers  instructions on how to download and install .  A nice GUI tool you can use with MongoDB is  MongoChef , and it s quite easy to install and set up.", 
            "title": "Download and install MongoDB"
        }, 
        {
            "location": "/developer/developer_setup/#create-your-local-coral-database", 
            "text": "TODO: add here", 
            "title": "Create your local coral database"
        }, 
        {
            "location": "/developer/developer_setup/#import-data", 
            "text": "The simplest way to do this is from the command line. First ensure you have MongoDB running.  Then, take the dump.tar.gz file you downloaded, place it in a folder, and extract it. Copy the directory path to the coral directory within the extracted file.  Then, run the below command (filling in your own directory path):  mongorestore -d coral /yourpath/dump/coral/  This will import all the data from the data dump into your own local MongoDB.", 
            "title": "Import data"
        }, 
        {
            "location": "/cay/", 
            "text": "Introduction\n\n\nCay\n is the front-end application for Coral.\n\n\nIt\ns made up of a series of \nReact\n components, compiled into modules with \nwebpack\n.\n\n\nThe webpack build process results in a \nbundle.js\n file, which contains all Javascript and CSS for Cay. Common issues like CSS cross-browser issues, ES6 transpilation, and minification are all handled by webpack. \nbundle.js\n lives in-memory until build time (\nnpm run build\n).\n\n\nThe meat of the application lives in the \n/src\n folder. Components are grouped into subdirectories based on their \ndomain\n: for instance, everything that has to do with creating, viewing and editing searches lives in the \nsearch\n folder. Similarly, everything having to do with tags lives in the \ntags\n folder.\n\n\nThe reducers are combined in \n/src/app/MainReducer.js\n.", 
            "title": "Introduction"
        }, 
        {
            "location": "/cay/#introduction", 
            "text": "Cay  is the front-end application for Coral.  It s made up of a series of  React  components, compiled into modules with  webpack .  The webpack build process results in a  bundle.js  file, which contains all Javascript and CSS for Cay. Common issues like CSS cross-browser issues, ES6 transpilation, and minification are all handled by webpack.  bundle.js  lives in-memory until build time ( npm run build ).  The meat of the application lives in the  /src  folder. Components are grouped into subdirectories based on their  domain : for instance, everything that has to do with creating, viewing and editing searches lives in the  search  folder. Similarly, everything having to do with tags lives in the  tags  folder.  The reducers are combined in  /src/app/MainReducer.js .", 
            "title": "Introduction"
        }, 
        {
            "location": "/cay/install/", 
            "text": "Cay Installation\n\n\nInstall from source\n\n\nBefore you begin\n\n\nBefore you begin, be sure you have the following installed and running:\n\n\n\n\nXenia\n\n\nPillar\n\n\n\n\nIn addition, you must have Node.js installed:\n\n\n\n\nNode.js\n\n\nYou must be running version 5.0.0 or higher of node. You can check your current version of node with the command \nnode --version\n\n\nWe recommend using \nnvm\n to manage your node installations.\n\n\n\n\n\n\n\n\nGet the source\n\n\nClone the Cay repository onto your machine:\n\n\ngit clone https://github.com/coralproject/cay.git\n\n\n\n\ncd into the Cay directory:\n\n\ncd cay\n\n\n\n\nDo an npm install to install the node code:\n\n\nnpm install\n\n\n\n\nSet up configuration file\n\n\nThe folder called \npublic\n has a sample configuration file, called \nconfig.sample.json\n. Copy this file to a new file called \nconfig.json\n, that you will edit:\n\n\ncp public/config.sample.json public/config.json\n\n\n\n\nNow edit the config.json file.\n\n\n  \nxeniaHost\n: \n,\n  \npillarHost\n: \n,\n  \nelkhornHost\n: \nhttp://localhost:4444\n,\n  \nenvironment\n: \ndevelopment\n,\n  \nbrand\n: \n,\n  \ngoogleAnalyticsId\n: \nUA-12345678-9\n,\n  \nrequireLogin\n: false,\n  \nbasicAuthorization\n: \n,\n  \nfeatures\n: {\n    \nask\n: false\n  }\n}\n\n\n\n\nFor \nxeniaHost\n, \npillarHost\n, and \nelkhornHost\n, enter the URLs where each service is running.\n\n\n\n\nFor \nxeniaHost\n:\n\n\nIf you installed Xenia \nlocally from source\n, \nxeniaHost\n should be \nhttp://localhost:4000/1.0/exec/\n.\n\n\n\n\n\n\nFor \npillarHost\n:\n\n\nIf you installed Pillar \nlocally from source\n, \npillarHost\n should be \nhttp://localhost:8080\n.\n\n\nIf you installed Pillar \nlocally as a Docker container\n, \npillarHost\n should be \nhttp://10.0.4.105:8080\n. \nhttp://10.0.4.105\n is the URL generated by Docker.\n\n\n\n\n\n\n\n\nFor \nelkhornHost\n:\n\n\n\n\nIf you installed \nlocally from source\n, \nelkhornHost\n should be \nhttp://localhost:4444\n.\n\n\n\n\n\n\n\n\nUnder \nfeatures\n, for the time being, only \nask\n will have a value of \ntrue\n. Later, we will be adding fields for our additional two products, Trust and Talk. By setting the value to \ntrue\n, you are turning on the features that can be seen in Cay.\n\n\n\n\n\n\nRun the app\n\n\nYou can now start Cay by running npm start:\n\n\nnpm start\n\n\n\n\nYou can now visit Cay by visiting the URL \nhttp://localhost:3000\n.", 
            "title": "Installation"
        }, 
        {
            "location": "/cay/install/#cay-installation", 
            "text": "", 
            "title": "Cay Installation"
        }, 
        {
            "location": "/cay/install/#install-from-source", 
            "text": "", 
            "title": "Install from source"
        }, 
        {
            "location": "/cay/install/#before-you-begin", 
            "text": "Before you begin, be sure you have the following installed and running:   Xenia  Pillar   In addition, you must have Node.js installed:   Node.js  You must be running version 5.0.0 or higher of node. You can check your current version of node with the command  node --version  We recommend using  nvm  to manage your node installations.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/cay/install/#get-the-source", 
            "text": "Clone the Cay repository onto your machine:  git clone https://github.com/coralproject/cay.git  cd into the Cay directory:  cd cay  Do an npm install to install the node code:  npm install", 
            "title": "Get the source"
        }, 
        {
            "location": "/cay/install/#set-up-configuration-file", 
            "text": "The folder called  public  has a sample configuration file, called  config.sample.json . Copy this file to a new file called  config.json , that you will edit:  cp public/config.sample.json public/config.json  Now edit the config.json file.     xeniaHost :  ,\n   pillarHost :  ,\n   elkhornHost :  http://localhost:4444 ,\n   environment :  development ,\n   brand :  ,\n   googleAnalyticsId :  UA-12345678-9 ,\n   requireLogin : false,\n   basicAuthorization :  ,\n   features : {\n     ask : false\n  }\n}  For  xeniaHost ,  pillarHost , and  elkhornHost , enter the URLs where each service is running.   For  xeniaHost :  If you installed Xenia  locally from source ,  xeniaHost  should be  http://localhost:4000/1.0/exec/ .    For  pillarHost :  If you installed Pillar  locally from source ,  pillarHost  should be  http://localhost:8080 .  If you installed Pillar  locally as a Docker container ,  pillarHost  should be  http://10.0.4.105:8080 .  http://10.0.4.105  is the URL generated by Docker.     For  elkhornHost :   If you installed  locally from source ,  elkhornHost  should be  http://localhost:4444 .     Under  features , for the time being, only  ask  will have a value of  true . Later, we will be adding fields for our additional two products, Trust and Talk. By setting the value to  true , you are turning on the features that can be seen in Cay.", 
            "title": "Set up configuration file"
        }, 
        {
            "location": "/cay/install/#run-the-app", 
            "text": "You can now start Cay by running npm start:  npm start  You can now visit Cay by visiting the URL  http://localhost:3000 .", 
            "title": "Run the app"
        }, 
        {
            "location": "/elkhorn/", 
            "text": "Introduction\n\n\nElkhorn\n is the form composer and embeddable builder.\n\n\nElkhorn lets you create forms to solicit feedback from readers. You can then take the resulting forms and embed them in your website. The resulting data you collect is viewable in the \nAsk\n interface.\n\n\nElkhorn consists of the AskComposer and the embed service.\n\n\nAskComposer\n\n\nAskComposer is a component that takes a spec in JSON format and turns it into a reader-facing form.\n\n\n\n\nAskComposer doesn\nt know where the JSON originates from. In our case, in will come from the Ask interface in Cay, but in theory it could come from anywhere.\n\n\nAskComposer stores the state of the form (completed fields, current progress, etc.).\n\n\nAskComposer persists or saves the state of the form by sending the form to a data storage destination (this could be S3 if you set that up during the installation process, or on your local drive if you\nve installed this locally without an S3 setup).\n\n\nPartial states may be stored locally, even if S3 has been set up.\n\n\n\n\nEmbed service\n\n\nThe embed service uses the \nrollup\n module bundler to generate a build of the form.\n\n\nUsing the generated forms\n\n\nAs a standalone page\n\n\nThe form can be viewed on a full standalone page, using the following URL:\n\n\nhttps://[elkhornserver]/iframe/[form_id]\n\n\n\n\nEmbedded as an iframe\n\n\nYou can take the standalone page link and use it in an iframe, which you can then embed directly into your page:\n\n\niframe src=\nhttps://[elkhornserver]/iframe/[form_id]\n width=\n100%\n height=\n600px\n/iframe\n\n\n\n\n\n\n\nYou may have to tweak the width and height parameters.\n\n\n\n\nEmbedded directly into your page\n\n\nYou can render a form directly into a page, using a \nscript src\n tag. This offers the advantages of native CSS inheritance, in addition to the benefits that come with iframes.\n\n\ndiv id=\nask-form\n/div\nscript src=\n[filewritelocation]/[formid].js\n/script", 
            "title": "Introduction"
        }, 
        {
            "location": "/elkhorn/#introduction", 
            "text": "Elkhorn  is the form composer and embeddable builder.  Elkhorn lets you create forms to solicit feedback from readers. You can then take the resulting forms and embed them in your website. The resulting data you collect is viewable in the  Ask  interface.  Elkhorn consists of the AskComposer and the embed service.", 
            "title": "Introduction"
        }, 
        {
            "location": "/elkhorn/#askcomposer", 
            "text": "AskComposer is a component that takes a spec in JSON format and turns it into a reader-facing form.   AskComposer doesn t know where the JSON originates from. In our case, in will come from the Ask interface in Cay, but in theory it could come from anywhere.  AskComposer stores the state of the form (completed fields, current progress, etc.).  AskComposer persists or saves the state of the form by sending the form to a data storage destination (this could be S3 if you set that up during the installation process, or on your local drive if you ve installed this locally without an S3 setup).  Partial states may be stored locally, even if S3 has been set up.", 
            "title": "AskComposer"
        }, 
        {
            "location": "/elkhorn/#embed-service", 
            "text": "The embed service uses the  rollup  module bundler to generate a build of the form.", 
            "title": "Embed service"
        }, 
        {
            "location": "/elkhorn/#using-the-generated-forms", 
            "text": "", 
            "title": "Using the generated forms"
        }, 
        {
            "location": "/elkhorn/#as-a-standalone-page", 
            "text": "The form can be viewed on a full standalone page, using the following URL:  https://[elkhornserver]/iframe/[form_id]", 
            "title": "As a standalone page"
        }, 
        {
            "location": "/elkhorn/#embedded-as-an-iframe", 
            "text": "You can take the standalone page link and use it in an iframe, which you can then embed directly into your page:  iframe src= https://[elkhornserver]/iframe/[form_id]  width= 100%  height= 600px /iframe    You may have to tweak the width and height parameters.", 
            "title": "Embedded as an iframe"
        }, 
        {
            "location": "/elkhorn/#embedded-directly-into-your-page", 
            "text": "You can render a form directly into a page, using a  script src  tag. This offers the advantages of native CSS inheritance, in addition to the benefits that come with iframes.  div id= ask-form /div script src= [filewritelocation]/[formid].js /script", 
            "title": "Embedded directly into your page"
        }, 
        {
            "location": "/elkhorn/install/", 
            "text": "Elkhorn Installation\n\n\nInstall from source\n\n\nBefore you begin\n\n\nBefore you begin, be sure you have the following installed and running:\n\n\n\n\nPillar\n\n\n\n\nIn addition, you must have Node.js installed:\n\n\n\n\nNode.js\n\n\nYou must be running version 5.0.0 or higher of node. You can check your current version of node with the command \nnode --version\n\n\nWe recommend using \nnvm\n to manage your node installations.\n\n\n\n\n\n\n\n\nClone the Elkhorn repository\n\n\nClone the Elkhorn repository:\n\n\ngit clone https://github.com/coralproject/elkhorn.git\n\n\n\n\nThen cd into the Elkhorn directory.\n\n\ncd elkhorn\n\n\n\n\nBuild Elkhorn.\n\n\nnpm install\n\n\n\n\nSet up configuration file\n\n\nThe Elkhorn directory has a configuration file, called \nconfig.sample.json\n. Copy this file to a new file called \nconfig.json\n, that you will edit:\n\n\ncp config.sample.json config.json\n\n\n\n\nNow edit the config.json file.\n\n\n{\n  \npillarHost\n: \n,\n  \nbasicAuthorization\n: \nBasic 123123123123213\n,\n  \ns3\n: {\n    \nbucket\n: \n,\n    \nregion\n: \n,\n    \naccessKeyId\n: \n,\n    \nsecretAccessKey\n: \n\n  }\n}\n\n\n\n\n\n\nFor \npillarHost\n, enter the URL where the service is running. If you installed \nlocally from source\n, \npillarHost\n should be \nhttp://localhost:8080\n.\n\n\nFor \ns3\n, you can enter the values for your S3 setup. This is where Elkhorn will save\n\n\n\n\nRun the app\n\n\nYou can now start Elkhorn by running npm start:\n\n\nnpm start\n\n\n\n\nElkhorn will now be running locally on port 4444. You can now visit Elkhorn by visiting the URL \nhttp://localhost:4444\n.\n\n\nInstall as a Docker container\n\n\nClone the Elkhorn repository\n\n\nClone the Elkhorn repository:\n\n\ngit clone https://github.com/coralproject/elkhorn.git\n\n\n\n\nThen cd into the Elkhorn directory.\n\n\ncd elkhorn\n\n\n\n\nBuild and run Elkhorn\n\n\nBuild Elkhorn:\n\n\ndocker build -t elkhorn .\n\n\n\n\nRun Elkhorn:\n\n\ndocker run  --name elkhorn -d -p 4444:4444 elkhorn\n\n\n\n\nElkhorn will now be running locally on port 4444. You can now visit Elkhorn by visiting the URL \nhttp://localhost:4444\n.", 
            "title": "Installation"
        }, 
        {
            "location": "/elkhorn/install/#elkhorn-installation", 
            "text": "", 
            "title": "Elkhorn Installation"
        }, 
        {
            "location": "/elkhorn/install/#install-from-source", 
            "text": "", 
            "title": "Install from source"
        }, 
        {
            "location": "/elkhorn/install/#before-you-begin", 
            "text": "Before you begin, be sure you have the following installed and running:   Pillar   In addition, you must have Node.js installed:   Node.js  You must be running version 5.0.0 or higher of node. You can check your current version of node with the command  node --version  We recommend using  nvm  to manage your node installations.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/elkhorn/install/#clone-the-elkhorn-repository", 
            "text": "Clone the Elkhorn repository:  git clone https://github.com/coralproject/elkhorn.git  Then cd into the Elkhorn directory.  cd elkhorn  Build Elkhorn.  npm install", 
            "title": "Clone the Elkhorn repository"
        }, 
        {
            "location": "/elkhorn/install/#set-up-configuration-file", 
            "text": "The Elkhorn directory has a configuration file, called  config.sample.json . Copy this file to a new file called  config.json , that you will edit:  cp config.sample.json config.json  Now edit the config.json file.  {\n   pillarHost :  ,\n   basicAuthorization :  Basic 123123123123213 ,\n   s3 : {\n     bucket :  ,\n     region :  ,\n     accessKeyId :  ,\n     secretAccessKey :  \n  }\n}   For  pillarHost , enter the URL where the service is running. If you installed  locally from source ,  pillarHost  should be  http://localhost:8080 .  For  s3 , you can enter the values for your S3 setup. This is where Elkhorn will save", 
            "title": "Set up configuration file"
        }, 
        {
            "location": "/elkhorn/install/#run-the-app", 
            "text": "You can now start Elkhorn by running npm start:  npm start  Elkhorn will now be running locally on port 4444. You can now visit Elkhorn by visiting the URL  http://localhost:4444 .", 
            "title": "Run the app"
        }, 
        {
            "location": "/elkhorn/install/#install-as-a-docker-container", 
            "text": "", 
            "title": "Install as a Docker container"
        }, 
        {
            "location": "/elkhorn/install/#clone-the-elkhorn-repository_1", 
            "text": "Clone the Elkhorn repository:  git clone https://github.com/coralproject/elkhorn.git  Then cd into the Elkhorn directory.  cd elkhorn", 
            "title": "Clone the Elkhorn repository"
        }, 
        {
            "location": "/elkhorn/install/#build-and-run-elkhorn", 
            "text": "Build Elkhorn:  docker build -t elkhorn .  Run Elkhorn:  docker run  --name elkhorn -d -p 4444:4444 elkhorn  Elkhorn will now be running locally on port 4444. You can now visit Elkhorn by visiting the URL  http://localhost:4444 .", 
            "title": "Build and run Elkhorn"
        }, 
        {
            "location": "/pillar/", 
            "text": "Overview\n\n\nPillar\n is a REST based API written in Go. It provides the following services:\n\n\n\n\nImports external data (working with Sponge) into the Coral database.\n\n\nAllows CRUD (Create, Read, Update, Delete) operations on the Coral database.\n\n\n\n\nPillar is one of the primary services that interacts with the Coral database. The other service that interacts with the Coral database is \nXenia\n, but Xenia\ns queries are much more complex than Pillar\ns. Pillar does use Xenia to perform one specific, more complex search, but they largely serve different purposes.\n\n\nIf you\nd like to see more about how Pillar fits into the Coral Ecosystem, you can find some drawings and diagrams on the \nArchitectural Overview\n page.\n\n\nKey Points\n\n\n\n\n\n\nThe Pillar API adheres strongly to \nREST style\n.\n\n\n\n\n\n\nThe Pillar API works only with \nJSON\n data.\n\n\n\n\n\n\nThe regular \nCRUD\n endpoint URL pattern is \n/api/*\n, where as the URL pattern for import endpoints is \n/api/import/*\n.\n\n\n\n\n\n\nImport-related endpoints allow you to import data into Coral from an existing source system (i.e., an existing database of comment information).\n\n\n\n\nCoral keeps track of the original identifiers (i.e., the user id), and stores that data (using a structure called \nImportSource\n) in a field named \nSource\n. That means you won\nt lose the original identifier data from your original source when you import into Coral.\n\n\n\n\n\n\n\n\nAll import endpoints \nupsert\n data. This means that when you import an entry, it will overwrite the information for that entry if the entry already exists. This prevents duplications and other problems.", 
            "title": "Introduction"
        }, 
        {
            "location": "/pillar/#overview", 
            "text": "Pillar  is a REST based API written in Go. It provides the following services:   Imports external data (working with Sponge) into the Coral database.  Allows CRUD (Create, Read, Update, Delete) operations on the Coral database.   Pillar is one of the primary services that interacts with the Coral database. The other service that interacts with the Coral database is  Xenia , but Xenia s queries are much more complex than Pillar s. Pillar does use Xenia to perform one specific, more complex search, but they largely serve different purposes.  If you d like to see more about how Pillar fits into the Coral Ecosystem, you can find some drawings and diagrams on the  Architectural Overview  page.", 
            "title": "Overview"
        }, 
        {
            "location": "/pillar/#key-points", 
            "text": "The Pillar API adheres strongly to  REST style .    The Pillar API works only with  JSON  data.    The regular  CRUD  endpoint URL pattern is  /api/* , where as the URL pattern for import endpoints is  /api/import/* .    Import-related endpoints allow you to import data into Coral from an existing source system (i.e., an existing database of comment information).   Coral keeps track of the original identifiers (i.e., the user id), and stores that data (using a structure called  ImportSource ) in a field named  Source . That means you won t lose the original identifier data from your original source when you import into Coral.     All import endpoints  upsert  data. This means that when you import an entry, it will overwrite the information for that entry if the entry already exists. This prevents duplications and other problems.", 
            "title": "Key Points"
        }, 
        {
            "location": "/pillar/install/", 
            "text": "Pillar Installation\n\n\nIf you want to install Pillar as part of an all-in-one installation of the Coral Ecosystem, you can \nfind instructions to do that here\n.\n\n\nWhen installing Pillar by itself, you can choose between installing Pillar as a Docker container, or installing from source.\n\n\n\n\nInstall Pillar from source\n\n\nInstall Pillar as a Docker container\n\n\n\n\nBefore you begin\n\n\nBefore you install Pillar, you must have the following items installed and running:\n\n\n\n\nMongoDB\n: You can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nThere are \ninstructions on importing sample comment data into MongoDB here\n\n\n\n\n\n\nRabbitMQ\n: You can find instructions on installing RabbitMQ \non the RabbitMQ website\n.\n\n\nXenia\n: Xenia is a configurable service layer that publishes endpoints against MongoDB aggregation pipeline queries. It is part of the Coral ecosystem. You can find instructions on how to install Xenia \nhere\n.\n\n\n\n\nInstall Pillar from source\n\n\nBefore you begin\n\n\nIf you want to install from source, you will need to have Go installed.\n\n\nYou can install \ninstall Go from their website\n. The \ninstallation and setup instructions\n on the Go website are quite good. Ensure that you have exported your $GOPATH environment variable, as detailed in the \ninstallation instructions\n.\n\n\nIf you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.\n\n\nexport GO15VENDOREXPERIMENT=1\n\n\n\n\nIf you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.\n\n\nGet the source code\n\n\nYou can install the source code via using the \ngo get\n command, or by manually cloning the code.\n\n\nUsing the go get command\n\n\ngo get github.com/coralproject/pillar\n\n\n\n\nIf you see a message about \nno buildable Go source files\n as shown below, you can ignore it. It simply means that there are no buildable source files in the uppermost pillar directory (though there are buildable source files in subdirectories).\n\n\npackage github.com/coralproject/pillar: no buildable Go source files in [directory]\n\n\n\n\nCloning manually\n\n\nYou can also clone the code manually (this does the same thing as the \ngo get\n command above).\n\n\nmkdir $GOPATH/src/github.com/coralproject/pillar\ncd $GOPATH/src/github.com/coralproject/pillar\n\ngit clone https://github.com/coralproject/pillar.git\n\n\n\n\nSet your environment variables\n\n\nSetting your environment variables tells Pillar the URLs and other information for communicating with MongoDB, RabbitMQ, and Xenia.\n\n\nMake your own copy of the \nconfig/dev.cfg\n file (you can edit this configuration file with your own values, and then ensure that you don\nt commit it back to the repository). Call your config file whatever you like; we\nll call it \ncustom\n in this example.\n\n\ncd $GOPATH/src/github.com/coralproject/pillar\ncp config/dev.cfg config/custom.cfg\n\n\n\n\nNow edit the values in your custom.cfg file:\n\n\n#Resources\nexport MONGODB_URL=\nmongodb://localhost:27017/coral\n\nexport AMQP_URL=\namqp://localhost:5672/\n\nexport AMQP_EXCHANGE=\nPillarMQ\n\n\n#Pillar\nexport PILLAR_ADDRESS=\n:8080\n\nexport PILLAR_HOME=\n/opt/pillar\n\nexport PILLAR_CRON=\nfalse\n\nexport PILLAR_CRON_SEARCH=\n@every 30m\n\nexport PILLAR_CRON_STATS=\n@every 1m\n\n\n#Xenia\nexport XENIA_URL=\nhttp://localhost:4000/1.0/exec/\n\nexport XENIA_QUERY_PARAM=\n?skip=0\nlimit=100\n\nexport XENIA_AUTH=\nauth token\n\n\n# Stats\nexport MONGODB_ADDRESS=\n127.0.0.1:27017\n\nexport MONGODB_USERNAME=\n\nexport MONGODB_PASSWORD=\n\nexport MONGODB_DATABASE=\n\nexport MONGODB_SSL=\nFalse\n\n\n\n\n\n\n\nFor \nXENIA_URL\n:\n\n\nIf you installed \nlocally from source\n, \nXENIA_URL\n should be \nhttp://localhost:4000/1.0/exec/\n.\n\n\n\n\n\n\nFor \nMONGODB_URL\n:\n\n\nIf your MongoDB is a local installation, \nMONGODB_URL\n should be \nmongodb://localhost:27017/coral\n.\n\n\n\n\n\n\nFor \nAMQP_URL\n:\n\n\nIf your RabbitMQ is a local installation, \nAMQP_URL\n should be \namqp://localhost:5672/\n.\n\n\n\n\n\n\n\n\nOnce you\nve edited and saved your custom.cfg file, source it with the following command:\n\n\nsource $GOPATH/src/github.com/coralproject/pillar/config/custom.cfg\n\n\n\n\nRun Pillar\n\n\n$GOPATH/bin/pillar\n\n\n\n\nYou should see:\n\n\n[negroni] listening on :8080\n\n\n\n\nInstall as Docker Container\n\n\nInstall Docker\n\n\nYou can find more information on installing Docker on your machine \non the Docker website\n.\n\n\n\n\nOn the server, you can install Docker with the following command:\n\n\n\n\nsudo yum install docker\n\n\n\n\nClone the Pillar repository\n\n\nClone the Pillar repository:\n\n\ngit clone https://github.com/coralproject/pillar.git\n\n\n\n\nThen cd into the Pillar directory.\n\n\ncd pillar\n\n\n\n\nStart Docker\n\n\nStart Docker.\n\n\n\n\nOn the server, you can do this via the command:\n  \nsudo service docker start\n\n\nOn your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type \ndocker quickstart\n into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.\n\n\nIf, at any point, you see the error message \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n, this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you\nve opened up the Docker Quickstart Terminal and are running your Docker commands there.\n\n\n\n\n\n\n\n\nBuild Pillar server\n\n\nBuild the Pillar server using \ndocker build\n.\n\n\ndocker build -t pillar-server:0.1 .\n\n\n\n\n\n\nIf you are building on the server, you may have to use \nsudo\n:\n\n\n\n\nsudo docker build -t pillar-server:0.1 .\n\n\n\n\nEdit environment variables\n\n\nThe env.list file contains environment variables you need to set. Edit this file to reflect the settings on your own system.\n\n\nMONGODB_URL=\nmongodb://localhost:27017/coral\n\nAMQP_URL=\namqp://localhost:5672/\n\nAMQP_EXCHANGE=\nPillarMQ\n\n\nPILLAR_ADDRESS=\n:8080\n\nPILLAR_HOME=\n/opt/pillar\n\nPILLAR_CRON=\nfalse\n\nPILLAR_CRON_SEARCH=\n@every 30m\n\nPILLAR_CRON_STATS=\n@every 1m\n\n\nXENIA_URL=\nhttp://localhost:4000/1.0/exec/\n\nXENIA_QUERY_PARAM=\n?skip=0\nlimit=100\n\nXENIA_AUTH=\nauth token\n\n\nMONGODB_ADDRESS=\n127.0.0.1:27017\n\nMONGODB_USERNAME=\n\nMONGODB_PASSWORD=\n\nMONGODB_DATABASE=\n\nMONGODB_SSL=\nFalse\n\n\n\n\n\n\n\nFor \nXENIA_URL\n:\n\n\nIf you installed \nlocally\n, \nXENIA_URL\n should be \nhttp://localhost:4000/1.0/exec/\n.\n\n\n\n\n\n\nFor \nMONGODB_URL\n:\n\n\nIf your MongoDB is a local installation, \nMONGODB_URL\n should be \nmongodb://localhost:27017/coral\n.\n\n\nIf your MongoDB is a local installation, \nMONGODB_ADDRESS\n should be \n127.0.0.1:27017\n.\n\n\n\n\n\n\nFor \nAMQP_URL\n:\n\n\nIf your RabbitMQ is a local installation, \nAMQP_URL\n should be \namqp://localhost:5672/\n.\n\n\n\n\n\n\n\n\nRun Docker\n\n\nFirst, find the Image ID for the Pillar server:\n\n\ndocker images\n\n\n\n\n\n\nIf you are running on a server, you may have to use \nsudo\n.\n\n\n\n\nThis shows you the Image ID:\n\n\nREPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\npillar-server       0.1                 24b7acf7a4b3        4 hours ago         771 MB\ngolang              1.6                 024309f28934        8 days ago          744.1 MB\n\n\n\n\nThen run the docker run command with the Image ID:\n\n\ndocker run --env-file env.list --publish 8080:8080 24b7acf7a4b3\n\n\n\n\nYou should see the following:\n\n\n[negroni] listening on :8080\n\n\n\n\nTest it out\n\n\nTo see if Pillar is working correctly, visit this url: \nhttp://10.0.4.105:8080/about\n. \nhttp://10.0.4.105\n is the URL generated by Docker for Pillar.\n\n\nIf things are running properly, you should see this text:\n\n\n{\nApp\n:\nCoral Pillar Web Service\n,\nVersion\n:\nVersion - 0.0.1\n}\n\n\n\n\nShutting Pillar down\n\n\nShutting Pillar down when running from source\n\n\nIf you installed and ran Pillar from source using the command \n$GOPATH/bin/pillar\n, you can shut it down by using the Ctrl + C command.\n\n\nShutting Pillar down when running as a Docker container\n\n\nTo shut Pillar down when running as Docker container, first find the container ID (if you are running on a server, you may have to use \nsudo\n):\n\n\ndocker ps\n\n\n\n\nFind the container ID for Pillar:\n\n\nCONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                                                                                        NAMES\nb30f4fa5f497        coralproject/pillar      \n/bin/sh -c /go/bin/p\n   3 days ago          Up 3 days           0.0.0.0:32776-\n8080/tcp                                                                      proxy_pillarapp_1\n\n\n\n\nRun \ndocker stop\n with the container ID (if you are running on a server, you may have to use \nsudo\n):\n\n\ndocker stop b30f4fa5f497", 
            "title": "Installation"
        }, 
        {
            "location": "/pillar/install/#pillar-installation", 
            "text": "If you want to install Pillar as part of an all-in-one installation of the Coral Ecosystem, you can  find instructions to do that here .  When installing Pillar by itself, you can choose between installing Pillar as a Docker container, or installing from source.   Install Pillar from source  Install Pillar as a Docker container", 
            "title": "Pillar Installation"
        }, 
        {
            "location": "/pillar/install/#before-you-begin", 
            "text": "Before you install Pillar, you must have the following items installed and running:   MongoDB : You can find instructions on installing MongoDB  on the MongoDB website .  There are  instructions on importing sample comment data into MongoDB here    RabbitMQ : You can find instructions on installing RabbitMQ  on the RabbitMQ website .  Xenia : Xenia is a configurable service layer that publishes endpoints against MongoDB aggregation pipeline queries. It is part of the Coral ecosystem. You can find instructions on how to install Xenia  here .", 
            "title": "Before you begin"
        }, 
        {
            "location": "/pillar/install/#install-pillar-from-source", 
            "text": "", 
            "title": "Install Pillar from source"
        }, 
        {
            "location": "/pillar/install/#before-you-begin_1", 
            "text": "If you want to install from source, you will need to have Go installed.  You can install  install Go from their website . The  installation and setup instructions  on the Go website are quite good. Ensure that you have exported your $GOPATH environment variable, as detailed in the  installation instructions .  If you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.  export GO15VENDOREXPERIMENT=1  If you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/pillar/install/#get-the-source-code", 
            "text": "You can install the source code via using the  go get  command, or by manually cloning the code.", 
            "title": "Get the source code"
        }, 
        {
            "location": "/pillar/install/#using-the-go-get-command", 
            "text": "go get github.com/coralproject/pillar  If you see a message about  no buildable Go source files  as shown below, you can ignore it. It simply means that there are no buildable source files in the uppermost pillar directory (though there are buildable source files in subdirectories).  package github.com/coralproject/pillar: no buildable Go source files in [directory]", 
            "title": "Using the go get command"
        }, 
        {
            "location": "/pillar/install/#cloning-manually", 
            "text": "You can also clone the code manually (this does the same thing as the  go get  command above).  mkdir $GOPATH/src/github.com/coralproject/pillar\ncd $GOPATH/src/github.com/coralproject/pillar\n\ngit clone https://github.com/coralproject/pillar.git", 
            "title": "Cloning manually"
        }, 
        {
            "location": "/pillar/install/#set-your-environment-variables", 
            "text": "Setting your environment variables tells Pillar the URLs and other information for communicating with MongoDB, RabbitMQ, and Xenia.  Make your own copy of the  config/dev.cfg  file (you can edit this configuration file with your own values, and then ensure that you don t commit it back to the repository). Call your config file whatever you like; we ll call it  custom  in this example.  cd $GOPATH/src/github.com/coralproject/pillar\ncp config/dev.cfg config/custom.cfg  Now edit the values in your custom.cfg file:  #Resources\nexport MONGODB_URL= mongodb://localhost:27017/coral \nexport AMQP_URL= amqp://localhost:5672/ \nexport AMQP_EXCHANGE= PillarMQ \n\n#Pillar\nexport PILLAR_ADDRESS= :8080 \nexport PILLAR_HOME= /opt/pillar \nexport PILLAR_CRON= false \nexport PILLAR_CRON_SEARCH= @every 30m \nexport PILLAR_CRON_STATS= @every 1m \n\n#Xenia\nexport XENIA_URL= http://localhost:4000/1.0/exec/ \nexport XENIA_QUERY_PARAM= ?skip=0 limit=100 \nexport XENIA_AUTH= auth token \n\n# Stats\nexport MONGODB_ADDRESS= 127.0.0.1:27017 \nexport MONGODB_USERNAME= \nexport MONGODB_PASSWORD= \nexport MONGODB_DATABASE= \nexport MONGODB_SSL= False    For  XENIA_URL :  If you installed  locally from source ,  XENIA_URL  should be  http://localhost:4000/1.0/exec/ .    For  MONGODB_URL :  If your MongoDB is a local installation,  MONGODB_URL  should be  mongodb://localhost:27017/coral .    For  AMQP_URL :  If your RabbitMQ is a local installation,  AMQP_URL  should be  amqp://localhost:5672/ .     Once you ve edited and saved your custom.cfg file, source it with the following command:  source $GOPATH/src/github.com/coralproject/pillar/config/custom.cfg", 
            "title": "Set your environment variables"
        }, 
        {
            "location": "/pillar/install/#run-pillar", 
            "text": "$GOPATH/bin/pillar  You should see:  [negroni] listening on :8080", 
            "title": "Run Pillar"
        }, 
        {
            "location": "/pillar/install/#install-as-docker-container", 
            "text": "", 
            "title": "Install as Docker Container"
        }, 
        {
            "location": "/pillar/install/#install-docker", 
            "text": "You can find more information on installing Docker on your machine  on the Docker website .   On the server, you can install Docker with the following command:   sudo yum install docker", 
            "title": "Install Docker"
        }, 
        {
            "location": "/pillar/install/#clone-the-pillar-repository", 
            "text": "Clone the Pillar repository:  git clone https://github.com/coralproject/pillar.git  Then cd into the Pillar directory.  cd pillar", 
            "title": "Clone the Pillar repository"
        }, 
        {
            "location": "/pillar/install/#start-docker", 
            "text": "Start Docker.   On the server, you can do this via the command:\n   sudo service docker start  On your local machine, you can start Docker via the Docker Quickstart Terminal. This will usually be in your Applications folder, or (if on Mac) you can type  docker quickstart  into Spotlight to find it quickly. The Docker Quickstart Terminal will open a new terminal window, running Docker, that you will then use to run the rest of the Docker related commands below.  If, at any point, you see the error message  Cannot connect to the Docker daemon. Is the docker daemon running on this host? , this probably means that you are not running Docker commands within the Docker Quickstart Terminal. Make sure that you ve opened up the Docker Quickstart Terminal and are running your Docker commands there.", 
            "title": "Start Docker"
        }, 
        {
            "location": "/pillar/install/#build-pillar-server", 
            "text": "Build the Pillar server using  docker build .  docker build -t pillar-server:0.1 .   If you are building on the server, you may have to use  sudo :   sudo docker build -t pillar-server:0.1 .", 
            "title": "Build Pillar server"
        }, 
        {
            "location": "/pillar/install/#edit-environment-variables", 
            "text": "The env.list file contains environment variables you need to set. Edit this file to reflect the settings on your own system.  MONGODB_URL= mongodb://localhost:27017/coral \nAMQP_URL= amqp://localhost:5672/ \nAMQP_EXCHANGE= PillarMQ \n\nPILLAR_ADDRESS= :8080 \nPILLAR_HOME= /opt/pillar \nPILLAR_CRON= false \nPILLAR_CRON_SEARCH= @every 30m \nPILLAR_CRON_STATS= @every 1m \n\nXENIA_URL= http://localhost:4000/1.0/exec/ \nXENIA_QUERY_PARAM= ?skip=0 limit=100 \nXENIA_AUTH= auth token \n\nMONGODB_ADDRESS= 127.0.0.1:27017 \nMONGODB_USERNAME= \nMONGODB_PASSWORD= \nMONGODB_DATABASE= \nMONGODB_SSL= False    For  XENIA_URL :  If you installed  locally ,  XENIA_URL  should be  http://localhost:4000/1.0/exec/ .    For  MONGODB_URL :  If your MongoDB is a local installation,  MONGODB_URL  should be  mongodb://localhost:27017/coral .  If your MongoDB is a local installation,  MONGODB_ADDRESS  should be  127.0.0.1:27017 .    For  AMQP_URL :  If your RabbitMQ is a local installation,  AMQP_URL  should be  amqp://localhost:5672/ .", 
            "title": "Edit environment variables"
        }, 
        {
            "location": "/pillar/install/#run-docker", 
            "text": "First, find the Image ID for the Pillar server:  docker images   If you are running on a server, you may have to use  sudo .   This shows you the Image ID:  REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\npillar-server       0.1                 24b7acf7a4b3        4 hours ago         771 MB\ngolang              1.6                 024309f28934        8 days ago          744.1 MB  Then run the docker run command with the Image ID:  docker run --env-file env.list --publish 8080:8080 24b7acf7a4b3  You should see the following:  [negroni] listening on :8080", 
            "title": "Run Docker"
        }, 
        {
            "location": "/pillar/install/#test-it-out", 
            "text": "To see if Pillar is working correctly, visit this url:  http://10.0.4.105:8080/about .  http://10.0.4.105  is the URL generated by Docker for Pillar.  If things are running properly, you should see this text:  { App : Coral Pillar Web Service , Version : Version - 0.0.1 }", 
            "title": "Test it out"
        }, 
        {
            "location": "/pillar/install/#shutting-pillar-down", 
            "text": "", 
            "title": "Shutting Pillar down"
        }, 
        {
            "location": "/pillar/install/#shutting-pillar-down-when-running-from-source", 
            "text": "If you installed and ran Pillar from source using the command  $GOPATH/bin/pillar , you can shut it down by using the Ctrl + C command.", 
            "title": "Shutting Pillar down when running from source"
        }, 
        {
            "location": "/pillar/install/#shutting-pillar-down-when-running-as-a-docker-container", 
            "text": "To shut Pillar down when running as Docker container, first find the container ID (if you are running on a server, you may have to use  sudo ):  docker ps  Find the container ID for Pillar:  CONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                                                                                        NAMES\nb30f4fa5f497        coralproject/pillar       /bin/sh -c /go/bin/p    3 days ago          Up 3 days           0.0.0.0:32776- 8080/tcp                                                                      proxy_pillarapp_1  Run  docker stop  with the container ID (if you are running on a server, you may have to use  sudo ):  docker stop b30f4fa5f497", 
            "title": "Shutting Pillar down when running as a Docker container"
        }, 
        {
            "location": "/pillar/api/", 
            "text": "API Overview\n\n\nThis section is under construction, and is not currently complete.\n\n\n\n\n\n\nThe Pillar API adheres strongly to \nREST style\n.\n\n\n\n\n\n\nThe Pillar API works only with \nJSON\n data.\n\n\n\n\n\n\nThe regular \nCRUD\n endpoint URL pattern is \n/api/*\n, where as the URL pattern for import endpoints is \n/api/import/*\n.\n\n\n\n\n\n\nImport-related endpoints allow you to import data into Coral from an existing source system (i.e., an existing database of comment information).\n\n\n\n\nCoral keeps track of the original identifiers (i.e., the user id), and stores that data (using a structure called \nImportSource\n) in a field named \nSource\n. That means you won\nt lose the original identifier data from your original source when you import into Coral.\n\n\n\n\n\n\n\n\nAll import endpoints \nupsert\n data. This means that when you import an entry, it will overwrite the information for that entry if the entry already exists. This prevents duplications and other problems.\n\n\n\n\n\n\nImport endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/import/action\n\n\nGET\n\n\nImport action\n\n\n\n\n\n\n/api/import/asset\n\n\nGET\n\n\nImport asset\n\n\n\n\n\n\n/api/import/comment\n\n\nGET\n\n\nImport comment\n\n\n\n\n\n\n/api/import/note\n\n\nGET\n\n\nImport note\n\n\n\n\n\n\n/api/import/user\n\n\nGET\n\n\nImport user\n\n\n\n\n\n\n\n\nTag endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/tags\n\n\nGET\n\n\nGet tags\n\n\n\n\n\n\n/api/tag\n\n\nPOST\n\n\nCreate or update tag\n\n\n\n\n\n\n/api/tag\n\n\nDELETE\n\n\nDelete tag\n\n\n\n\n\n\n\n\nSearch endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/searches\n\n\nGET\n\n\nGet searches\n\n\n\n\n\n\n/api/search/{id}\n\n\nGET\n\n\nGet search by id\n\n\n\n\n\n\n/api/search\n\n\nPUT\n\n\nCreate or update search\n\n\n\n\n\n\n/api/search\n\n\nPOST\n\n\nCreate or update search\n\n\n\n\n\n\n/api/search/{id}\n\n\nDELETE\n\n\nDelete search by id\n\n\n\n\n\n\n\n\nManage user activities endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/cay/useraction\n\n\nPOST\n\n\nCreate or update user action\n\n\n\n\n\n\n\n\nCreate / update endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/author\n\n\nPOST\n\n\nCreate or update author\n\n\n\n\n\n\n/api/asset\n\n\nPOST\n\n\nCreate or update asset\n\n\n\n\n\n\n/api/comment\n\n\nPOST\n\n\nCreate or update comment\n\n\n\n\n\n\n/api/index\n\n\nPOST\n\n\nCreate index\n\n\n\n\n\n\n/api/metadata\n\n\nPOST\n\n\nUpdate metadata\n\n\n\n\n\n\n/api/section\n\n\nPOST\n\n\nCreate or update section\n\n\n\n\n\n\n/api/user\n\n\nPOST\n\n\nCreate or update user\n\n\n\n\n\n\n\n\nForm endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/form\n\n\nPOST\n\n\nCreate or update form\n\n\n\n\n\n\n/api/form\n\n\nPUT\n\n\nCreate or update form\n\n\n\n\n\n\n/api/form/{id}/status/{status}\n\n\nPOST\n\n\nUpdate form status\n\n\n\n\n\n\n/api/forms\n\n\nGET\n\n\nGet forms\n\n\n\n\n\n\n/api/form/{id}\n\n\nGET\n\n\nGet form by id\n\n\n\n\n\n\n/api/form/{id}\n\n\nDELETE\n\n\nDelete form\n\n\n\n\n\n\n\n\nForm submission endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{form_id}\n\n\nPOST\n\n\nCreate form submission\n\n\n\n\n\n\n/api/form_submission/{id}/status/{status}\n\n\nPUT\n\n\nUpdate form submission status\n\n\n\n\n\n\n/api/form_submissions/{form_id}\n\n\nGET\n\n\nGet form submissions by form\n\n\n\n\n\n\n/api/form_submission/{id}\n\n\nGET\n\n\nGet form submission\n\n\n\n\n\n\n/api/form_submission/{id}/{answer_id}\n\n\nPUT\n\n\nEdit form submission answer\n\n\n\n\n\n\n/api/form_submission/{id}/flag/{flag}\n\n\nPUT\n\n\nAdd flag to form submission\n\n\n\n\n\n\n/api/form_submission/{id}/flag/{flag}\n\n\nDELETE\n\n\nDelete flag from form submission\n\n\n\n\n\n\n/api/form_submission/{id}\n\n\nDELETE\n\n\nDelete form submission\n\n\n\n\n\n\n\n\nForm galleries endpoints\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/form_gallery/{id}\n\n\nGET\n\n\nGet form gallery\n\n\n\n\n\n\n/api/form_galleries/{form_id}\n\n\nGET\n\n\nGet form galleries by form\n\n\n\n\n\n\n/api/form_galleries/form/{form_id}\n\n\nGET\n\n\nGet form galleries by form (version 2)\n\n\n\n\n\n\n/api/form_gallery/{id}/add/{submission_id}/{answer_id}\n\n\nPUT\n\n\nAdd answer to form gallery\n\n\n\n\n\n\n/api/form_gallery/{id}/remove/{submission_id}/{answer_id}\n\n\nDELETE\n\n\nRemove answer from form gallery\n\n\n\n\n\n\n\n\nImport action\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/action\n\n\nGET\n\n\nImport action\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/action\n\n\n\n\nExample response\n\n\n{\n  \nresults\n: [\n    {\n      \nplayerName\n: \nJang Min Chul\n,\n      \nupdatedAt\n: \n2011-08-19T02:24:17.787Z\n,\n      \ncheatMode\n: false,\n      \ncreatedAt\n: \n2011-08-19T02:24:17.787Z\n,\n      \nobjectId\n: \nA22v5zRAgd\n,\n      \nscore\n: 80075\n    },\n    {\n      \nplayerName\n: \nSean Plott\n,\n      \nupdatedAt\n: \n2011-08-21T18:02:52.248Z\n,\n      \ncheatMode\n: false,\n      \ncreatedAt\n: \n2011-08-20T02:06:57.931Z\n,\n      \nobjectId\n: \nEd1nuqPvcm\n,\n      \nscore\n: 73453\n    }\n  ]\n}\n\n\n\n\nImport asset\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/asset\n\n\nGET\n\n\nImport asset\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/asset\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nImport comment\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/comment\n\n\nGET\n\n\nImport comment\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/comment\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nImport note\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/note\n\n\nGET\n\n\nImport note\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/note\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nImport user\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/import/user\n\n\nGET\n\n\nImport user\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/import/user\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet tags\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/tags\n\n\nGET\n\n\nGet tags\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/tags\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nCreate or update tag\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/tag\n\n\nPOST\n\n\nCreate or update tag\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nMessage body\n\n\nbody here\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/tag\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nDelete tag\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/tag\n\n\nPOST\n\n\nCreate or update tag\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nMessage body\n\n\nbody\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/tag\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet searches\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/searches\n\n\nGET\n\n\nGet searches\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/searches\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nGet search by id\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/search/{id}\n\n\nGET\n\n\nGet search by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: search id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/search/123\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nCreate or update search (put)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/search\n\n\nPUT\n\n\nCreate or update search\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: search id\n\n\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/search\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update search (post)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/search\n\n\nPUT\n\n\nCreate or update search\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: search id\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/search\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nDelete search\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/search{id}\n\n\nDELETE\n\n\nDelete search by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: search id\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/search/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update user action\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/cay/useraction\n\n\nPOST\n\n\nCreate or update user action\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: user id\n\n\n\n\nMessage body\n\n\n.\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/cay/useraction?userid=123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update author\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/author/{id}\n\n\nPOST\n\n\nCreate or update author\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: author id\n\n\n\n\nMessage body\n\n\n.\n\n\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/author/456\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update asset\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/asset/{id}\n\n\nPOST\n\n\nCreate or update asset\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: asset id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/asset/456\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update comment\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/comment/{id}\n\n\nPOST\n\n\nCreate or update comment\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: comment id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/comment/456\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate index\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/index/{id}\n\n\nPOST\n\n\nCreate index\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: index id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/index/678\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nUpdate metadata\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/metadata/{id}\n\n\nPOST\n\n\nUpdate metadata\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: metadata id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/metadata/789\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update section\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/section/{id}\n\n\nPOST\n\n\nCreate or update section\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: section id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/section/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update user\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/user/{id}\n\n\nPOST\n\n\nCreate or update user\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: user id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/user/234\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update form (post)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}\n\n\nPOST\n\n\nCreate or update form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate or update form (put)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}\n\n\nPUT\n\n\nCreate or update form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: asset id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nUpdate form status\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}/status/{status}\n\n\nPOST\n\n\nUpdate form status\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nid\n: updated form status (what are the available form status options?)\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/form/123/status/complete\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet forms\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/forms\n\n\nGET\n\n\nGet all forms\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/forms\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nGet form by id\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}\n\n\nGET\n\n\nGet form by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\n.\n\n\n\n\nDelete form\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{id}\n\n\nDELETE\n\n\nDelete form by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nCreate form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form/{form_id}\n\n\nPOST\n\n\nCreate form submission by id\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nform_id\n: form id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPOST\nhttps://localhost:8080/api/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nUpdate form submission status\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}/status/{status}\n\n\nPUT\n\n\nUpdate form submission status\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nstatus\n: updated form submission status\n\n\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/form_submission/123/status/completed\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet form submissions by form\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submissions/{form_id}\n\n\nGET\n\n\nGet form submission by form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nform_id\n: form id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_submissions/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}\n\n\nGET\n\n\nGet form submission\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_submission/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nEdit form submission answer\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}/{answer_id}\n\n\nPUT\n\n\nEdit form submission answer\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nanswer_id\n: answer id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/form_submission/123/456\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nAdd flag to form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}/flag/{flag}\n\n\nPUT\n\n\nAdd flag to form submission\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nflag\n: updated flag\n\n\n\n\nExample call\n\n\nPUT\nhttps://localhost:8080/api/form_submission/123/flag/g\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nDelete flag from form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}/flag/{flag}\n\n\nDELETE\n\n\nDelete flag from form submission\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\nflag\n: flag to delete\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/form_submission/123/flag/g\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nDelete form submission\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_submission/{id}\n\n\nDELETE\n\n\nDelete form submission\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form id\n\n\n\n\nExample call\n\n\nDELETE\nhttps://localhost:8080/api/form_submission/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet form gallery\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_gallery/{id}\n\n\nGET\n\n\nGet form gallery\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form gallery id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_gallery/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet form galleries by form\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_galleries/{form_id}\n\n\nGET\n\n\nGet form galleries by form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nform_id\n: form gallery id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_galleries/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nGet form galleries by form (version 2)\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_galleries/form/{form_id}\n\n\nGET\n\n\nGet form galleries by form\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nform_id\n: form gallery id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_galleries/form/123\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nAdd answer to form gallery\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_gallery/{id}/add/{submission_id}/{answer_id}\n\n\nPUT\n\n\nAdd answer to form gallery\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form gallery id\n\n\nsubmission_id\n: submission id\n\n\nanswer_id\n: answer id\n\n\n\n\nMessage body\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_gallery/123/add/456/789\n\n\n\n\nExample response\n\n\nStatus: 200 OK\n\n\n\n\nRemove answer from form gallery\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/api/form_gallery/{id}/remove/{submission_id}/{answer_id}\n\n\nDELETE\n\n\nRemove answer from form gallery\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\nid\n: form gallery id\n\n\nsubmission_id\n: submission id\n\n\nanswer_id\n: answer id\n\n\n\n\nExample call\n\n\nGET\nhttps://localhost:8080/api/form_gallery/123/remove/456/789\n\n\n\n\nExample response\n\n\nStatus: 200 OK", 
            "title": "API"
        }, 
        {
            "location": "/pillar/api/#api-overview", 
            "text": "This section is under construction, and is not currently complete.    The Pillar API adheres strongly to  REST style .    The Pillar API works only with  JSON  data.    The regular  CRUD  endpoint URL pattern is  /api/* , where as the URL pattern for import endpoints is  /api/import/* .    Import-related endpoints allow you to import data into Coral from an existing source system (i.e., an existing database of comment information).   Coral keeps track of the original identifiers (i.e., the user id), and stores that data (using a structure called  ImportSource ) in a field named  Source . That means you won t lose the original identifier data from your original source when you import into Coral.     All import endpoints  upsert  data. This means that when you import an entry, it will overwrite the information for that entry if the entry already exists. This prevents duplications and other problems.", 
            "title": "API Overview"
        }, 
        {
            "location": "/pillar/api/#import-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/import/action  GET  Import action    /api/import/asset  GET  Import asset    /api/import/comment  GET  Import comment    /api/import/note  GET  Import note    /api/import/user  GET  Import user", 
            "title": "Import endpoints"
        }, 
        {
            "location": "/pillar/api/#tag-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/tags  GET  Get tags    /api/tag  POST  Create or update tag    /api/tag  DELETE  Delete tag", 
            "title": "Tag endpoints"
        }, 
        {
            "location": "/pillar/api/#search-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/searches  GET  Get searches    /api/search/{id}  GET  Get search by id    /api/search  PUT  Create or update search    /api/search  POST  Create or update search    /api/search/{id}  DELETE  Delete search by id", 
            "title": "Search endpoints"
        }, 
        {
            "location": "/pillar/api/#manage-user-activities-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/cay/useraction  POST  Create or update user action", 
            "title": "Manage user activities endpoints"
        }, 
        {
            "location": "/pillar/api/#create-update-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/author  POST  Create or update author    /api/asset  POST  Create or update asset    /api/comment  POST  Create or update comment    /api/index  POST  Create index    /api/metadata  POST  Update metadata    /api/section  POST  Create or update section    /api/user  POST  Create or update user", 
            "title": "Create / update endpoints"
        }, 
        {
            "location": "/pillar/api/#form-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/form  POST  Create or update form    /api/form  PUT  Create or update form    /api/form/{id}/status/{status}  POST  Update form status    /api/forms  GET  Get forms    /api/form/{id}  GET  Get form by id    /api/form/{id}  DELETE  Delete form", 
            "title": "Form endpoints"
        }, 
        {
            "location": "/pillar/api/#form-submission-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/form_submission/{form_id}  POST  Create form submission    /api/form_submission/{id}/status/{status}  PUT  Update form submission status    /api/form_submissions/{form_id}  GET  Get form submissions by form    /api/form_submission/{id}  GET  Get form submission    /api/form_submission/{id}/{answer_id}  PUT  Edit form submission answer    /api/form_submission/{id}/flag/{flag}  PUT  Add flag to form submission    /api/form_submission/{id}/flag/{flag}  DELETE  Delete flag from form submission    /api/form_submission/{id}  DELETE  Delete form submission", 
            "title": "Form submission endpoints"
        }, 
        {
            "location": "/pillar/api/#form-galleries-endpoints", 
            "text": "URL  HTTP Verb  Description      /api/form_gallery/{id}  GET  Get form gallery    /api/form_galleries/{form_id}  GET  Get form galleries by form    /api/form_galleries/form/{form_id}  GET  Get form galleries by form (version 2)    /api/form_gallery/{id}/add/{submission_id}/{answer_id}  PUT  Add answer to form gallery    /api/form_gallery/{id}/remove/{submission_id}/{answer_id}  DELETE  Remove answer from form gallery", 
            "title": "Form galleries endpoints"
        }, 
        {
            "location": "/pillar/api/#import-action", 
            "text": "URL  HTTP Verb  Functionality      /api/import/action  GET  Import action", 
            "title": "Import action"
        }, 
        {
            "location": "/pillar/api/#parameters", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call", 
            "text": "GET\nhttps://localhost:8080/api/import/action", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response", 
            "text": "{\n   results : [\n    {\n       playerName :  Jang Min Chul ,\n       updatedAt :  2011-08-19T02:24:17.787Z ,\n       cheatMode : false,\n       createdAt :  2011-08-19T02:24:17.787Z ,\n       objectId :  A22v5zRAgd ,\n       score : 80075\n    },\n    {\n       playerName :  Sean Plott ,\n       updatedAt :  2011-08-21T18:02:52.248Z ,\n       cheatMode : false,\n       createdAt :  2011-08-20T02:06:57.931Z ,\n       objectId :  Ed1nuqPvcm ,\n       score : 73453\n    }\n  ]\n}", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#import-asset", 
            "text": "URL  HTTP Verb  Functionality      /api/import/asset  GET  Import asset", 
            "title": "Import asset"
        }, 
        {
            "location": "/pillar/api/#parameters_1", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_1", 
            "text": "GET\nhttps://localhost:8080/api/import/asset", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_1", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#import-comment", 
            "text": "URL  HTTP Verb  Functionality      /api/import/comment  GET  Import comment", 
            "title": "Import comment"
        }, 
        {
            "location": "/pillar/api/#parameters_2", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_2", 
            "text": "GET\nhttps://localhost:8080/api/import/comment", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_2", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#import-note", 
            "text": "URL  HTTP Verb  Functionality      /api/import/note  GET  Import note", 
            "title": "Import note"
        }, 
        {
            "location": "/pillar/api/#parameters_3", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_3", 
            "text": "GET\nhttps://localhost:8080/api/import/note", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_3", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#import-user", 
            "text": "URL  HTTP Verb  Functionality      /api/import/user  GET  Import user", 
            "title": "Import user"
        }, 
        {
            "location": "/pillar/api/#parameters_4", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_4", 
            "text": "GET\nhttps://localhost:8080/api/import/user", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_4", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-tags", 
            "text": "URL  HTTP Verb  Functionality      /api/tags  GET  Get tags", 
            "title": "Get tags"
        }, 
        {
            "location": "/pillar/api/#parameters_5", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_5", 
            "text": "GET\nhttps://localhost:8080/api/tags", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_5", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-tag", 
            "text": "URL  HTTP Verb  Functionality      /api/tag  POST  Create or update tag", 
            "title": "Create or update tag"
        }, 
        {
            "location": "/pillar/api/#parameters_6", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body", 
            "text": "body here", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_6", 
            "text": "POST\nhttps://localhost:8080/api/tag", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_6", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#delete-tag", 
            "text": "URL  HTTP Verb  Functionality      /api/tag  POST  Create or update tag", 
            "title": "Delete tag"
        }, 
        {
            "location": "/pillar/api/#parameters_7", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_1", 
            "text": "body", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_7", 
            "text": "DELETE\nhttps://localhost:8080/api/tag", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_7", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-searches", 
            "text": "URL  HTTP Verb  Functionality      /api/searches  GET  Get searches", 
            "title": "Get searches"
        }, 
        {
            "location": "/pillar/api/#parameters_8", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_8", 
            "text": "GET\nhttps://localhost:8080/api/searches", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_8", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-search-by-id", 
            "text": "URL  HTTP Verb  Functionality      /api/search/{id}  GET  Get search by id", 
            "title": "Get search by id"
        }, 
        {
            "location": "/pillar/api/#parameters_9", 
            "text": "id : search id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_9", 
            "text": "GET\nhttps://localhost:8080/api/search/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_9", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-search-put", 
            "text": "URL  HTTP Verb  Functionality      /api/search  PUT  Create or update search", 
            "title": "Create or update search (put)"
        }, 
        {
            "location": "/pillar/api/#parameters_10", 
            "text": "id : search id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_10", 
            "text": "PUT\nhttps://localhost:8080/api/search", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_10", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-search-post", 
            "text": "URL  HTTP Verb  Functionality      /api/search  PUT  Create or update search", 
            "title": "Create or update search (post)"
        }, 
        {
            "location": "/pillar/api/#parameters_11", 
            "text": "id : search id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_11", 
            "text": "POST\nhttps://localhost:8080/api/search", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_11", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#delete-search", 
            "text": "URL  HTTP Verb  Functionality      /api/search{id}  DELETE  Delete search by id", 
            "title": "Delete search"
        }, 
        {
            "location": "/pillar/api/#parameters_12", 
            "text": "id : search id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_12", 
            "text": "DELETE\nhttps://localhost:8080/api/search/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_12", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-user-action", 
            "text": "URL  HTTP Verb  Functionality      /api/cay/useraction  POST  Create or update user action", 
            "title": "Create or update user action"
        }, 
        {
            "location": "/pillar/api/#parameters_13", 
            "text": "id : user id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_2", 
            "text": ".", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_13", 
            "text": "POST\nhttps://localhost:8080/api/cay/useraction?userid=123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_13", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-author", 
            "text": "URL  HTTP Verb  Functionality      /api/author/{id}  POST  Create or update author", 
            "title": "Create or update author"
        }, 
        {
            "location": "/pillar/api/#parameters_14", 
            "text": "id : author id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_3", 
            "text": ".", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_14", 
            "text": "POST\nhttps://localhost:8080/api/author/456", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_14", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-asset", 
            "text": "URL  HTTP Verb  Functionality      /api/asset/{id}  POST  Create or update asset", 
            "title": "Create or update asset"
        }, 
        {
            "location": "/pillar/api/#parameters_15", 
            "text": "id : asset id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_4", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_15", 
            "text": "POST\nhttps://localhost:8080/api/asset/456", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_15", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-comment", 
            "text": "URL  HTTP Verb  Functionality      /api/comment/{id}  POST  Create or update comment", 
            "title": "Create or update comment"
        }, 
        {
            "location": "/pillar/api/#parameters_16", 
            "text": "id : comment id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_5", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_16", 
            "text": "POST\nhttps://localhost:8080/api/comment/456", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_16", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-index", 
            "text": "URL  HTTP Verb  Functionality      /api/index/{id}  POST  Create index", 
            "title": "Create index"
        }, 
        {
            "location": "/pillar/api/#parameters_17", 
            "text": "id : index id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_6", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_17", 
            "text": "POST\nhttps://localhost:8080/api/index/678", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_17", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#update-metadata", 
            "text": "URL  HTTP Verb  Functionality      /api/metadata/{id}  POST  Update metadata", 
            "title": "Update metadata"
        }, 
        {
            "location": "/pillar/api/#parameters_18", 
            "text": "id : metadata id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_7", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_18", 
            "text": "POST\nhttps://localhost:8080/api/metadata/789", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_18", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-section", 
            "text": "URL  HTTP Verb  Functionality      /api/section/{id}  POST  Create or update section", 
            "title": "Create or update section"
        }, 
        {
            "location": "/pillar/api/#parameters_19", 
            "text": "id : section id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_8", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_19", 
            "text": "POST\nhttps://localhost:8080/api/section/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_19", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-user", 
            "text": "URL  HTTP Verb  Functionality      /api/user/{id}  POST  Create or update user", 
            "title": "Create or update user"
        }, 
        {
            "location": "/pillar/api/#parameters_20", 
            "text": "id : user id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_9", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_20", 
            "text": "POST\nhttps://localhost:8080/api/user/234", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_20", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-form-post", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}  POST  Create or update form", 
            "title": "Create or update form (post)"
        }, 
        {
            "location": "/pillar/api/#parameters_21", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_10", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_21", 
            "text": "POST\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_21", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-or-update-form-put", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}  PUT  Create or update form", 
            "title": "Create or update form (put)"
        }, 
        {
            "location": "/pillar/api/#parameters_22", 
            "text": "id : asset id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_11", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_22", 
            "text": "PUT\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_22", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#update-form-status", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}/status/{status}  POST  Update form status", 
            "title": "Update form status"
        }, 
        {
            "location": "/pillar/api/#parameters_23", 
            "text": "id : form id  id : updated form status (what are the available form status options?)", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_12", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_23", 
            "text": "POST\nhttps://localhost:8080/api/form/123/status/complete", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_23", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-forms", 
            "text": "URL  HTTP Verb  Functionality      /api/forms  GET  Get all forms", 
            "title": "Get forms"
        }, 
        {
            "location": "/pillar/api/#parameters_24", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_24", 
            "text": "GET\nhttps://localhost:8080/api/forms", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_24", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-form-by-id", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}  GET  Get form by id", 
            "title": "Get form by id"
        }, 
        {
            "location": "/pillar/api/#parameters_25", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_25", 
            "text": "GET\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_25", 
            "text": ".", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#delete-form", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{id}  DELETE  Delete form by id", 
            "title": "Delete form"
        }, 
        {
            "location": "/pillar/api/#parameters_26", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_26", 
            "text": "DELETE\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_26", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#create-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form/{form_id}  POST  Create form submission by id", 
            "title": "Create form submission"
        }, 
        {
            "location": "/pillar/api/#parameters_27", 
            "text": "form_id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_13", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_27", 
            "text": "POST\nhttps://localhost:8080/api/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_27", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#update-form-submission-status", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}/status/{status}  PUT  Update form submission status", 
            "title": "Update form submission status"
        }, 
        {
            "location": "/pillar/api/#parameters_28", 
            "text": "id : form id  status : updated form submission status", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_28", 
            "text": "PUT\nhttps://localhost:8080/api/form_submission/123/status/completed", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_28", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-form-submissions-by-form", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submissions/{form_id}  GET  Get form submission by form", 
            "title": "Get form submissions by form"
        }, 
        {
            "location": "/pillar/api/#parameters_29", 
            "text": "form_id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_29", 
            "text": "GET\nhttps://localhost:8080/api/form_submissions/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_29", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}  GET  Get form submission", 
            "title": "Get form submission"
        }, 
        {
            "location": "/pillar/api/#parameters_30", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_30", 
            "text": "GET\nhttps://localhost:8080/api/form_submission/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_30", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#edit-form-submission-answer", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}/{answer_id}  PUT  Edit form submission answer", 
            "title": "Edit form submission answer"
        }, 
        {
            "location": "/pillar/api/#parameters_31", 
            "text": "id : form id  answer_id : answer id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_14", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_31", 
            "text": "PUT\nhttps://localhost:8080/api/form_submission/123/456", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_31", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#add-flag-to-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}/flag/{flag}  PUT  Add flag to form submission", 
            "title": "Add flag to form submission"
        }, 
        {
            "location": "/pillar/api/#parameters_32", 
            "text": "id : form id  flag : updated flag", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_32", 
            "text": "PUT\nhttps://localhost:8080/api/form_submission/123/flag/g", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_32", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#delete-flag-from-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}/flag/{flag}  DELETE  Delete flag from form submission", 
            "title": "Delete flag from form submission"
        }, 
        {
            "location": "/pillar/api/#parameters_33", 
            "text": "id : form id  flag : flag to delete", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_33", 
            "text": "DELETE\nhttps://localhost:8080/api/form_submission/123/flag/g", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_33", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#delete-form-submission", 
            "text": "URL  HTTP Verb  Functionality      /api/form_submission/{id}  DELETE  Delete form submission", 
            "title": "Delete form submission"
        }, 
        {
            "location": "/pillar/api/#parameters_34", 
            "text": "id : form id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_34", 
            "text": "DELETE\nhttps://localhost:8080/api/form_submission/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_34", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-form-gallery", 
            "text": "URL  HTTP Verb  Functionality      /api/form_gallery/{id}  GET  Get form gallery", 
            "title": "Get form gallery"
        }, 
        {
            "location": "/pillar/api/#parameters_35", 
            "text": "id : form gallery id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_35", 
            "text": "GET\nhttps://localhost:8080/api/form_gallery/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_35", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-form-galleries-by-form", 
            "text": "URL  HTTP Verb  Functionality      /api/form_galleries/{form_id}  GET  Get form galleries by form", 
            "title": "Get form galleries by form"
        }, 
        {
            "location": "/pillar/api/#parameters_36", 
            "text": "form_id : form gallery id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_36", 
            "text": "GET\nhttps://localhost:8080/api/form_galleries/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_36", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#get-form-galleries-by-form-version-2", 
            "text": "URL  HTTP Verb  Functionality      /api/form_galleries/form/{form_id}  GET  Get form galleries by form", 
            "title": "Get form galleries by form (version 2)"
        }, 
        {
            "location": "/pillar/api/#parameters_37", 
            "text": "form_id : form gallery id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_37", 
            "text": "GET\nhttps://localhost:8080/api/form_galleries/form/123", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_37", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#add-answer-to-form-gallery", 
            "text": "URL  HTTP Verb  Functionality      /api/form_gallery/{id}/add/{submission_id}/{answer_id}  PUT  Add answer to form gallery", 
            "title": "Add answer to form gallery"
        }, 
        {
            "location": "/pillar/api/#parameters_38", 
            "text": "id : form gallery id  submission_id : submission id  answer_id : answer id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#message-body_15", 
            "text": "", 
            "title": "Message body"
        }, 
        {
            "location": "/pillar/api/#example-call_38", 
            "text": "GET\nhttps://localhost:8080/api/form_gallery/123/add/456/789", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_38", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/pillar/api/#remove-answer-from-form-gallery", 
            "text": "URL  HTTP Verb  Functionality      /api/form_gallery/{id}/remove/{submission_id}/{answer_id}  DELETE  Remove answer from form gallery", 
            "title": "Remove answer from form gallery"
        }, 
        {
            "location": "/pillar/api/#parameters_39", 
            "text": "id : form gallery id  submission_id : submission id  answer_id : answer id", 
            "title": "Parameters"
        }, 
        {
            "location": "/pillar/api/#example-call_39", 
            "text": "GET\nhttps://localhost:8080/api/form_gallery/123/remove/456/789", 
            "title": "Example call"
        }, 
        {
            "location": "/pillar/api/#example-response_39", 
            "text": "Status: 200 OK", 
            "title": "Example response"
        }, 
        {
            "location": "/sponge/", 
            "text": "Introduction\n\n\nSponge is a data import service used to get your existing community (comments, authors, assets, and other entities) into the Coral ecosystem.\n\n\nIt is an Extract, Transform, and Load command line tool designed to:\n\n\n\n\nRead data from a foreign source,\n\n\nTranslate the schema into Coral conventions, and\n\n\nPOST entities to our service layer for insertion.\n\n\n\n\nSponge uses strategy files to assist with data import. Strategy files are JSON files that are used to tell Sponge where to get the data, and how to translate it. You can read more about \nstrategy files here\n, including information on their structure and examples.\n\n\nComposition\n\n\nSponge is made up of several different packages, and you can read more about them on the \nIncluded Packages page\n. They work together as shown in the diagram below:\n\n\n\n\nData import sources supported\n\n\nSponge currently only supports importing data from mySQL, PostgreSQL, MongoDB or web services with REST APIs.\n\n\nCommand line tool\n\n\nUsage:\n\n\nsponge \nflag [command]\n\n\nAvailable Commands:\n\n\n\n\nimport      Import data to the coral database\n\n\nindex       Work with indexes in the coral database\n\n\nshow        Read the report on errors\n\n\nversion     Print the version number of Sponge\n\n\nall         Import and Create Indexes\n\n\n\n\nFlags\n\n\n      --dbname=\nreport.db\n: set the name for the db to read\n      --filepath=\nreport.db\n: set the file path for the report on errors (default is report.db)\n  -h, --help[=false]: help for sponge\n      --limit=9999999999: number of rows that we are going to import (default is 9999999999)\n      --offset=0: offset for rows to import (default is 0)\n      --onlyfails[=false]: import only the the records that failed in the last import(default is import all)\n      --orderby=\n: order by field on the external source (default is not ordered)\n      --query=\n: query on the external table (where condition on mysql, query document on mongodb). It only works with a specific --type. Example updated_date \n'2003-12-31 01:02:03'\n      --report[=false]: create report on records that fail importing (default is do not report)\n      --type=\n: import or create indexes for only these types of data (default is everything)\n\n\n\n\nSponge roadmap\n\n\nThis document tracks features that are not yet prioritized into issues and releases.\n\n\nAPI Import\n\n\nPull data from Http(s) sources\n\n\n\n\nDisqus - https://disqus.com/api/docs/\n\n\nWordpress Core - https://codex.wordpress.org/XML-RPC_WordPress_API/Comments\n\n\nLyvewire - http://answers.livefyre.com/developers/api-reference/\n\n\nFacebook - https://developers.facebook.com/docs/graph-api/reference/v2.5/comment\n\n\n\n\nRate Limit Counter\n\n\nIn order to protect source databases, we want to be able to throttle the number of queries sponge is making.\n\n\n\n\nKeeps a sliding count of how many requests were made in the past time frame based on the strategy.\n\n\nExposes isOkToQuery() to determine if we are currently at the limit.\n\n\nEach request sends a message to this routine each time a request is made.\n\n\n\n\nSynchronization\n\n\nAn internal mechanism that regularly polls the source and imports any updates.\n\n\nBasic polling specification\n\n\nThe main loop that keeps the data up to date.  Gets \nslices\n of records based on \nupdated_at\n timestamps to account for changing records.\n\n\nFor each table or api in the strategy:\n\n\n\n\nEnsure maximum rate limit is not met\n\n\nDetermine which slice of data to get next\n\n\nFind the last updated timestamp in the \nlog collection\n (or the collection itself?)\n\n\n\n\n\n\nUse the strategy to request the slice (either db query or api call)\n\n\nUpdate the rate limit counter\n\n\n\n\n\n\nFor each record returned\n\n\nCheck to ensure the document isn\nt already added\n\n\nIf not, add the document and kick off \nimport actions\n\n\nIf it\ns there, update the document\n\n\nUpdate the \nlog collection\n\n\n\n\n\n\n\n\nChallenges\n\n\nData synchronization between complex living systems is a difficult challenge. Approach with caution.", 
            "title": "Introduction"
        }, 
        {
            "location": "/sponge/#introduction", 
            "text": "Sponge is a data import service used to get your existing community (comments, authors, assets, and other entities) into the Coral ecosystem.  It is an Extract, Transform, and Load command line tool designed to:   Read data from a foreign source,  Translate the schema into Coral conventions, and  POST entities to our service layer for insertion.   Sponge uses strategy files to assist with data import. Strategy files are JSON files that are used to tell Sponge where to get the data, and how to translate it. You can read more about  strategy files here , including information on their structure and examples.", 
            "title": "Introduction"
        }, 
        {
            "location": "/sponge/#composition", 
            "text": "Sponge is made up of several different packages, and you can read more about them on the  Included Packages page . They work together as shown in the diagram below:", 
            "title": "Composition"
        }, 
        {
            "location": "/sponge/#data-import-sources-supported", 
            "text": "Sponge currently only supports importing data from mySQL, PostgreSQL, MongoDB or web services with REST APIs.", 
            "title": "Data import sources supported"
        }, 
        {
            "location": "/sponge/#command-line-tool", 
            "text": "", 
            "title": "Command line tool"
        }, 
        {
            "location": "/sponge/#usage", 
            "text": "sponge  flag [command]", 
            "title": "Usage:"
        }, 
        {
            "location": "/sponge/#available-commands", 
            "text": "import      Import data to the coral database  index       Work with indexes in the coral database  show        Read the report on errors  version     Print the version number of Sponge  all         Import and Create Indexes", 
            "title": "Available Commands:"
        }, 
        {
            "location": "/sponge/#flags", 
            "text": "--dbname= report.db : set the name for the db to read\n      --filepath= report.db : set the file path for the report on errors (default is report.db)\n  -h, --help[=false]: help for sponge\n      --limit=9999999999: number of rows that we are going to import (default is 9999999999)\n      --offset=0: offset for rows to import (default is 0)\n      --onlyfails[=false]: import only the the records that failed in the last import(default is import all)\n      --orderby= : order by field on the external source (default is not ordered)\n      --query= : query on the external table (where condition on mysql, query document on mongodb). It only works with a specific --type. Example updated_date  '2003-12-31 01:02:03'\n      --report[=false]: create report on records that fail importing (default is do not report)\n      --type= : import or create indexes for only these types of data (default is everything)", 
            "title": "Flags"
        }, 
        {
            "location": "/sponge/#sponge-roadmap", 
            "text": "This document tracks features that are not yet prioritized into issues and releases.", 
            "title": "Sponge roadmap"
        }, 
        {
            "location": "/sponge/#api-import", 
            "text": "Pull data from Http(s) sources   Disqus - https://disqus.com/api/docs/  Wordpress Core - https://codex.wordpress.org/XML-RPC_WordPress_API/Comments  Lyvewire - http://answers.livefyre.com/developers/api-reference/  Facebook - https://developers.facebook.com/docs/graph-api/reference/v2.5/comment", 
            "title": "API Import"
        }, 
        {
            "location": "/sponge/#rate-limit-counter", 
            "text": "In order to protect source databases, we want to be able to throttle the number of queries sponge is making.   Keeps a sliding count of how many requests were made in the past time frame based on the strategy.  Exposes isOkToQuery() to determine if we are currently at the limit.  Each request sends a message to this routine each time a request is made.", 
            "title": "Rate Limit Counter"
        }, 
        {
            "location": "/sponge/#synchronization", 
            "text": "An internal mechanism that regularly polls the source and imports any updates.", 
            "title": "Synchronization"
        }, 
        {
            "location": "/sponge/#basic-polling-specification", 
            "text": "The main loop that keeps the data up to date.  Gets  slices  of records based on  updated_at  timestamps to account for changing records.  For each table or api in the strategy:   Ensure maximum rate limit is not met  Determine which slice of data to get next  Find the last updated timestamp in the  log collection  (or the collection itself?)    Use the strategy to request the slice (either db query or api call)  Update the rate limit counter    For each record returned  Check to ensure the document isn t already added  If not, add the document and kick off  import actions  If it s there, update the document  Update the  log collection", 
            "title": "Basic polling specification"
        }, 
        {
            "location": "/sponge/#challenges", 
            "text": "Data synchronization between complex living systems is a difficult challenge. Approach with caution.", 
            "title": "Challenges"
        }, 
        {
            "location": "/sponge/install/", 
            "text": "Installation\n\n\nBefore you begin\n\n\nPillar\n\n\nYou will need to have an instance of \nPillar\n running, where your translated data will be sent. Instructions on installing Pillar \ncan be found here\n.\n\n\nExternal database source\n\n\nYou will also have your external database running. This external database is the source of your existing comment data that will be extracted by Sponge and sent to Pillar, which will then load it into the Coral ecosystem.\n\n\nThe external sources we currently support are: PostgreSQL, MySQL, MongoDB, and REST APIs.\n\n\nVendoring dependencies\n\n\nYou should be vendoring the packages you choose to use (\nvendoring\n is the moving of all third party items such as packages into the \n/vendor\n directory). We recommend using \ngovendor\n. This tool will manage your dependencies from the vendor folder associated with this project repository.\n\n\nInstall from source\n\n\nBefore you begin\n\n\nIf you want to install from source, you will need to have Go installed.\n\n\nFirst \ninstall Go\n. The \ninstallation and setup instructions\n on the Go website are pretty good. Ensure that you have exported your $GOPATH environment variable, as detailed in the \ninstallation instructions\n.\n\n\nIf you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.\n\n\nexport GO15VENDOREXPERIMENT=1\n\n\n\n\nIf you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.\n\n\nGet the source code\n\n\nYou can install the source code via using the \ngo get\n command, or by manually cloning the code.\n\n\nUsing the go get command\n\n\ngo get github.com/coralproject/sponge\n\n\n\n\nIf you see a message about \nno buildable Go source files\n like the below, you can ignore it. It simply means that there are buildable source files in subdirectories, just not the uppermost sponge directory.\n\n\npackage github.com/coralproject/sponge: no buildable Go source files in [directory]\n\n\n\n\nCloning manually\n\n\nYou can also clone the code manually.\n\n\nmkdir $GOPATH/src/github.com/coralproject/sponge\ncd $GOPATH/src/github.com/coralproject/sponge\n\ngit clone git@github.com:CoralProject/sponge.git\n\n\n\n\nSet up your strategy.json file\n\n\nYou can read about \nstrategy files in depth here\n.\n\n\nThe strategy.json file tells Sponge how to do the transformation between the publisher\ns existing data and the Coral data schema. It also tells us how to connect to the external publisher\ns source data. We currently support the following sources: PostgreSQL, MySQL, MongoDB, and REST APIs.\n\n\nWe have example strategy.json files for each of those source types. You can see those example strategy.json files in the \nexamples\n folder: \n$GOPATH/src/github.com/coralproject/sponge/examples\n\n\nTo copy one of the example strategy.json files to another folder, where you can then customize it:\n\n\ncp $GOPATH/src/github.com/coralproject/sponge/examples/strategy.json.example $GOPATH/src/github.com/coralproject/sponge/strategy/strategy.json\n\n\n\n\nSet your environment variables\n\n\nSetting your environment variables tells Sponge which strategy file you want to use, and the URL for the \nPillar\n instance you are pushing data to.\n\n\nMake your own copy of the \nconfig/dev.cfg\n file (you can edit this configuration file with your own values, and then ensure that you don\nt commit it back to the repository). Call your config file whatever you like; we\nll call it \ncustom\n in this example.\n\n\ncd $GOPATH/src/github.com/coralproject/sponge\ncp config/dev.cfg config/custom.cfg\n\n\n\n\nNow edit the values in your custom.cfg file:\n\n\nexport STRATEGY_CONF=/path/to/my/strategy.json\nexport PILLAR_URL=http://localhost:8080\n\n\n\n\n\n\nThe \nSTRATEGY_CONF\n variable specifies the path to your strategy.json file.\n\n\nThe \nPILLAR_URL\n variable specifies the URL where your Pillar instance is running. If you installed Pillar locally from source, this will probably be \nhttp://localhost:8080\n.\n\n\n\n\nOnce you\nve edited and saved your custom.cfg file, source it:\n\n\nsource $GOPATH/src/github.com/coralproject/sponge/config/custom.cfg\n\n\n\n\nRun Sponge\n\n\nYou can either run Sponge using Go, or via a CLI tool.\n\n\nRunning Sponge using go run\n\n\ncd $GOPATH/src/github.com/coralproject/sponge/cmd/sponge\ngo run main.go\n\n\n\n\nRunning Sponge using the CLI tool\n\n\nFirst build the CLI tool:\n\n\ncd $GOPATH/src/github.com/coralproject/cmd/cmd/sponge\ngo build\n\n\n\n\nThen run the CLI tool\n\n\n./sponge -h\n\n\n\n\nInstall as a Docker container\n\n\nBuilding image\n\n\nTo build the docker image run this command:\n\n\ndocker build -t \nsponge:latest\n -f Dockerfile ./\n\n\n\n\nEdit env.list\n\n\nSetting your environment variables tells Sponge which strategy file you want to use, and the URL for the \nPillar\n instance you are pushing data to.\n\n\nPILLAR_URL=http://192.168.99.100:8080\nSTRATEGY_CONF=/strategy/strategy_psql.json\n\n# DATABASE\n# (optional if you want to overwrite strategy file values)\nDB_database= \n\nDB_username= \n\nDB_password= \n\nDB_host= \n\nDB_port= \n\n\n# WEB SERVICE\n# (optional if you want to overwrite strategy file values)\nWS_appkey= \n\nWS_endpoint= \n\nWS_records= \n\nWS_pagination= \n\nWS_useragent= \n\nWS_attributes= \n\n\n\n\n\n\n\nThe \nSTRATEGY_CONF\n variable specifies the path to your strategy.json file.\n\n\nThe \nPILLAR_URL\n variable specifies the URL where your Pillar instance is running. If you installed Pillar as a Docker container, this will probably be \nhttp://192.168.99.100:8080\n.\n\n\n\n\nRunning the container\n\n\nIt will start importing everything setup in the \nstrategy file\n.\n\n\ndocker run --env-file env.list -d sponge", 
            "title": "Installation"
        }, 
        {
            "location": "/sponge/install/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/sponge/install/#before-you-begin", 
            "text": "", 
            "title": "Before you begin"
        }, 
        {
            "location": "/sponge/install/#pillar", 
            "text": "You will need to have an instance of  Pillar  running, where your translated data will be sent. Instructions on installing Pillar  can be found here .", 
            "title": "Pillar"
        }, 
        {
            "location": "/sponge/install/#external-database-source", 
            "text": "You will also have your external database running. This external database is the source of your existing comment data that will be extracted by Sponge and sent to Pillar, which will then load it into the Coral ecosystem.  The external sources we currently support are: PostgreSQL, MySQL, MongoDB, and REST APIs.", 
            "title": "External database source"
        }, 
        {
            "location": "/sponge/install/#vendoring-dependencies", 
            "text": "You should be vendoring the packages you choose to use ( vendoring  is the moving of all third party items such as packages into the  /vendor  directory). We recommend using  govendor . This tool will manage your dependencies from the vendor folder associated with this project repository.", 
            "title": "Vendoring dependencies"
        }, 
        {
            "location": "/sponge/install/#install-from-source", 
            "text": "", 
            "title": "Install from source"
        }, 
        {
            "location": "/sponge/install/#before-you-begin_1", 
            "text": "If you want to install from source, you will need to have Go installed.  First  install Go . The  installation and setup instructions  on the Go website are pretty good. Ensure that you have exported your $GOPATH environment variable, as detailed in the  installation instructions .  If you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.  export GO15VENDOREXPERIMENT=1  If you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/sponge/install/#get-the-source-code", 
            "text": "You can install the source code via using the  go get  command, or by manually cloning the code.", 
            "title": "Get the source code"
        }, 
        {
            "location": "/sponge/install/#using-the-go-get-command", 
            "text": "go get github.com/coralproject/sponge  If you see a message about  no buildable Go source files  like the below, you can ignore it. It simply means that there are buildable source files in subdirectories, just not the uppermost sponge directory.  package github.com/coralproject/sponge: no buildable Go source files in [directory]", 
            "title": "Using the go get command"
        }, 
        {
            "location": "/sponge/install/#cloning-manually", 
            "text": "You can also clone the code manually.  mkdir $GOPATH/src/github.com/coralproject/sponge\ncd $GOPATH/src/github.com/coralproject/sponge\n\ngit clone git@github.com:CoralProject/sponge.git", 
            "title": "Cloning manually"
        }, 
        {
            "location": "/sponge/install/#set-up-your-strategyjson-file", 
            "text": "You can read about  strategy files in depth here .  The strategy.json file tells Sponge how to do the transformation between the publisher s existing data and the Coral data schema. It also tells us how to connect to the external publisher s source data. We currently support the following sources: PostgreSQL, MySQL, MongoDB, and REST APIs.  We have example strategy.json files for each of those source types. You can see those example strategy.json files in the  examples  folder:  $GOPATH/src/github.com/coralproject/sponge/examples  To copy one of the example strategy.json files to another folder, where you can then customize it:  cp $GOPATH/src/github.com/coralproject/sponge/examples/strategy.json.example $GOPATH/src/github.com/coralproject/sponge/strategy/strategy.json", 
            "title": "Set up your strategy.json file"
        }, 
        {
            "location": "/sponge/install/#set-your-environment-variables", 
            "text": "Setting your environment variables tells Sponge which strategy file you want to use, and the URL for the  Pillar  instance you are pushing data to.  Make your own copy of the  config/dev.cfg  file (you can edit this configuration file with your own values, and then ensure that you don t commit it back to the repository). Call your config file whatever you like; we ll call it  custom  in this example.  cd $GOPATH/src/github.com/coralproject/sponge\ncp config/dev.cfg config/custom.cfg  Now edit the values in your custom.cfg file:  export STRATEGY_CONF=/path/to/my/strategy.json\nexport PILLAR_URL=http://localhost:8080   The  STRATEGY_CONF  variable specifies the path to your strategy.json file.  The  PILLAR_URL  variable specifies the URL where your Pillar instance is running. If you installed Pillar locally from source, this will probably be  http://localhost:8080 .   Once you ve edited and saved your custom.cfg file, source it:  source $GOPATH/src/github.com/coralproject/sponge/config/custom.cfg", 
            "title": "Set your environment variables"
        }, 
        {
            "location": "/sponge/install/#run-sponge", 
            "text": "You can either run Sponge using Go, or via a CLI tool.", 
            "title": "Run Sponge"
        }, 
        {
            "location": "/sponge/install/#running-sponge-using-go-run", 
            "text": "cd $GOPATH/src/github.com/coralproject/sponge/cmd/sponge\ngo run main.go", 
            "title": "Running Sponge using go run"
        }, 
        {
            "location": "/sponge/install/#running-sponge-using-the-cli-tool", 
            "text": "First build the CLI tool:  cd $GOPATH/src/github.com/coralproject/cmd/cmd/sponge\ngo build  Then run the CLI tool  ./sponge -h", 
            "title": "Running Sponge using the CLI tool"
        }, 
        {
            "location": "/sponge/install/#install-as-a-docker-container", 
            "text": "", 
            "title": "Install as a Docker container"
        }, 
        {
            "location": "/sponge/install/#building-image", 
            "text": "To build the docker image run this command:  docker build -t  sponge:latest  -f Dockerfile ./", 
            "title": "Building image"
        }, 
        {
            "location": "/sponge/install/#edit-envlist", 
            "text": "Setting your environment variables tells Sponge which strategy file you want to use, and the URL for the  Pillar  instance you are pushing data to.  PILLAR_URL=http://192.168.99.100:8080\nSTRATEGY_CONF=/strategy/strategy_psql.json\n\n# DATABASE\n# (optional if you want to overwrite strategy file values)\nDB_database=  \nDB_username=  \nDB_password=  \nDB_host=  \nDB_port=  \n\n# WEB SERVICE\n# (optional if you want to overwrite strategy file values)\nWS_appkey=  \nWS_endpoint=  \nWS_records=  \nWS_pagination=  \nWS_useragent=  \nWS_attributes=     The  STRATEGY_CONF  variable specifies the path to your strategy.json file.  The  PILLAR_URL  variable specifies the URL where your Pillar instance is running. If you installed Pillar as a Docker container, this will probably be  http://192.168.99.100:8080 .", 
            "title": "Edit env.list"
        }, 
        {
            "location": "/sponge/install/#running-the-container", 
            "text": "It will start importing everything setup in the  strategy file .  docker run --env-file env.list -d sponge", 
            "title": "Running the container"
        }, 
        {
            "location": "/sponge/included_packages/", 
            "text": "Packages included in Sponge\n\n\n\n\nStrategy\n reads the translations file.\n\n\nSource\n performs the extraction of data from the external data source.\n\n\nFiddler\n performs the transformation of data.\n\n\nCoral\n sends data to Pillar.\n\n\nSponge\n ties all the pieces together.\n\n\n\n\n\n\nStrategy\n\n\nimport \ngithub.com/coralproject/sponge/pkg/strategy\n\n\n\n\n\nThe Strategy package reads in the external \nstrategy JSON file\n and creates a structure containing translation information.\n\n\nVariables\n\n\n\n\nvar pillarURL string\n: URL that points to the Pillar instance, where the data will be sent.\n\n\nThis is initialized by the \nPILLAR_URL\n environment variable.\n\n\n\n\n\n\nvar uuid string\n: Universally Unique Identifier used for the logs.\n\n\n\n\nTo read more about strategy JSON files, you can read \nour page on strategy files\n.\n\n\nSource\n\n\nimport \ngithub.com/coralproject/sponge/pkg/source\n\n\n\n\n\nThe Source package contains the drivers that we use to connect to the external source and retrieve data. The credentials for the external data source are set up in the \nstrategy file\n.\n\n\nVariables\n\n\n\n\nvar strategy str.Strategy\n: Holds the credentials for the external source, as well as all the entities that need to be extracted.\n\n\nvar uuid string\n: Universally Unique Identifier used for the logs.\n\n\nvar credential str.Credential\n: Credential for the external source (database or web service).\n\n\n\n\nSourcer interface\n\n\nThis is the interface that needs to be implemented by any driver that connects to an external data source.\n\n\nfunc GetData\n\n\nGetData(string, *Options) ([]map[string]interface{}, error)\n\n\n\n\nReturns all the data (query by options in Options) in the format []map[string]interface{}\n\n\nfunc IsWebService\n\n\nIsWebService() bool\n\n\n\n\nReturns true if the implementation of sourcer is a web service.\n\n\nfunc New\n\n\nfunc New(d string) (Sourcer, error)\n\n\n\n\nDepending on the parameter, it returns a structure with the connection to the external source that implements the interface Sourcer.\n\n\nfunc GetEntities\n\n\nfunc GetEntities() ([]string, error)\n\n\n\n\nGets all the entities\n names from the source\n\n\nfunc GetforeignEntity\n\n\nfunc GetForeignEntity(name string) string\n\n\n\n\nGets the foreign entity\ns name for the Coral collection.\n\n\nmySQL driver\n\n\nThe mySQL driver is contained in the \nmysql.go\n file. It has a mySQL struct that implements the Sourcer interface, and enables data extraction from a mySQL database.\n\n\nPostgreSQL driver\n\n\nThe PostgreSQL driver is contained in the \npostgresql.go\n file. It has a PostgreSQL struct that implements the Sourcer interface, and enables data extraction from a PostgreSQL database.\n\n\nMongoDB driver\n\n\nThe MongoDB driver is contained in the \nmongodb.go\n file. It has a MongoDB struct that implements the Sourcer interface, and enables data extraction from a MongoDB database.\n\n\nAPI driver\n\n\nThe API driver is contained in the \napi.go\n file. It has an API struct that implements the Sourcer interface, and enables data extraction from an API interface.\n\n\nHow to add a new source\n\n\nCurrently, we offer the four drivers listed above (mySQL, PostgreSQL, MongoDB, and REST API). If you need to add a new type of external source, you can write your own driver. To write your own driver, you will implement the Sourcer interface for your type of external data source.\n\n\nFiddler\n\n\nimport \ngithub.com/coralproject/sponge/pkg/fiddler\n\n\n\n\n\nThe Fiddler package performs the translation from the external database schema into Coral\ns database schema.\n\n\nVariables\n\n\n\n\nstrategy   str.Strategy\n Holds the translation, in JSON form, to apply to the data.\n\n\ndateLayout string\n Date Layout as specified in the strategy file.\n\n\nuuid string\n Universally Unique Identifier used for the logs.\n\n\n\n\nFunctions\n\n\nfunc GetID\n\n\nfunc GetID(modelName string) string\n\n\n\n\nReturns the field that is the identifier for that model\n\n\nfunc GetCollections\n\n\nfunc GetCollections() []string\n\n\n\n\nReturns the names of all the collections in the strategy file.\n\n\nfunc TransformRow\n\n\nfunc TransformRow(row map[string]interface{}, coralName string) (interface{}, []map[string]interface{}, error)\n\n\n\n\nApplies the coral schema to a row of data from the external source.\n\n\nCoral\n\n\nNote\n: The \nCoral\n package is not to be confused with the Coral ecosystem as a whole. In this instance, this is merely the name of a package included in the Sponge app.\n\n\nimport \ngithub.com/coralproject/sponge/pkg/coral\n\n\n\n\n\nCoral interacts with Pillar endpoints to import data into the Coral system.\n\n\nConstants\n\n\n\n\nretryTimes int    = 3\n Determines how many times to retry communication with Pillar, if it initially fails.\n\n\nmethodGet  string = \"GET\"\n\n\nmethodPost string = \"POST\"\n\n\n\n\nVariables\n\n\n\n\nendpoints map[string]string\n \nendpoints\n is a map containing all of the services where we can send data. Right now, that is only Pillar.\n\n\nuuid string\n Universally Unique Identifier used for the logs.\n\n\nstr  strategy.Strategy\n Holds the translation, in JSON form, to apply to the data.\n\n\n\n\nFunctions\n\n\nfunc AddRow\n\n\nfunc AddRow(data map[string]interface{}, tableName string) error\n\n\n\n\nAdds data to the collection \ntableName\n.\n\n\nfunc CreateIndex\n\n\nfunc CreateIndex(collection string) error\n\n\n\n\nCalls the service to create index for \ncollection\n.\n\n\nSponge\n\n\nNote\n: The \nSponge\n package is not to be confused with the Sponge app as a whole. In this instance, this is merely the name of a package included in the larger Sponge app.\n\n\nimport \ngithub.com/coralproject/sponge/pkg/sponge\n\n\n\n\n\nThe Sponge package ties together all of the other packages, so that they all communicate and work with each other.\n\n\nConstants\n\n\n\n\nVersionNumber = 0.1\n Provides the version number of Sponge.\n\n\n\n\nVariables\n\n\n\n\ndbsource source.Sourcer\n\n\nuuid     string\n\n\noptions  source.Options\n\n\n\n\nFunctions\n\n\nfunc AddOptions\n\n\nfunc AddOptions(limit int, offset int, orderby string, query string, types string, importonlyfailed bool, reportOnFailedRecords bool, reportdbfile string)\n\n\n\n\nAddOptions\n sets options for how Sponge will run. The options are:\n\n\n\n\nLimit\n: limit for the query\n\n\nOffset\n: offset for the query\n\n\nOrderby\n:  order by this field\n\n\nQuery\n:  we use this field if we want to specific a filter on WHERE for mySQL/PostgreSQL and Find for MongoDB\n\n\nTypes\n: it specifies which entities to import (default is everything)\n\n\nImportonlyfailed\n: import only the documents that are in the report\n\n\nReportOnFailedRecords\n: create a report with all the documents that failed the import\n\n\nReportdbfile\n: name of the file for the report on documents that fail the import\n\n\n\n\nfunc Import\n\n\nfunc Import()\n\n\n\n\nGets data, transforms it and sends it to Pillar. It bases everything on the STRATEGY_CONF environment variable and the PILLAR_URL environment variable.\n\n\nfunc CreateIndex\n\n\nfunc CreateIndex(collection string)\n\n\n\n\nCreates index on the collection \ncollection\n. This feature creates indexes on the Coral database, depending on data in the strategy file.\n\n\nFor example:\n\n\nIndex\n: [\n  {\n    \nname\n: \nasset-url\n,\n    \nkeys\n: [\nasseturl\n],\n    \nunique\n: \ntrue\n,\n    \ndropdups\n: \ntrue\n\n  }\n],\n\n\n\n\nYou can read more information at the \nmongodb\ns create index definition\n.", 
            "title": "Included packages"
        }, 
        {
            "location": "/sponge/included_packages/#packages-included-in-sponge", 
            "text": "Strategy  reads the translations file.  Source  performs the extraction of data from the external data source.  Fiddler  performs the transformation of data.  Coral  sends data to Pillar.  Sponge  ties all the pieces together.", 
            "title": "Packages included in Sponge"
        }, 
        {
            "location": "/sponge/included_packages/#strategy", 
            "text": "import  github.com/coralproject/sponge/pkg/strategy   The Strategy package reads in the external  strategy JSON file  and creates a structure containing translation information.", 
            "title": "Strategy"
        }, 
        {
            "location": "/sponge/included_packages/#variables", 
            "text": "var pillarURL string : URL that points to the Pillar instance, where the data will be sent.  This is initialized by the  PILLAR_URL  environment variable.    var uuid string : Universally Unique Identifier used for the logs.   To read more about strategy JSON files, you can read  our page on strategy files .", 
            "title": "Variables"
        }, 
        {
            "location": "/sponge/included_packages/#source", 
            "text": "import  github.com/coralproject/sponge/pkg/source   The Source package contains the drivers that we use to connect to the external source and retrieve data. The credentials for the external data source are set up in the  strategy file .", 
            "title": "Source"
        }, 
        {
            "location": "/sponge/included_packages/#variables_1", 
            "text": "var strategy str.Strategy : Holds the credentials for the external source, as well as all the entities that need to be extracted.  var uuid string : Universally Unique Identifier used for the logs.  var credential str.Credential : Credential for the external source (database or web service).", 
            "title": "Variables"
        }, 
        {
            "location": "/sponge/included_packages/#sourcer-interface", 
            "text": "This is the interface that needs to be implemented by any driver that connects to an external data source.", 
            "title": "Sourcer interface"
        }, 
        {
            "location": "/sponge/included_packages/#func-getdata", 
            "text": "GetData(string, *Options) ([]map[string]interface{}, error)  Returns all the data (query by options in Options) in the format []map[string]interface{}", 
            "title": "func GetData"
        }, 
        {
            "location": "/sponge/included_packages/#func-iswebservice", 
            "text": "IsWebService() bool  Returns true if the implementation of sourcer is a web service.", 
            "title": "func IsWebService"
        }, 
        {
            "location": "/sponge/included_packages/#func-new", 
            "text": "func New(d string) (Sourcer, error)  Depending on the parameter, it returns a structure with the connection to the external source that implements the interface Sourcer.", 
            "title": "func New"
        }, 
        {
            "location": "/sponge/included_packages/#func-getentities", 
            "text": "func GetEntities() ([]string, error)  Gets all the entities  names from the source", 
            "title": "func GetEntities"
        }, 
        {
            "location": "/sponge/included_packages/#func-getforeignentity", 
            "text": "func GetForeignEntity(name string) string  Gets the foreign entity s name for the Coral collection.", 
            "title": "func GetforeignEntity"
        }, 
        {
            "location": "/sponge/included_packages/#mysql-driver", 
            "text": "The mySQL driver is contained in the  mysql.go  file. It has a mySQL struct that implements the Sourcer interface, and enables data extraction from a mySQL database.", 
            "title": "mySQL driver"
        }, 
        {
            "location": "/sponge/included_packages/#postgresql-driver", 
            "text": "The PostgreSQL driver is contained in the  postgresql.go  file. It has a PostgreSQL struct that implements the Sourcer interface, and enables data extraction from a PostgreSQL database.", 
            "title": "PostgreSQL driver"
        }, 
        {
            "location": "/sponge/included_packages/#mongodb-driver", 
            "text": "The MongoDB driver is contained in the  mongodb.go  file. It has a MongoDB struct that implements the Sourcer interface, and enables data extraction from a MongoDB database.", 
            "title": "MongoDB driver"
        }, 
        {
            "location": "/sponge/included_packages/#api-driver", 
            "text": "The API driver is contained in the  api.go  file. It has an API struct that implements the Sourcer interface, and enables data extraction from an API interface.", 
            "title": "API driver"
        }, 
        {
            "location": "/sponge/included_packages/#how-to-add-a-new-source", 
            "text": "Currently, we offer the four drivers listed above (mySQL, PostgreSQL, MongoDB, and REST API). If you need to add a new type of external source, you can write your own driver. To write your own driver, you will implement the Sourcer interface for your type of external data source.", 
            "title": "How to add a new source"
        }, 
        {
            "location": "/sponge/included_packages/#fiddler", 
            "text": "import  github.com/coralproject/sponge/pkg/fiddler   The Fiddler package performs the translation from the external database schema into Coral s database schema.", 
            "title": "Fiddler"
        }, 
        {
            "location": "/sponge/included_packages/#variables_2", 
            "text": "strategy   str.Strategy  Holds the translation, in JSON form, to apply to the data.  dateLayout string  Date Layout as specified in the strategy file.  uuid string  Universally Unique Identifier used for the logs.", 
            "title": "Variables"
        }, 
        {
            "location": "/sponge/included_packages/#functions", 
            "text": "", 
            "title": "Functions"
        }, 
        {
            "location": "/sponge/included_packages/#func-getid", 
            "text": "func GetID(modelName string) string  Returns the field that is the identifier for that model", 
            "title": "func GetID"
        }, 
        {
            "location": "/sponge/included_packages/#func-getcollections", 
            "text": "func GetCollections() []string  Returns the names of all the collections in the strategy file.", 
            "title": "func GetCollections"
        }, 
        {
            "location": "/sponge/included_packages/#func-transformrow", 
            "text": "func TransformRow(row map[string]interface{}, coralName string) (interface{}, []map[string]interface{}, error)  Applies the coral schema to a row of data from the external source.", 
            "title": "func TransformRow"
        }, 
        {
            "location": "/sponge/included_packages/#coral", 
            "text": "Note : The  Coral  package is not to be confused with the Coral ecosystem as a whole. In this instance, this is merely the name of a package included in the Sponge app.  import  github.com/coralproject/sponge/pkg/coral   Coral interacts with Pillar endpoints to import data into the Coral system.", 
            "title": "Coral"
        }, 
        {
            "location": "/sponge/included_packages/#constants", 
            "text": "retryTimes int    = 3  Determines how many times to retry communication with Pillar, if it initially fails.  methodGet  string = \"GET\"  methodPost string = \"POST\"", 
            "title": "Constants"
        }, 
        {
            "location": "/sponge/included_packages/#variables_3", 
            "text": "endpoints map[string]string   endpoints  is a map containing all of the services where we can send data. Right now, that is only Pillar.  uuid string  Universally Unique Identifier used for the logs.  str  strategy.Strategy  Holds the translation, in JSON form, to apply to the data.", 
            "title": "Variables"
        }, 
        {
            "location": "/sponge/included_packages/#functions_1", 
            "text": "", 
            "title": "Functions"
        }, 
        {
            "location": "/sponge/included_packages/#func-addrow", 
            "text": "func AddRow(data map[string]interface{}, tableName string) error  Adds data to the collection  tableName .", 
            "title": "func AddRow"
        }, 
        {
            "location": "/sponge/included_packages/#func-createindex", 
            "text": "func CreateIndex(collection string) error  Calls the service to create index for  collection .", 
            "title": "func CreateIndex"
        }, 
        {
            "location": "/sponge/included_packages/#sponge", 
            "text": "Note : The  Sponge  package is not to be confused with the Sponge app as a whole. In this instance, this is merely the name of a package included in the larger Sponge app.  import  github.com/coralproject/sponge/pkg/sponge   The Sponge package ties together all of the other packages, so that they all communicate and work with each other.", 
            "title": "Sponge"
        }, 
        {
            "location": "/sponge/included_packages/#constants_1", 
            "text": "VersionNumber = 0.1  Provides the version number of Sponge.", 
            "title": "Constants"
        }, 
        {
            "location": "/sponge/included_packages/#variables_4", 
            "text": "dbsource source.Sourcer  uuid     string  options  source.Options", 
            "title": "Variables"
        }, 
        {
            "location": "/sponge/included_packages/#functions_2", 
            "text": "", 
            "title": "Functions"
        }, 
        {
            "location": "/sponge/included_packages/#func-addoptions", 
            "text": "func AddOptions(limit int, offset int, orderby string, query string, types string, importonlyfailed bool, reportOnFailedRecords bool, reportdbfile string)  AddOptions  sets options for how Sponge will run. The options are:   Limit : limit for the query  Offset : offset for the query  Orderby :  order by this field  Query :  we use this field if we want to specific a filter on WHERE for mySQL/PostgreSQL and Find for MongoDB  Types : it specifies which entities to import (default is everything)  Importonlyfailed : import only the documents that are in the report  ReportOnFailedRecords : create a report with all the documents that failed the import  Reportdbfile : name of the file for the report on documents that fail the import", 
            "title": "func AddOptions"
        }, 
        {
            "location": "/sponge/included_packages/#func-import", 
            "text": "func Import()  Gets data, transforms it and sends it to Pillar. It bases everything on the STRATEGY_CONF environment variable and the PILLAR_URL environment variable.", 
            "title": "func Import"
        }, 
        {
            "location": "/sponge/included_packages/#func-createindex_1", 
            "text": "func CreateIndex(collection string)  Creates index on the collection  collection . This feature creates indexes on the Coral database, depending on data in the strategy file.  For example:  Index : [\n  {\n     name :  asset-url ,\n     keys : [ asseturl ],\n     unique :  true ,\n     dropdups :  true \n  }\n],  You can read more information at the  mongodb s create index definition .", 
            "title": "func CreateIndex"
        }, 
        {
            "location": "/sponge/strategy/", 
            "text": "Strategy files\n\n\nStrategy files are JSON configuration files that contain all the information Sponge needs to extract data from a source, translate it to the Coral schema, and send it on to Pillar and from there to the Coral MongoDB.\n\n\nThe external data sources we currently support are: PostgreSQL, MySQL, MongoDB, and REST APIs.\n\n\nThe strategy spec is still being refined. We have examples that you can view in the \nexamples directory\n.\n\n\nExamples:\n\n\n\n\nAPI example\n\n\nMongoDB example\n\n\nmySQL example\n\n\nPostgreSQL example\n\n\n\n\nFields in the strategy.json file\n\n\nGeneral fields\n\n\n\n\nName\n: The name of the strategy that we are describing.\n\n\nMap\n: Contains all the information to map fields from the external data source to our local Coral database.\n\n\nForeign\n: Describes the type of external database source (for example, \nmysql\n or \nmongodb\n).\n\n\nDateTimeFormat\n: Tells us how to parse date/time fields in the external data source. You should populated this field with the date and time of \n2006 Mon Jan 2 15:04:05\n, written in the format that appears in your external database.\n\n\n\n\nEntity fields\n\n\nEntities\n is a JSON object that describes all of the different entities in the Coral database, and how to perform the transformation for that entity.\n\n\n\n\nForeign\n: The name of the foreign entity.\n\n\nLocal\n: The collection into which we are importing this entity.\n\n\nPriority\n: This is a number that specifies which entity to import first (the highest priority is 0).\n\n\nOrderBy\n: The field to order the results by when querying the foreign source.\n\n\nID\n: The identifier field for the foreign entity. We use this field when we need to import only some records and not the whole entity.\n\n\nEndpoint\n: This is the \nPillar endpoint URL\n where we will push the data.\n\n\nFields\n: All the fields that are being mapped.\n\n\nforeign\n: The name of the field in the foreign entity.\n\n\nlocal\n: The name of the field in our local database.\n\n\nrelation\n: The relationship between the foreign field and the local one. We have this options:\n\n\nPassthrough\n: when the value is the same\n\n\nSource\n: when it needs to be added to our source struct for the local collection (the original identifiers have to go into source)\n\n\nParseTimeDate\n: when we need to parse the foreign value as date time.\n\n\nConstant\n: when the local field should always be the same value. In this case we will have \nforeign\n blank and we will have other field called \nvalue\n with the value of the local field.\n\n\nSubDocument\n: when the local field has an array of documents in one of the fields.\n\n\nStatus\n: when the field need to be translated based on the status map that is declared in that same strategy file for the entity.\n\n\n\n\n\n\nType\n: The type of the value we are converting.\n\n\nString\n\n\nTimedate\n\n\n\n\n\n\n\n\nCredentials\n\n\nThis contains the credentials for the external data source. It could be a REST API or a database (MySQL, PostgreSQL or MongoDB).\n\n\n\n\nadapter\n: This tells us which driver we need to use to extract data. Right now, the options available are \nmysql\n, \npostgresql\n, \nmongodb\n, or \nservice\n.\n\n\ntype\n: Right now this is always \nforeign\n, but in future it could tell us what type of credential this is.", 
            "title": "Strategy files"
        }, 
        {
            "location": "/sponge/strategy/#strategy-files", 
            "text": "Strategy files are JSON configuration files that contain all the information Sponge needs to extract data from a source, translate it to the Coral schema, and send it on to Pillar and from there to the Coral MongoDB.  The external data sources we currently support are: PostgreSQL, MySQL, MongoDB, and REST APIs.  The strategy spec is still being refined. We have examples that you can view in the  examples directory .  Examples:   API example  MongoDB example  mySQL example  PostgreSQL example", 
            "title": "Strategy files"
        }, 
        {
            "location": "/sponge/strategy/#fields-in-the-strategyjson-file", 
            "text": "", 
            "title": "Fields in the strategy.json file"
        }, 
        {
            "location": "/sponge/strategy/#general-fields", 
            "text": "Name : The name of the strategy that we are describing.  Map : Contains all the information to map fields from the external data source to our local Coral database.  Foreign : Describes the type of external database source (for example,  mysql  or  mongodb ).  DateTimeFormat : Tells us how to parse date/time fields in the external data source. You should populated this field with the date and time of  2006 Mon Jan 2 15:04:05 , written in the format that appears in your external database.", 
            "title": "General fields"
        }, 
        {
            "location": "/sponge/strategy/#entity-fields", 
            "text": "Entities  is a JSON object that describes all of the different entities in the Coral database, and how to perform the transformation for that entity.   Foreign : The name of the foreign entity.  Local : The collection into which we are importing this entity.  Priority : This is a number that specifies which entity to import first (the highest priority is 0).  OrderBy : The field to order the results by when querying the foreign source.  ID : The identifier field for the foreign entity. We use this field when we need to import only some records and not the whole entity.  Endpoint : This is the  Pillar endpoint URL  where we will push the data.  Fields : All the fields that are being mapped.  foreign : The name of the field in the foreign entity.  local : The name of the field in our local database.  relation : The relationship between the foreign field and the local one. We have this options:  Passthrough : when the value is the same  Source : when it needs to be added to our source struct for the local collection (the original identifiers have to go into source)  ParseTimeDate : when we need to parse the foreign value as date time.  Constant : when the local field should always be the same value. In this case we will have  foreign  blank and we will have other field called  value  with the value of the local field.  SubDocument : when the local field has an array of documents in one of the fields.  Status : when the field need to be translated based on the status map that is declared in that same strategy file for the entity.    Type : The type of the value we are converting.  String  Timedate", 
            "title": "Entity fields"
        }, 
        {
            "location": "/sponge/strategy/#credentials", 
            "text": "This contains the credentials for the external data source. It could be a REST API or a database (MySQL, PostgreSQL or MongoDB).   adapter : This tells us which driver we need to use to extract data. Right now, the options available are  mysql ,  postgresql ,  mongodb , or  service .  type : Right now this is always  foreign , but in future it could tell us what type of credential this is.", 
            "title": "Credentials"
        }, 
        {
            "location": "/sponge/logging/", 
            "text": "About LOGGING\n\n\nWe are using (Ardanlabs Log\ns package)[https://github.com/ardanlabs/kit/tree/master/log] for all the tools we are developing in GO.\n\n\nSpec:\n\n\nLogging levels:\n\n\n* Dev: to be outputted in development environment only\n* User (prod): to be outputted in dev and production environments\n\n\n\nAll logs should contain:\n\n\n* context uuid to identify a particular execution (aka, run of Sponge or a Request/Response execution from a web server.)\n* the name of the function that is executing\n* a readable message including relevant data\n\n\n\nLogs should write to stdout so they can be flexibly directed.", 
            "title": "Logging"
        }, 
        {
            "location": "/sponge/logging/#about-logging", 
            "text": "We are using (Ardanlabs Log s package)[https://github.com/ardanlabs/kit/tree/master/log] for all the tools we are developing in GO.", 
            "title": "About LOGGING"
        }, 
        {
            "location": "/sponge/logging/#spec", 
            "text": "", 
            "title": "Spec:"
        }, 
        {
            "location": "/sponge/logging/#logging-levels", 
            "text": "* Dev: to be outputted in development environment only\n* User (prod): to be outputted in dev and production environments", 
            "title": "Logging levels:"
        }, 
        {
            "location": "/sponge/logging/#all-logs-should-contain", 
            "text": "* context uuid to identify a particular execution (aka, run of Sponge or a Request/Response execution from a web server.)\n* the name of the function that is executing\n* a readable message including relevant data  Logs should write to stdout so they can be flexibly directed.", 
            "title": "All logs should contain:"
        }, 
        {
            "location": "/xenia/", 
            "text": "Xenia\n\n\nXenia\n is a configurable service layer that publishes endpoints against \nMongoDB aggregation pipeline\n queries.\n\n\nAggregation pipelines are chainable, allowing for the output of one endpoint to be fed into the next. Xenia provides a request syntax to allow for this, giving the requesting application an added dimension of flexibility via query control.\n\n\nSimilarly, output documents from multiple pipelines can be bundled together. This is particularly useful in the noSQL/document database paradigm, in which joins are not natively supported.\n\n\nStraightforward query creation\n\n\nXenia moves the query logic out of the application code. Front end developers, data analysts, and anyone else familiar with the simple, declarative \nMongoDB aggregation syntax\n can adjust the data requests, and create or update endpoints.", 
            "title": "Introduction"
        }, 
        {
            "location": "/xenia/#xenia", 
            "text": "Xenia  is a configurable service layer that publishes endpoints against  MongoDB aggregation pipeline  queries.  Aggregation pipelines are chainable, allowing for the output of one endpoint to be fed into the next. Xenia provides a request syntax to allow for this, giving the requesting application an added dimension of flexibility via query control.  Similarly, output documents from multiple pipelines can be bundled together. This is particularly useful in the noSQL/document database paradigm, in which joins are not natively supported.", 
            "title": "Xenia"
        }, 
        {
            "location": "/xenia/#straightforward-query-creation", 
            "text": "Xenia moves the query logic out of the application code. Front end developers, data analysts, and anyone else familiar with the simple, declarative  MongoDB aggregation syntax  can adjust the data requests, and create or update endpoints.", 
            "title": "Straightforward query creation"
        }, 
        {
            "location": "/xenia/install/", 
            "text": "Xenia Installation\n\n\nXenia is a configurable service layer that publishes endpoints against \nMongoDB aggregation pipeline queries\n.\n\n\nBefore you begin\n\n\nBefore you install Xenia, you will want to have the following installed.\n\n\nMongoDB\n\n\nYou can find instructions on installing MongoDB \non the MongoDB website\n.\n\n\nThere are \ninstructions on importing sample comment data into MongoDB here\n\n\nGo\n\n\nIf you want to install from source, you will need to have Go installed.\n\n\nYou can install \ninstall Go from their website\n. The \ninstallation and setup instructions\n on the Go website are quite good. Ensure that you have exported your $GOPATH environment variable, as detailed in the \ninstallation instructions\n.\n\n\nIf you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.\n\n\nexport GO15VENDOREXPERIMENT=1\n\n\n\n\nIf you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.\n\n\nObtaining the source code\n\n\nYou can install the source code via using the \ngo get\n command, or by manually cloning the code.\n\n\nUsing the go get command\n\n\ngo get github.com/coralproject/xenia\n\n\n\n\nIf you see a message about \nno buildable Go source files\n like the below, you can ignore it. It simply means that there are buildable source files in subdirectories, just not the uppermost xenia directory.\n\n\npackage github.com/coralproject/xenia: no buildable Go source files in [directory]\n\n\n\n\nCloning manually\n\n\nYou can also clone the code manually.\n\n\nmkdir $GOPATH/src/github.com/coralproject/xenia\ncd $GOPATH/src/github.com/coralproject/xenia\n\ngit clone git@github.com:CoralProject/xenia.git\n\n\n\n\nSet up your environment variables\n\n\nThis tells Xenia which database you want to use, sets your port, and sets your database password.\n\n\nMake your own copy of the \nconfig/dev.cfg\n file (this edited cfg file will contain your own values for things like your database password, and will not be committed back to the repository if you are doing development work on Xenia). Call your config file whatever you like; we\nll call it \ncustom\n in this example.\n\n\ncd $GOPATH/src/github.com/coralproject/xenia\ncp config/dev.cfg config/custom.cfg\n\n\n\n\nEdit the environment variables to reflect your MongoDB setup.\n\nRemember, you\nre entering your password here, so be sure not to commit this file to the repository!\n\n\nexport XENIA_MONGO_HOST=localhost:27017\nexport XENIA_MONGO_USER=coral-user\nexport XENIA_MONGO_AUTHDB=coral\nexport XENIA_MONGO_DB=coral\n\nexport XENIA_LOGGING_LEVEL=1\nexport XENIA_HOST=:4000\n\n# Use to have the CLI tooling hit the web service.\nexport XENIA_WEB_HOST=\nexport XENIA_WEB_AUTH=\n\n# Set host to Anvil if configured.\n# export XENIA_ANVIL_HOST=https://HOST\n\n# Use to apply extra key:value pairs to the header\n# export XENIA_HEADERS=key:value,key:value\n\n# DO NOT PUSH TO REPO\nexport XENIA_MONGO_PASS=\n\n\n\n\nRequired edits:\n\n\n\n\nXENIA_MONGO_HOST\n: set to your MongoDB where you will be communicating with.\n\n\nIf you are running MongoDB locally on your machine, you should set this to \nlocalhost:27017\n.\n\n\nIf you are pointing to a MongoDB running on a server somewhere, set this to the IP address and port of your MongoDB.\n\n\n\n\n\n\nXENIA_MONGO_DB\n: the database you are running queries against (\ncoral\n).\n\n\nXENIA_MONGO_USER\n: your MongoDB username.\n\n\nXENIA_MONGO_PASS\n: the password for your MongoDB user.\n\n\nXENIA_MONGO_AUTHDB\n: the database you are authenticating against (in most cases, should be the same \ncoral\n database as XENIA_MONGO_DB).\n\n\n\n\nOptional edits:\n\n\n\n\nXENIA_WEB_HOST\n: this is required for the CLI tool. It is the address of the Xenia web service (i.e., an instance of Xenia that you are running on a server).\n\n\nIf you are running everything locally, comment this variable out. This means that the CLI tool will connect directly to your local database, instead of connecting to a running web service.\n\n\n\n\n\n\nXENIA_HOST\n: default is \n:4000\n if this variable is not set.\n\n\nXENIA_LOGGING_LEVEL\n: default is \n2\n if this variable is not set.\n\n\nXENIA_WEB_AUTH\n: your Anvil token, if you have Anvil authentication set up. If you do not have authentication set up, leave this commented out.\n\n\nXENIA_ANVIL_HOST\n: the URL to the Anvil host, if you have Anvil authentication set up. If you do not have authentication set up, leave this commented out.\n\n\nXENIA_HEADERS\n: leave this commented out.\n\n\n\n\nOnce you\nve finished editing, source your config file using the source command:\n\n\nsource $GOPATH/src/github.com/coralproject/xenia/config/custom.cfg\n\n\n\n\nBuild the CLI tool\n\n\nXenia has a CLI tool that allows you to manage endpoints and perform other actions.\n\n\nTo build to the tool:\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia\ngo build\n\n\n\n\nNote: It is best to run with logging level 0 when using the xenia command:\n\n\nexport XENIA_LOGGING_LEVEL=0\n\n\n\n\nCreating a Xenia database for the first time\n\n\nIf you are running Xenia on a MongoDB database for the first time you will need the Xenia command line tool to set up the MongoDB for use with Xenia. The CLI tool will create collections and sets of indexes that you can use to execute queries: a sort of dictionary of pre-made queries for you to use.\n\n\n1) First cd into cmd/xenia directory (this contains the CLI tool):\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia\n\n\n\n\n2) Configure the database using \ndb create\n. The database.json file contains the information necessary to create the collections and indexes.\n\n\n./xenia db create -f scrdb/database.json\n\n\n\n\nExpected output:\n\n\nConfiguring MongoDB\nCreating collection query_sets\nCreating collection query_sets_history\nCreating collection query_scripts\nCreating collection query_scripts_history\nCreating collection query_masks\nCreating collection query_masks_history\nCreating collection query_regexs\nCreating collection query_regexs_history\n\n\n\n\nTroubleshooting note #1\n\n\nIf you get a response that contains \nERROR: Invalid DB provided\n, you may have an incorrectly set environment variable. If you are running everything locally and using a local MongoDB, use \nprintev\n to see if \nXENIA_WEB_HOST\n is set:\n\n\nprintenv XENIA_WEB_HOST\n\n\n\n\nIf you are using a local MongoDB, this should not return a value. If it does return a value, unset the variable using \nunset\n, and then try step 2 again:\n\n\nunset XENIA_WEB_HOST\n\n\n\n\nTroubleshooting note #2\n\n\nInstead of the expected output shown above, you may see something like:\n\n\nConfiguring MongoDB\nCreating collection query_sets\nERROR: collection already exists\n\n\n\n\nThat\ns okay! It means that your database is already set up with Xenia. Perhaps you imported data that already had configured collections set up. Continue on to step 3.\n\n\n3) Load all the existing queries:\n\n\n./xenia query upsert -p scrquery\n\n\n\n\nExpected output:\n\n\nConfiguring MongoDB\nUpserting Set : Path[scrquery]\nUpserting Set : Upserted\n\n\n\n\n4) Load all the existing masks:\n\n\n./xenia mask upsert -p scrmask\n\n\n\n\nExpected output:\n\n\nConfiguring MongoDB\nUpserting Set : Path[scrquery]\nUpserting Set : Upserted\n\n\n\n\n5) Load all the existing regexes:\n\n\n./xenia regex upsert -p scrregex\n\n\n\n\nExpected output:\n\n\nConfiguring MongoDB\nUpserting Regex : Path[scrregex]\nUpserting Regex : Upserted\n\n\n\n\n6) That\ns it! If you are using MongoChef, you should be able to see your newly created collections, which will look something like this:\n\n\n\n\nRun the web service\n\n\n1) First cd into the directory containing the web service, xeniad (the Xenia daemon):\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xeniad\n\n\n\n\n2) Build the Xenia web service:\n\n\ngo build\n\n\n\n\n3) Run the web service:\n\n\n./xeniad\n\n\n\n\nExpected output:\n\n\n2016/06/08 10:26:38 app.go:173: USER : startup : Init :\n\nConfig Settings:\nMONGO_USER=coral-user\nMONGO_AUTHDB=coral\nMONGO_DB=coral\nHOST=:4000\nLOGGING_LEVEL=1\nMONGO_HOST=localhost:27017\n\n2016/06/08 10:26:38 main.go:24: USER : startup : Init : Revision     : \nunknown\n\n2016/06/08 10:26:38 main.go:25: USER : startup : Init : Version      : \nunknown\n\n2016/06/08 10:26:38 main.go:26: USER : startup : Init : Build Date   : \nunknown\n\n2016/06/08 10:26:38 main.go:27: USER : startup : Init : Int Version  : \n201606081030\n\n2016/06/08 10:26:38 main.go:28: USER : startup : Init : Go Version   : \ngo1.6.2\n\n2016/06/08 10:26:38 main.go:29: USER : startup : Init : Go Compiler  : \ngc\n\n2016/06/08 10:26:38 main.go:30: USER : startup : Init : Go ARCH      : \namd64\n\n2016/06/08 10:26:38 main.go:31: USER : startup : Init : Go OS        : \ndarwin\n\n\n\n\n\n4) You can test your web service by going to the following URL in your browser: \nhttp://localhost:4000/1.0/query\n.\n\n\nIn your browser, you will see some json displayed. In your terminal, you should see something like:\n\n\n2016/06/08 13:30:58 app.go:104: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : Request : Started : Method[GET] URL[/1.0/query] RADDR[[::1]:62121]\n2016/06/08 13:30:58 context.go:65: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : api : Respond : Started : Code[200]\n2016/06/08 13:30:58 context.go:72: USER : startup : api : Respond : Setting user headers : Access-Control-Allow-Origin:*\n2016/06/08 13:30:58 context.go:110: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : api : Respond : Completed\n2016/06/08 13:30:58 app.go:126: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : Request : Completed : Status[200] Duration[46.497305ms]\n\n\n\n\nTroubleshooting\n\n\n\n\nAuthorization\n\n\nTODO", 
            "title": "Installation"
        }, 
        {
            "location": "/xenia/install/#xenia-installation", 
            "text": "Xenia is a configurable service layer that publishes endpoints against  MongoDB aggregation pipeline queries .", 
            "title": "Xenia Installation"
        }, 
        {
            "location": "/xenia/install/#before-you-begin", 
            "text": "Before you install Xenia, you will want to have the following installed.", 
            "title": "Before you begin"
        }, 
        {
            "location": "/xenia/install/#mongodb", 
            "text": "You can find instructions on installing MongoDB  on the MongoDB website .  There are  instructions on importing sample comment data into MongoDB here", 
            "title": "MongoDB"
        }, 
        {
            "location": "/xenia/install/#go", 
            "text": "If you want to install from source, you will need to have Go installed.  You can install  install Go from their website . The  installation and setup instructions  on the Go website are quite good. Ensure that you have exported your $GOPATH environment variable, as detailed in the  installation instructions .  If you are not on a version of Go that is 1.7 or higher, you will also have to set the GO15VENDOREXPERIMENT flag.  export GO15VENDOREXPERIMENT=1  If you are not on a version of Go 1.7 or higher, we recommend adding this to your ~/.bash_profile or other startup script.", 
            "title": "Go"
        }, 
        {
            "location": "/xenia/install/#obtaining-the-source-code", 
            "text": "You can install the source code via using the  go get  command, or by manually cloning the code.", 
            "title": "Obtaining the source code"
        }, 
        {
            "location": "/xenia/install/#using-the-go-get-command", 
            "text": "go get github.com/coralproject/xenia  If you see a message about  no buildable Go source files  like the below, you can ignore it. It simply means that there are buildable source files in subdirectories, just not the uppermost xenia directory.  package github.com/coralproject/xenia: no buildable Go source files in [directory]", 
            "title": "Using the go get command"
        }, 
        {
            "location": "/xenia/install/#cloning-manually", 
            "text": "You can also clone the code manually.  mkdir $GOPATH/src/github.com/coralproject/xenia\ncd $GOPATH/src/github.com/coralproject/xenia\n\ngit clone git@github.com:CoralProject/xenia.git", 
            "title": "Cloning manually"
        }, 
        {
            "location": "/xenia/install/#set-up-your-environment-variables", 
            "text": "This tells Xenia which database you want to use, sets your port, and sets your database password.  Make your own copy of the  config/dev.cfg  file (this edited cfg file will contain your own values for things like your database password, and will not be committed back to the repository if you are doing development work on Xenia). Call your config file whatever you like; we ll call it  custom  in this example.  cd $GOPATH/src/github.com/coralproject/xenia\ncp config/dev.cfg config/custom.cfg  Edit the environment variables to reflect your MongoDB setup. Remember, you re entering your password here, so be sure not to commit this file to the repository!  export XENIA_MONGO_HOST=localhost:27017\nexport XENIA_MONGO_USER=coral-user\nexport XENIA_MONGO_AUTHDB=coral\nexport XENIA_MONGO_DB=coral\n\nexport XENIA_LOGGING_LEVEL=1\nexport XENIA_HOST=:4000\n\n# Use to have the CLI tooling hit the web service.\nexport XENIA_WEB_HOST=\nexport XENIA_WEB_AUTH=\n\n# Set host to Anvil if configured.\n# export XENIA_ANVIL_HOST=https://HOST\n\n# Use to apply extra key:value pairs to the header\n# export XENIA_HEADERS=key:value,key:value\n\n# DO NOT PUSH TO REPO\nexport XENIA_MONGO_PASS=  Required edits:   XENIA_MONGO_HOST : set to your MongoDB where you will be communicating with.  If you are running MongoDB locally on your machine, you should set this to  localhost:27017 .  If you are pointing to a MongoDB running on a server somewhere, set this to the IP address and port of your MongoDB.    XENIA_MONGO_DB : the database you are running queries against ( coral ).  XENIA_MONGO_USER : your MongoDB username.  XENIA_MONGO_PASS : the password for your MongoDB user.  XENIA_MONGO_AUTHDB : the database you are authenticating against (in most cases, should be the same  coral  database as XENIA_MONGO_DB).   Optional edits:   XENIA_WEB_HOST : this is required for the CLI tool. It is the address of the Xenia web service (i.e., an instance of Xenia that you are running on a server).  If you are running everything locally, comment this variable out. This means that the CLI tool will connect directly to your local database, instead of connecting to a running web service.    XENIA_HOST : default is  :4000  if this variable is not set.  XENIA_LOGGING_LEVEL : default is  2  if this variable is not set.  XENIA_WEB_AUTH : your Anvil token, if you have Anvil authentication set up. If you do not have authentication set up, leave this commented out.  XENIA_ANVIL_HOST : the URL to the Anvil host, if you have Anvil authentication set up. If you do not have authentication set up, leave this commented out.  XENIA_HEADERS : leave this commented out.   Once you ve finished editing, source your config file using the source command:  source $GOPATH/src/github.com/coralproject/xenia/config/custom.cfg", 
            "title": "Set up your environment variables"
        }, 
        {
            "location": "/xenia/install/#build-the-cli-tool", 
            "text": "Xenia has a CLI tool that allows you to manage endpoints and perform other actions.  To build to the tool:  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia\ngo build  Note: It is best to run with logging level 0 when using the xenia command:  export XENIA_LOGGING_LEVEL=0", 
            "title": "Build the CLI tool"
        }, 
        {
            "location": "/xenia/install/#creating-a-xenia-database-for-the-first-time", 
            "text": "If you are running Xenia on a MongoDB database for the first time you will need the Xenia command line tool to set up the MongoDB for use with Xenia. The CLI tool will create collections and sets of indexes that you can use to execute queries: a sort of dictionary of pre-made queries for you to use.  1) First cd into cmd/xenia directory (this contains the CLI tool):  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia  2) Configure the database using  db create . The database.json file contains the information necessary to create the collections and indexes.  ./xenia db create -f scrdb/database.json  Expected output:  Configuring MongoDB\nCreating collection query_sets\nCreating collection query_sets_history\nCreating collection query_scripts\nCreating collection query_scripts_history\nCreating collection query_masks\nCreating collection query_masks_history\nCreating collection query_regexs\nCreating collection query_regexs_history", 
            "title": "Creating a Xenia database for the first time"
        }, 
        {
            "location": "/xenia/install/#troubleshooting-note-1", 
            "text": "If you get a response that contains  ERROR: Invalid DB provided , you may have an incorrectly set environment variable. If you are running everything locally and using a local MongoDB, use  printev  to see if  XENIA_WEB_HOST  is set:  printenv XENIA_WEB_HOST  If you are using a local MongoDB, this should not return a value. If it does return a value, unset the variable using  unset , and then try step 2 again:  unset XENIA_WEB_HOST", 
            "title": "Troubleshooting note #1"
        }, 
        {
            "location": "/xenia/install/#troubleshooting-note-2", 
            "text": "Instead of the expected output shown above, you may see something like:  Configuring MongoDB\nCreating collection query_sets\nERROR: collection already exists  That s okay! It means that your database is already set up with Xenia. Perhaps you imported data that already had configured collections set up. Continue on to step 3.  3) Load all the existing queries:  ./xenia query upsert -p scrquery  Expected output:  Configuring MongoDB\nUpserting Set : Path[scrquery]\nUpserting Set : Upserted  4) Load all the existing masks:  ./xenia mask upsert -p scrmask  Expected output:  Configuring MongoDB\nUpserting Set : Path[scrquery]\nUpserting Set : Upserted  5) Load all the existing regexes:  ./xenia regex upsert -p scrregex  Expected output:  Configuring MongoDB\nUpserting Regex : Path[scrregex]\nUpserting Regex : Upserted  6) That s it! If you are using MongoChef, you should be able to see your newly created collections, which will look something like this:", 
            "title": "Troubleshooting note #2"
        }, 
        {
            "location": "/xenia/install/#run-the-web-service", 
            "text": "1) First cd into the directory containing the web service, xeniad (the Xenia daemon):  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xeniad  2) Build the Xenia web service:  go build  3) Run the web service:  ./xeniad  Expected output:  2016/06/08 10:26:38 app.go:173: USER : startup : Init :\n\nConfig Settings:\nMONGO_USER=coral-user\nMONGO_AUTHDB=coral\nMONGO_DB=coral\nHOST=:4000\nLOGGING_LEVEL=1\nMONGO_HOST=localhost:27017\n\n2016/06/08 10:26:38 main.go:24: USER : startup : Init : Revision     :  unknown \n2016/06/08 10:26:38 main.go:25: USER : startup : Init : Version      :  unknown \n2016/06/08 10:26:38 main.go:26: USER : startup : Init : Build Date   :  unknown \n2016/06/08 10:26:38 main.go:27: USER : startup : Init : Int Version  :  201606081030 \n2016/06/08 10:26:38 main.go:28: USER : startup : Init : Go Version   :  go1.6.2 \n2016/06/08 10:26:38 main.go:29: USER : startup : Init : Go Compiler  :  gc \n2016/06/08 10:26:38 main.go:30: USER : startup : Init : Go ARCH      :  amd64 \n2016/06/08 10:26:38 main.go:31: USER : startup : Init : Go OS        :  darwin   4) You can test your web service by going to the following URL in your browser:  http://localhost:4000/1.0/query .  In your browser, you will see some json displayed. In your terminal, you should see something like:  2016/06/08 13:30:58 app.go:104: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : Request : Started : Method[GET] URL[/1.0/query] RADDR[[::1]:62121]\n2016/06/08 13:30:58 context.go:65: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : api : Respond : Started : Code[200]\n2016/06/08 13:30:58 context.go:72: USER : startup : api : Respond : Setting user headers : Access-Control-Allow-Origin:*\n2016/06/08 13:30:58 context.go:110: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : api : Respond : Completed\n2016/06/08 13:30:58 app.go:126: USER : 6bd28905-8a92-4aa9-80fd-5e9cff199b3e : Request : Completed : Status[200] Duration[46.497305ms]", 
            "title": "Run the web service"
        }, 
        {
            "location": "/xenia/install/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/xenia/install/#authorization", 
            "text": "TODO", 
            "title": "Authorization"
        }, 
        {
            "location": "/xenia/api/", 
            "text": "Xenia API\n\n\nThis section is under construction, and is not currently complete.\n\n\nEndpoints\n\n\nIf you set the authorization header properly in your browser (TODO) you can run the following endpoints.\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/1.0/query\n\n\nGET\n\n\nGet a list of configured queries\n\n\n\n\n\n\n/1.0/query/basic\n\n\nGET\n\n\nGet the query set document for the \nbasic\n query set\n\n\n\n\n\n\n/1.0/exec/basic\n\n\nGET\n\n\nExecute the query for the \nbasic\n query set\n\n\n\n\n\n\n/1.0/exec/basic_var\n\n\nGET\n\n\nExecute the query for the \nbasic_var\n query set with variables\n\n\n\n\n\n\n/1.0/exec\n\n\nPOST\n\n\nExecute a dynamic query set\n\n\n\n\n\n\n\n\nGet a list of configured queries\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/query\n\n\nGET\n\n\nGet a list of configured queries\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttp://localhost:4000/1.0/query\n\n\n\n\nExample response\n\n\n[\nbasic\n,\nbasic_var\n,\ntop_commenters_by_count\n]\n\n\n\n\nGet the query set document for the \nbasic\n query set\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/query/basic\n\n\nGET\n\n\nGet the query set document for the \nbasic\n query set\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttp://localhost:4000/1.0/query/basic\n\n\n\n\nExample response\n\n\n{\n   \nname\n:\nQTEST_basic\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n42021\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\n\n\n\nExecute the query for the \nbasic\n query set\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/query\n\n\nGET\n\n\nExecute the query for the basic query set\n\n\n\n\n\n\n\n\nParameters\n\n\nNone\n\n\nExample call\n\n\nGET\nhttp://localhost:4000/1.0/exec/basic\n\n\n\n\nset:\n\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n42021\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\n\n\n\nExample response\n\n\n{\n  \nresults\n:[\n    {\n      \nName\n:\nbasic\n,\n      \nDocs\n:[\n        {\n          \nname\n:\nC14 - Pasco County Buoy, FL\n\n        }\n      ]\n    }\n  ],\n  \nerror\n:false\n}\n\n\n\n\nExecute the query for the \nbasic_var\n query set with variables\n\n\n\n\n\n\n\n\nURL\n\n\nHTTP Verb\n\n\nFunctionality\n\n\n\n\n\n\n\n\n\n\n/1.0/exec/basic_var\n\n\nGET\n\n\nExecute the query for the \nbasic_var\n query set with variables\n\n\n\n\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName\n\n\nRequired?\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nstation_id\n\n\nY\n\n\nTag ID\n\n\n\n\n\n\n\n\nGET\nhttp://localhost:4000/1.0/exec/basic_var?station_id=42021\n\nset:\n\n{\n   \nname\n:\nbasic_var\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasicVar\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n#string:station_id\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\noutput:\n\n{\n  \nresults\n:[\n    {\n      \nName\n:\nbasic_var\n,\n      \nDocs\n:[\n        {\n          \nname\n:\nC14 - Pasco County Buoy, FL\n\n        }\n      ]\n    }\n  ],\n  \nerror\n:false\n}\n\n\n\n\n5) You can execute a dynamic query set:\n\n\nPOST\nhttp://localhost:4000/1.0/exec\n\nPost Data:\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n42021\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\n\n\n\nQuery management with the command line tool\n\n\nUsing the Xenia command line tool you can manage query sets.\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia\n\n\n\n\nGet a list of saved queries:\n\n\n./xenia query list\n\noutput:\n\nbasic\nbasic_var\ntop_commenters_by_count\n\n\n\n\nLook at the details of a query:\n\n\n./xenia query get -n basic\n\noutput:\n\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : \n42021\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      }\n   ]\n}\n\n\n\n\nExecute a query:\n\n\n./xenia query exec -n basic\n\noutput:\n\n{\n  \nresults\n:[\n    {\n      \nName\n:\nbasic\n,\n      \nDocs\n:[\n        {\n          \nname\n:\nC14 - Pasco County Buoy, FL\n\n        }\n      ]\n    }\n  ],\n  \nerror\n:false\n}\n\n\n\n\nAdd or update a query for use:\n\n\n./xenia query upsert -p ./scrquery/basic_var.json\n\noutput:\n\nUpserting Query : Path[./scrquery/basic_var.json]\n\n\n\n\nBy convention, we store core query scripts in the \n/xenia/cmd/xenia/scrquery\n folder.  As we develop Coral features, store the JSON files there so other developers can use them (eventually, groups of query sets will be refactored to another location, but that\ns the right folder for the time being).\n\n\ncd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia/scrquery\nls\n\n\n\n\nDirect Mongo access (optional)\n\n\nYou can look in the db at existing queries:\n\n\nmongo [flags to connect to your server]\nuse coral (or your databasename)\ndb.query_sets.find()\n\n\n\n\nWriting Sets\n\n\nWriting a set\n is essentially about creating a MongoDB aggregation pipeline. Xenia has built on top of this by providing extended functionality to make MongoDB more powerful.\n\n\nHere is a multi query set with variable substitution and date processing:\n\n\nGET\nhttp://localhost:4000/1.0/exec/basic?station_id=42021\n\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\nShows a basic multi result query.\n,\n   \nenabled\n:true,\n   \nqueries\n:[\n      {\n         \nname\n:\nBasic\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_bill\n,\n         \nreturn\n:true,\n         \nscripts\n:[\n            {\n$match\n: {\nstation_id\n : \n#station_id#\n}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}}\n         ]\n      },\n      {\n         \nname\n:\nTime\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_bill\n,\n         \nreturn\n:true,\n         \nscripts\n:[\n            {\n$match\n: {\ncondition.date\n : {\n$gt\n: \n#date:2013-01-01T00:00:00.000Z\n}}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n            {\n$limit\n: 2}\n         ]\n      }\n   ]\n}\n\n\n\n\nHere is the list of commands that exist for variable substitution.\n\n\n{\nfield\n: \n#cmd:variable\n}\n\n// Basic commands.\nBefore: {\nfield\n: \n#number:variable_name\n}      After: {\nfield\n: 1234}\nBefore: {\nfield\n: \n#string:variable_name\n}      After: {\nfield\n: \nvalue\n}\nBefore: {\nfield\n: \n#date:variable_name\n}        After: {\nfield\n: time.Time}\nBefore: {\nfield\n: \n#objid:variable_name\n}       After: {\nfield\n: mgo.ObjectId}\nBefore: {\nfield\n: \n#regex:/pattern/{options}\n}  After: {\nfield\n: bson.RegEx}\n\n// data command can index into saved results.\nBefore: {\nfield\n : {\n$in\n: \n#data.*:list.station_id\n}}}   After: [{\nstation_id\n:\n42021\n}]\nBefore: {\nfield\n: \n#data.0:doc.station_id\n}               After: {\nfield\n: \n23453\n}\n\n// time command manipulates the current time.\nBefore: {\nfield\n: #time:0}                 After: {\nfield\n: time.Time(Current Time)}\nBefore: {\nfield\n: #time:-3600}             After: {\nfield\n: time.Time(3600 seconds in the past)}\nBefore: {\nfield\n: #time:3m}                After: {\nfield\n: time.Time(3 minutes in the future)}\n\nPossible duration types. Default is seconds if not provided.\n\nns\n: Nanosecond\n\nus\n: Microsecond\n\nms\n: Millisecond\n\ns\n : Second\n\nm\n : Minute\n\nh\n : Hour\n\n\n\n\nYou can save the result of one query for later use by the next.\n\n\nGET\nhttp://localhost:4000/1.0/exec/basic_save\n\n{\n   \nname\n:\nbasic_save\n,\n   \ndesc\n:\n,\n   \nenabled\n:true,\n   \nparams\n:[],\n   \nqueries\n:[\n      {\n         \nname\n:\nget_id_list\n,\n         \ndesc\n: \nGet the list of id's\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:false,\n         \ncommands\n:[\n            {\n$project\n: {\n_id\n: 0, \nstation_id\n: 1}},\n            {\n$limit\n: 5}\n            {\n$save\n: {\n$map\n: \nlist\n}}\n         ]\n      },\n      {\n         \nname\n:\nretrieve_stations\n,\n         \ndesc\n: \nRetrieve the list of stations\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_xenia_data\n,\n         \nreturn\n:true,\n         \ncommands\n:[\n            {\n$match\n: {\nstation_id\n : {\n$in\n: \n#data.*:list.station_id\n}}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n         ]\n      }\n   ]\n}\n\n\n\n\nThe \n$save\n command is an Xenia extension and currently only \n$map\n is supported.\n\n\n{\n$save\n: {\n$map\n: \nlist\n}}\n\n\n\n\nThe result will be saved in a map under the name \nlist\n.\n\n\nThe second query is using the \n#data\n command. The data command has two options. Use can use \n#data.*\n or \n#data.Idx\n.\n\n\nUse the \n*\n operator when you need an array. In this example we need to support an \n$in\n command:\n\n\n{\n   \nname\n:\nretrieve_stations\n,\n   \ndesc\n: \nRetrieve the list of stations\n,\n   \ntype\n:\npipeline\n,\n   \ncollection\n:\ntest_xenia_data\n,\n   \nreturn\n:true,\n   \ncommands\n:[\n      {\n$match\n: {\nstation_id\n : {\n$in\n: \n#data.*:list.station_id\n}}},\n      {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n   ]\n}\n\nWhen you need an array to be substituted.\nBefore: {\nfield\n : {\n$in\n: \n#data.*:list.station_id\n}}}\nAfter : {\nfield\n : {\n$in\n: [\n42021\n]}}\n    dataOp : \n*\n\n    lookup : \nlist.station_id\n\n    results: {\nlist\n: [{\nstation_id\n:\n42021\n}]}\n\n\n\n\nUse the index operator when you need a single value. Specify which document in the array of documents you want to select:\n\n\n\n{\n   \nname\n:\nretrieve_stations\n,\n   \ndesc\n: \nRetrieve the list of stations\n,\n   \ntype\n:\npipeline\n,\n   \ncollection\n:\ntest_xenia_data\n,\n   \nreturn\n:true,\n   \ncommands\n:[\n      {\n$match\n: {\nstation_id\n : \n#data.0:list.station_id\n}},\n      {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n   ]\n}\n\nWhen you need a single value to be substituted, select an index.\nBefore: {\nfield\n : \n#data.0:list.station_id\n}\nAfter : {\nfield\n : \n42021\n}\n    dataOp : 0\n    lookup : \nlist.station_id\n\n    results: {\nlist\n: [{\nstation_id\n:\n42021\n}, {\nstation_id\n:\n23567\n}]}\n\n\n\n\nYou can also replace field names in the query commands.\n\n\nVariables\n{\n  \ncond\n: \ncondition\n,\n  \ndt\n: \ndate\n\n}\n\nQuery Set\n{\n   \nname\n:\nbasic\n,\n   \ndesc\n:\nShows field substitution.\n,\n   \nenabled\n:true,\n   \nqueries\n:[\n      {\n         \nname\n:\nTime\n,\n         \ntype\n:\npipeline\n,\n         \ncollection\n:\ntest_bill\n,\n         \nreturn\n:true,\n         \nscripts\n:[\n            {\n$match\n: {\n{cond}.{dt}\n : {\n$gt\n: \n#date:2013-01-01T00:00:00.000Z\n}}},\n            {\n$project\n: {\n_id\n: 0, \nname\n: 1}},\n            {\n$limit\n: 2}\n         ]\n      }\n   ]\n}", 
            "title": "API and query management"
        }, 
        {
            "location": "/xenia/api/#xenia-api", 
            "text": "This section is under construction, and is not currently complete.", 
            "title": "Xenia API"
        }, 
        {
            "location": "/xenia/api/#endpoints", 
            "text": "If you set the authorization header properly in your browser (TODO) you can run the following endpoints.     URL  HTTP Verb  Description      /1.0/query  GET  Get a list of configured queries    /1.0/query/basic  GET  Get the query set document for the  basic  query set    /1.0/exec/basic  GET  Execute the query for the  basic  query set    /1.0/exec/basic_var  GET  Execute the query for the  basic_var  query set with variables    /1.0/exec  POST  Execute a dynamic query set", 
            "title": "Endpoints"
        }, 
        {
            "location": "/xenia/api/#get-a-list-of-configured-queries", 
            "text": "URL  HTTP Verb  Functionality      /1.0/query  GET  Get a list of configured queries", 
            "title": "Get a list of configured queries"
        }, 
        {
            "location": "/xenia/api/#parameters", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/xenia/api/#example-call", 
            "text": "GET\nhttp://localhost:4000/1.0/query", 
            "title": "Example call"
        }, 
        {
            "location": "/xenia/api/#example-response", 
            "text": "[ basic , basic_var , top_commenters_by_count ]", 
            "title": "Example response"
        }, 
        {
            "location": "/xenia/api/#get-the-query-set-document-for-the-basic-query-set", 
            "text": "URL  HTTP Verb  Functionality      /1.0/query/basic  GET  Get the query set document for the  basic  query set", 
            "title": "Get the query set document for the basic query set"
        }, 
        {
            "location": "/xenia/api/#parameters_1", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/xenia/api/#example-call_1", 
            "text": "GET\nhttp://localhost:4000/1.0/query/basic", 
            "title": "Example call"
        }, 
        {
            "location": "/xenia/api/#example-response_1", 
            "text": "{\n    name : QTEST_basic ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  42021 }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}", 
            "title": "Example response"
        }, 
        {
            "location": "/xenia/api/#execute-the-query-for-the-basic-query-set", 
            "text": "URL  HTTP Verb  Functionality      /1.0/query  GET  Execute the query for the basic query set", 
            "title": "Execute the query for the basic query set"
        }, 
        {
            "location": "/xenia/api/#parameters_2", 
            "text": "None", 
            "title": "Parameters"
        }, 
        {
            "location": "/xenia/api/#example-call_2", 
            "text": "GET\nhttp://localhost:4000/1.0/exec/basic  set:\n\n{\n    name : basic ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  42021 }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}", 
            "title": "Example call"
        }, 
        {
            "location": "/xenia/api/#example-response_2", 
            "text": "{\n   results :[\n    {\n       Name : basic ,\n       Docs :[\n        {\n           name : C14 - Pasco County Buoy, FL \n        }\n      ]\n    }\n  ],\n   error :false\n}", 
            "title": "Example response"
        }, 
        {
            "location": "/xenia/api/#execute-the-query-for-the-basic_var-query-set-with-variables", 
            "text": "URL  HTTP Verb  Functionality      /1.0/exec/basic_var  GET  Execute the query for the  basic_var  query set with variables", 
            "title": "Execute the query for the basic_var query set with variables"
        }, 
        {
            "location": "/xenia/api/#parameters_3", 
            "text": "Name  Required?  Description      station_id  Y  Tag ID     GET\nhttp://localhost:4000/1.0/exec/basic_var?station_id=42021\n\nset:\n\n{\n    name : basic_var ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : BasicVar ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  #string:station_id }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}\n\noutput:\n\n{\n   results :[\n    {\n       Name : basic_var ,\n       Docs :[\n        {\n           name : C14 - Pasco County Buoy, FL \n        }\n      ]\n    }\n  ],\n   error :false\n}  5) You can execute a dynamic query set:  POST\nhttp://localhost:4000/1.0/exec\n\nPost Data:\n{\n    name : basic ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  42021 }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}", 
            "title": "Parameters"
        }, 
        {
            "location": "/xenia/api/#query-management-with-the-command-line-tool", 
            "text": "Using the Xenia command line tool you can manage query sets.  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia", 
            "title": "Query management with the command line tool"
        }, 
        {
            "location": "/xenia/api/#get-a-list-of-saved-queries", 
            "text": "./xenia query list\n\noutput:\n\nbasic\nbasic_var\ntop_commenters_by_count", 
            "title": "Get a list of saved queries:"
        }, 
        {
            "location": "/xenia/api/#look-at-the-details-of-a-query", 
            "text": "./xenia query get -n basic\n\noutput:\n\n{\n    name : basic ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  :  42021 }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      }\n   ]\n}", 
            "title": "Look at the details of a query:"
        }, 
        {
            "location": "/xenia/api/#execute-a-query", 
            "text": "./xenia query exec -n basic\n\noutput:\n\n{\n   results :[\n    {\n       Name : basic ,\n       Docs :[\n        {\n           name : C14 - Pasco County Buoy, FL \n        }\n      ]\n    }\n  ],\n   error :false\n}", 
            "title": "Execute a query:"
        }, 
        {
            "location": "/xenia/api/#add-or-update-a-query-for-use", 
            "text": "./xenia query upsert -p ./scrquery/basic_var.json\n\noutput:\n\nUpserting Query : Path[./scrquery/basic_var.json]  By convention, we store core query scripts in the  /xenia/cmd/xenia/scrquery  folder.  As we develop Coral features, store the JSON files there so other developers can use them (eventually, groups of query sets will be refactored to another location, but that s the right folder for the time being).  cd $GOPATH/src/github.com/coralproject/xenia/cmd/xenia/scrquery\nls", 
            "title": "Add or update a query for use:"
        }, 
        {
            "location": "/xenia/api/#direct-mongo-access-optional", 
            "text": "You can look in the db at existing queries:  mongo [flags to connect to your server]\nuse coral (or your databasename)\ndb.query_sets.find()", 
            "title": "Direct Mongo access (optional)"
        }, 
        {
            "location": "/xenia/api/#writing-sets", 
            "text": "Writing a set  is essentially about creating a MongoDB aggregation pipeline. Xenia has built on top of this by providing extended functionality to make MongoDB more powerful.  Here is a multi query set with variable substitution and date processing:  GET\nhttp://localhost:4000/1.0/exec/basic?station_id=42021\n\n{\n    name : basic ,\n    desc : Shows a basic multi result query. ,\n    enabled :true,\n    queries :[\n      {\n          name : Basic ,\n          type : pipeline ,\n          collection : test_bill ,\n          return :true,\n          scripts :[\n            { $match : { station_id  :  #station_id# }},\n            { $project : { _id : 0,  name : 1}}\n         ]\n      },\n      {\n          name : Time ,\n          type : pipeline ,\n          collection : test_bill ,\n          return :true,\n          scripts :[\n            { $match : { condition.date  : { $gt :  #date:2013-01-01T00:00:00.000Z }}},\n            { $project : { _id : 0,  name : 1}},\n            { $limit : 2}\n         ]\n      }\n   ]\n}  Here is the list of commands that exist for variable substitution.  { field :  #cmd:variable }\n\n// Basic commands.\nBefore: { field :  #number:variable_name }      After: { field : 1234}\nBefore: { field :  #string:variable_name }      After: { field :  value }\nBefore: { field :  #date:variable_name }        After: { field : time.Time}\nBefore: { field :  #objid:variable_name }       After: { field : mgo.ObjectId}\nBefore: { field :  #regex:/pattern/{options} }  After: { field : bson.RegEx}\n\n// data command can index into saved results.\nBefore: { field  : { $in :  #data.*:list.station_id }}}   After: [{ station_id : 42021 }]\nBefore: { field :  #data.0:doc.station_id }               After: { field :  23453 }\n\n// time command manipulates the current time.\nBefore: { field : #time:0}                 After: { field : time.Time(Current Time)}\nBefore: { field : #time:-3600}             After: { field : time.Time(3600 seconds in the past)}\nBefore: { field : #time:3m}                After: { field : time.Time(3 minutes in the future)}\n\nPossible duration types. Default is seconds if not provided. ns : Nanosecond us : Microsecond ms : Millisecond s  : Second m  : Minute h  : Hour  You can save the result of one query for later use by the next.  GET\nhttp://localhost:4000/1.0/exec/basic_save\n\n{\n    name : basic_save ,\n    desc : ,\n    enabled :true,\n    params :[],\n    queries :[\n      {\n          name : get_id_list ,\n          desc :  Get the list of id's ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :false,\n          commands :[\n            { $project : { _id : 0,  station_id : 1}},\n            { $limit : 5}\n            { $save : { $map :  list }}\n         ]\n      },\n      {\n          name : retrieve_stations ,\n          desc :  Retrieve the list of stations ,\n          type : pipeline ,\n          collection : test_xenia_data ,\n          return :true,\n          commands :[\n            { $match : { station_id  : { $in :  #data.*:list.station_id }}},\n            { $project : { _id : 0,  name : 1}},\n         ]\n      }\n   ]\n}  The  $save  command is an Xenia extension and currently only  $map  is supported.  { $save : { $map :  list }}  The result will be saved in a map under the name  list .  The second query is using the  #data  command. The data command has two options. Use can use  #data.*  or  #data.Idx .  Use the  *  operator when you need an array. In this example we need to support an  $in  command:  {\n    name : retrieve_stations ,\n    desc :  Retrieve the list of stations ,\n    type : pipeline ,\n    collection : test_xenia_data ,\n    return :true,\n    commands :[\n      { $match : { station_id  : { $in :  #data.*:list.station_id }}},\n      { $project : { _id : 0,  name : 1}},\n   ]\n}\n\nWhen you need an array to be substituted.\nBefore: { field  : { $in :  #data.*:list.station_id }}}\nAfter : { field  : { $in : [ 42021 ]}}\n    dataOp :  * \n    lookup :  list.station_id \n    results: { list : [{ station_id : 42021 }]}  Use the index operator when you need a single value. Specify which document in the array of documents you want to select:  \n{\n    name : retrieve_stations ,\n    desc :  Retrieve the list of stations ,\n    type : pipeline ,\n    collection : test_xenia_data ,\n    return :true,\n    commands :[\n      { $match : { station_id  :  #data.0:list.station_id }},\n      { $project : { _id : 0,  name : 1}},\n   ]\n}\n\nWhen you need a single value to be substituted, select an index.\nBefore: { field  :  #data.0:list.station_id }\nAfter : { field  :  42021 }\n    dataOp : 0\n    lookup :  list.station_id \n    results: { list : [{ station_id : 42021 }, { station_id : 23567 }]}  You can also replace field names in the query commands.  Variables\n{\n   cond :  condition ,\n   dt :  date \n}\n\nQuery Set\n{\n    name : basic ,\n    desc : Shows field substitution. ,\n    enabled :true,\n    queries :[\n      {\n          name : Time ,\n          type : pipeline ,\n          collection : test_bill ,\n          return :true,\n          scripts :[\n            { $match : { {cond}.{dt}  : { $gt :  #date:2013-01-01T00:00:00.000Z }}},\n            { $project : { _id : 0,  name : 1}},\n            { $limit : 2}\n         ]\n      }\n   ]\n}", 
            "title": "Writing Sets"
        }, 
        {
            "location": "/xenia/tests/", 
            "text": "Running Tests\n\n\nYou can run tests in the \napp\n and \npkg\n folder.\n\n\nIf you plan to run tests in parallel, use this command:\n\n\ngo test -cpu 1 ./...\n\n\n\n\nYou can always run individual tests in each package using simply:\n\n\ngo test\n\n\n\n\nDo not run tests in the vendor folder.", 
            "title": "Testing"
        }, 
        {
            "location": "/xenia/tests/#running-tests", 
            "text": "You can run tests in the  app  and  pkg  folder.  If you plan to run tests in parallel, use this command:  go test -cpu 1 ./...  You can always run individual tests in each package using simply:  go test  Do not run tests in the vendor folder.", 
            "title": "Running Tests"
        }, 
        {
            "location": "/xenia/xenia-driver-js/", 
            "text": "Xenia Driver\n\n\nXenia-driver-js\n is a JavaScript library that performs queries to \nXenia\n from the browser, or from a Node.js application.", 
            "title": "Introduction"
        }, 
        {
            "location": "/xenia/xenia-driver-js/#xenia-driver", 
            "text": "Xenia-driver-js  is a JavaScript library that performs queries to  Xenia  from the browser, or from a Node.js application.", 
            "title": "Xenia Driver"
        }, 
        {
            "location": "/xenia/xenia-driver-js-install/", 
            "text": "Xenia Driver Installation\n\n\n$ npm install --save xenia-driver\n\n\n\n\nImport and use\n\n\nimport XeniaDriver from 'xenia-driver'\n\n// Configure your instance\nconst xenia = XeniaDriver(baseUrl, {username: 'user', password: 'pass'})\n\n// Use the driver\nxenia()\n  .match({ 'category': 'sports' })\n  .include(['comments', 'name'])\n  .limit(14)\n  .skip(8)\n.join('my_collection')\n.exec().then(data =\n console.log(data.results))", 
            "title": "Installation"
        }, 
        {
            "location": "/xenia/xenia-driver-js-install/#xenia-driver-installation", 
            "text": "$ npm install --save xenia-driver", 
            "title": "Xenia Driver Installation"
        }, 
        {
            "location": "/xenia/xenia-driver-js-install/#import-and-use", 
            "text": "import XeniaDriver from 'xenia-driver'\n\n// Configure your instance\nconst xenia = XeniaDriver(baseUrl, {username: 'user', password: 'pass'})\n\n// Use the driver\nxenia()\n  .match({ 'category': 'sports' })\n  .include(['comments', 'name'])\n  .limit(14)\n  .skip(8)\n.join('my_collection')\n.exec().then(data =  console.log(data.results))", 
            "title": "Import and use"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/", 
            "text": "Xenia Driver API\n\n\nList of queries\n\n\n\n\nXeniaDriver(baseURL, auth [, queryParams] [, reqParams])\n\n\naddQuery(queryData)\n\n\ncollection(name)\n\n\nexec(queryName, params)\n\n\ngetQueries()\n\n\ngetQuery(name)\n\n\nsaveQuery(name)\n\n\ndeleteQuery(name)\n\n\nlimit(n)\n\n\nskip(n)\n\n\nsample(n)\n\n\nproject(fields)\n\n\ninclude(fieldNames)\n\n\nexclude(fieldNames)\n\n\nmatch(query)\n\n\nredact(query)\n\n\nunwind(path, includeArrayIndex, preserveNullAndEmptyArrays)\n\n\ngroup(groups)\n\n\nsort(order)\n\n\njoin(collection, field, matchingField, name)\n\n\n\n\nXeniaDriver(baseURL, auth [, queryParams] [, reqParams])\n\n\nCreates a new \nXeniaDriver\n instance\n\n\n\n\nbaseURL\n (String) - Xenia server base url\n\n\nauth\n (String | Object) - basic authentication credentials. If it\ns a string it should be the Basic authentication value for the Authorization header\n\n\n[auth.username]\n (String) - Auth username\n\n\n[auth.password]\n (String) - Auth password\n\n\n[queryParams]\n (Object) - It can hold a Xenia raw query to perform before the rest of the queries\n\n\n[reqParams]\n (Object) - Add your own parameters to the request\n\n\n\n\nconst xenia = XeniaDriver('https://my-xenia-url.com', 'Basic kewlrgm;we4p3jtqpwfawmeklfdmdsadlm')\n\n\n\n\naddQuery(queryData)\n\n\nInitialize a query. When the xenia constructor runs it will call this function for you. Use it for adding more than one query in the same request.\n\n\n\n\n[queryData]\n (Object) - Provide the configuration for the new query\n\n\n\n\nxenia()\n  .limit(20).skip(10)\n  .addQuery().match({'name': 'John Doe'})\n  .exec().then(data =\n console.log(data))\n\n\n\n\ncollection(name)\n\n\nSet the current query collection\n\n\n\n\nname\n (String) - collection name\n\n\n\n\nxenia()\n  .collection('users')\n  .exclude(['_id'])\n  .exec().then(data =\n console.log(data))\n\n\n\n\nexec(queryName, params)\n\n\nExecutes the request\n\n\n\n\n[name]\n (string) - Executes a saved query by name\n\n\n[params]\n (Object) - Custom request parameters\n\n\n\n\nxenia().exec('my_saved_query').then(data =\n console.log(data))\n\n// Or\n\nxenia().limit(20).skip(10)\n  .exec().then(data =\n console.log(data))\n  .catch(err =\n console.log(err))\n\n\n\n\ngetQueries()\n\n\nGet a list of available queries\n\n\nxenia().getQueries().then(data =\n console.log(data))\n\n\n\n\ngetQuery(name)\n\n\nGet a specific query document\n\n\n\n\nname\n (String) - query name\n\n\n\n\nxenia().getQuery('my_query').then(data =\n console.log(data))\n\n\n\n\nsaveQuery(name)\n\n\nSave a new query\n\n\n\n\n[name]\n (String) - query name\n\n\n\n\nxenia()\n  .collection('users')\n  .limit(5).include(['name', 'avatar'])\n  .saveQuery('first users').then(data =\n console.log(data))\n\n\n\n\ndeleteQuery(name)\n\n\nDelete a query\n\n\n\n\n[name]\n (String) - query name\n\n\n\n\nxenia()\n  .deleteQuery('first users')\n  .then(data =\n console.log(data))\n\n\n\n\nlimit(n)\n\n\nLimit the amount of retrieved documents\n\n\n\n\n[n]\n (Number) - number of docs to retrieve, default: 20\n\n\n\n\nxenia().limit(15)\n\n\n\n\nskip(n)\n\n\nSkip the first n documents\n\n\n\n\n[n]\n (Number) - number of skipped docs, default: 0\n\n\n\n\nxenia().skip(12)\n\n\n\n\nsample(n)\n\n\nReturn a document sample from the collection\n\n\n\n\n[n]\n (Number) - number of sample docs, default: 20\n\n\n\n\nxenia().sample(50)\n\n\n\n\nproject(fields)\n\n\nInclude and exclude fields from the result using the $project aggregation pipeline operator. You\nll find out that \nXenia#include\n and \nXenia#exclude\n can be easier to use for most scenarios.\n\n\n\n\nfields\n (Object) - Aggregation fields object\n\n\n\n\nxenia()\n  .project({'name': true, '_id': false, 'comments': { 'country': true}})\n\n\n\n\ninclude(fieldNames)\n\n\nWhitelist retrieved fields\n\n\n\n\nfieldNames\n (Array) - fields you want to retrieve\n\n\n\n\nxenia().include(['name', 'avatar'])\n\n\n\n\nexclude(fieldNames)\n\n\nBlacklist retrieved fields\n\n\n\n\nfieldNames\n (Array) - fields you don\nt want to retrieve\n\n\n\n\nxenia().exclude(['age', 'gender'])\n\n\n\n\nmatch(query)\n\n\nPerforms a match command on the aggregation pipeline\n\n\n\n\nquery\n (Object) - Match parameters\n\n\n\n\nxenia().match({ 'name': 'John', 'status': { '$in' : ['user', 'admin']} })\n\n\n\n\nredact(query)\n\n\nPerforms a redact command on the aggregation pipeline\n\n\n\n\nquery\n (Object) - Redact parameters\n\n\n\n\nxenia().redact({ $cond: {\n  if: { $gt: [ { $size: { $setIntersection: [ \n$tags\n, userAccess ] } }, 0 ] },\n  then: \n$$DESCEND\n,\n  else: \n$$PRUNE\n\n}})\n\n\n\n\nunwind(path, includeArrayIndex, preserveNullAndEmptyArrays)\n\n\nPerforms a unwind command on the aggregation pipeline - Deconstructs an array field from the input documents to output a document for each element\n\n\n\n\npath\n (Object | String) - Field path\n\n\n[includeArrayIndex]\n (String) - arrayIndex name\n\n\n[preserveNullAndEmptyArrays]\n (Boolean) - preserve null and empty arrays, default false\n\n\n\n\nxenia().unwind('$comments')\n\n\n\n\ngroup(groups)\n\n\nGroup documents\n\n\n\n\ngroups\n (Object) - group object\n\n\n\n\nxenia().group({ _id : { month: { $month: '$date' } })\n\n\n\n\nsort(order)\n\n\nSort documents by fields\n\n\n\n\norder\n (Object|Array) - how to sort the data\n\n\n\n\nxenia().sort(['name', 1])\n\n// Or\n\nxenia.sort({'name': 1, 'statistics.comments.count': -1})\n\n\n\n\njoin(collection, field, matchingField, name)\n\n\nCreates a new query joining the actual one using the save method from Xenia\n\n\n\n\ncollection\n (String) - The collection you want to join\n\n\n[field]\n (String) - The matching field in the collection you want to join, default: _id\n\n\n[matchingField]\n (String) - The field to match in your actual collection, default: same as field parameter\n\n\n[name]\n (String) - The field name on the results, default: list\n\n\n\n\nxenia().collection('comments')\n.include(['body', 'asset_id']).limit(5)\n\n.join('assets', '_id', 'asset_id', 'asset')\n\n.include(['section']).exec()\n\n\n\n\nDevelopment\n\n\n$ npm start\n\n\n\nTest\n\n\n$ npm test", 
            "title": "API"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#xenia-driver-api", 
            "text": "", 
            "title": "Xenia Driver API"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#list-of-queries", 
            "text": "XeniaDriver(baseURL, auth [, queryParams] [, reqParams])  addQuery(queryData)  collection(name)  exec(queryName, params)  getQueries()  getQuery(name)  saveQuery(name)  deleteQuery(name)  limit(n)  skip(n)  sample(n)  project(fields)  include(fieldNames)  exclude(fieldNames)  match(query)  redact(query)  unwind(path, includeArrayIndex, preserveNullAndEmptyArrays)  group(groups)  sort(order)  join(collection, field, matchingField, name)", 
            "title": "List of queries"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#xeniadriverbaseurl-auth-queryparams-reqparams", 
            "text": "Creates a new  XeniaDriver  instance   baseURL  (String) - Xenia server base url  auth  (String | Object) - basic authentication credentials. If it s a string it should be the Basic authentication value for the Authorization header  [auth.username]  (String) - Auth username  [auth.password]  (String) - Auth password  [queryParams]  (Object) - It can hold a Xenia raw query to perform before the rest of the queries  [reqParams]  (Object) - Add your own parameters to the request   const xenia = XeniaDriver('https://my-xenia-url.com', 'Basic kewlrgm;we4p3jtqpwfawmeklfdmdsadlm')", 
            "title": "XeniaDriver(baseURL, auth [, queryParams] [, reqParams])"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#addqueryquerydata", 
            "text": "Initialize a query. When the xenia constructor runs it will call this function for you. Use it for adding more than one query in the same request.   [queryData]  (Object) - Provide the configuration for the new query   xenia()\n  .limit(20).skip(10)\n  .addQuery().match({'name': 'John Doe'})\n  .exec().then(data =  console.log(data))", 
            "title": "addQuery(queryData)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#collectionname", 
            "text": "Set the current query collection   name  (String) - collection name   xenia()\n  .collection('users')\n  .exclude(['_id'])\n  .exec().then(data =  console.log(data))", 
            "title": "collection(name)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#execqueryname-params", 
            "text": "Executes the request   [name]  (string) - Executes a saved query by name  [params]  (Object) - Custom request parameters   xenia().exec('my_saved_query').then(data =  console.log(data))\n\n// Or\n\nxenia().limit(20).skip(10)\n  .exec().then(data =  console.log(data))\n  .catch(err =  console.log(err))", 
            "title": "exec(queryName, params)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#getqueries", 
            "text": "Get a list of available queries  xenia().getQueries().then(data =  console.log(data))", 
            "title": "getQueries()"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#getqueryname", 
            "text": "Get a specific query document   name  (String) - query name   xenia().getQuery('my_query').then(data =  console.log(data))", 
            "title": "getQuery(name)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#savequeryname", 
            "text": "Save a new query   [name]  (String) - query name   xenia()\n  .collection('users')\n  .limit(5).include(['name', 'avatar'])\n  .saveQuery('first users').then(data =  console.log(data))", 
            "title": "saveQuery(name)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#deletequeryname", 
            "text": "Delete a query   [name]  (String) - query name   xenia()\n  .deleteQuery('first users')\n  .then(data =  console.log(data))", 
            "title": "deleteQuery(name)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#limitn", 
            "text": "Limit the amount of retrieved documents   [n]  (Number) - number of docs to retrieve, default: 20   xenia().limit(15)", 
            "title": "limit(n)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#skipn", 
            "text": "Skip the first n documents   [n]  (Number) - number of skipped docs, default: 0   xenia().skip(12)", 
            "title": "skip(n)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#samplen", 
            "text": "Return a document sample from the collection   [n]  (Number) - number of sample docs, default: 20   xenia().sample(50)", 
            "title": "sample(n)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#projectfields", 
            "text": "Include and exclude fields from the result using the $project aggregation pipeline operator. You ll find out that  Xenia#include  and  Xenia#exclude  can be easier to use for most scenarios.   fields  (Object) - Aggregation fields object   xenia()\n  .project({'name': true, '_id': false, 'comments': { 'country': true}})", 
            "title": "project(fields)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#includefieldnames", 
            "text": "Whitelist retrieved fields   fieldNames  (Array) - fields you want to retrieve   xenia().include(['name', 'avatar'])", 
            "title": "include(fieldNames)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#excludefieldnames", 
            "text": "Blacklist retrieved fields   fieldNames  (Array) - fields you don t want to retrieve   xenia().exclude(['age', 'gender'])", 
            "title": "exclude(fieldNames)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#matchquery", 
            "text": "Performs a match command on the aggregation pipeline   query  (Object) - Match parameters   xenia().match({ 'name': 'John', 'status': { '$in' : ['user', 'admin']} })", 
            "title": "match(query)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#redactquery", 
            "text": "Performs a redact command on the aggregation pipeline   query  (Object) - Redact parameters   xenia().redact({ $cond: {\n  if: { $gt: [ { $size: { $setIntersection: [  $tags , userAccess ] } }, 0 ] },\n  then:  $$DESCEND ,\n  else:  $$PRUNE \n}})", 
            "title": "redact(query)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#unwindpath-includearrayindex-preservenullandemptyarrays", 
            "text": "Performs a unwind command on the aggregation pipeline - Deconstructs an array field from the input documents to output a document for each element   path  (Object | String) - Field path  [includeArrayIndex]  (String) - arrayIndex name  [preserveNullAndEmptyArrays]  (Boolean) - preserve null and empty arrays, default false   xenia().unwind('$comments')", 
            "title": "unwind(path, includeArrayIndex, preserveNullAndEmptyArrays)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#groupgroups", 
            "text": "Group documents   groups  (Object) - group object   xenia().group({ _id : { month: { $month: '$date' } })", 
            "title": "group(groups)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#sortorder", 
            "text": "Sort documents by fields   order  (Object|Array) - how to sort the data   xenia().sort(['name', 1])\n\n// Or\n\nxenia.sort({'name': 1, 'statistics.comments.count': -1})", 
            "title": "sort(order)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#joincollection-field-matchingfield-name", 
            "text": "Creates a new query joining the actual one using the save method from Xenia   collection  (String) - The collection you want to join  [field]  (String) - The matching field in the collection you want to join, default: _id  [matchingField]  (String) - The field to match in your actual collection, default: same as field parameter  [name]  (String) - The field name on the results, default: list   xenia().collection('comments')\n.include(['body', 'asset_id']).limit(5)\n\n.join('assets', '_id', 'asset_id', 'asset')\n\n.include(['section']).exec()", 
            "title": "join(collection, field, matchingField, name)"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#development", 
            "text": "$ npm start", 
            "title": "Development"
        }, 
        {
            "location": "/xenia/xenia-driver-js-api/#test", 
            "text": "$ npm test", 
            "title": "Test"
        }, 
        {
            "location": "/user/", 
            "text": "Introduction\n\n\nWelcome! This is the place to be if you want to learn more about Coral as a user. We\nll guide you through the different products and show you tutorials on how to make the best use of the tools.\n\n\nCan you think of some tutorial or how-to guide that we\nre missing? We\nd love for you to create and share it! You can read more about contributing to our documentation in our \nContribute section\n.\n\n\nIf you are looking for information on how to install Coral, check out the \nDeveloper Guide\n section.\n\n\nHow the User Guide section is organized\n\n\nWe have a User Guide for each Coral product (Trust, Ask, and Talk).\n\n\n\n\nEach product has an \noverview section\n to tell you a little about the product, the goals for that product, and a high level explanation of its functionality.\n\n\nEach product also has a set of \ntutorials\n, to show you how you can perform certain tasks using that product.\n\n\n\n\nTrust\n\n\n\n\nTrust overview\n\n\nTrust tutorials\n\n\n\n\nAsk\n\n\n\n\nAsk overview\n\n\nAsk tutorials\n\n\n\n\nTalk\n\n\n\n\nTalk overview\n\n\nTalk tutorials", 
            "title": "Introduction"
        }, 
        {
            "location": "/user/#introduction", 
            "text": "Welcome! This is the place to be if you want to learn more about Coral as a user. We ll guide you through the different products and show you tutorials on how to make the best use of the tools.  Can you think of some tutorial or how-to guide that we re missing? We d love for you to create and share it! You can read more about contributing to our documentation in our  Contribute section .  If you are looking for information on how to install Coral, check out the  Developer Guide  section.", 
            "title": "Introduction"
        }, 
        {
            "location": "/user/#how-the-user-guide-section-is-organized", 
            "text": "We have a User Guide for each Coral product (Trust, Ask, and Talk).   Each product has an  overview section  to tell you a little about the product, the goals for that product, and a high level explanation of its functionality.  Each product also has a set of  tutorials , to show you how you can perform certain tasks using that product.", 
            "title": "How the User Guide section is organized"
        }, 
        {
            "location": "/user/#trust", 
            "text": "Trust overview  Trust tutorials", 
            "title": "Trust"
        }, 
        {
            "location": "/user/#ask", 
            "text": "Ask overview  Ask tutorials", 
            "title": "Ask"
        }, 
        {
            "location": "/user/#talk", 
            "text": "Talk overview  Talk tutorials", 
            "title": "Talk"
        }, 
        {
            "location": "/user/trust/", 
            "text": "Trust\n\n\nWhat is Trust?\n\n\nThe Trust product is a tool that allows journalistic organizations to filter through and create metrics based on individual comment behavior, and also add qualitative information. This information can be used to help journalistic organizations take next steps to better utilize and strengthen their communities.\n\n\nThe \ntutorials page\n will help guide you through accomplishing goals like the following:\n\n\n\n\nI would like to find the most liked comments based on keyword/topic searches, so that I can do a round up (for instance, \nbest comments written about the Zika virus\u201d).\n\n\nI would like to identify commenters who leave high-quality comments that appear to be expert, so that potential sources can be identified.\n\n\nI would like to identify new commenters who leave comments that get a lot of likes, so I can welcome them personally.\n\n\nI would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.\n\n\n\n\nTrust sections\n\n\nTrust is comprised of the following sections:\n\n\n\n\nDashboard\n\n\nCommunity Explorer\n\n\nLists\n\n\nSettings\n\n\nLogin/Authentication\n\n\n\n\nDashboard\n\n\nCommunity Explorer\n\n\nLists\n\n\nSettings", 
            "title": "Overview"
        }, 
        {
            "location": "/user/trust/#trust", 
            "text": "", 
            "title": "Trust"
        }, 
        {
            "location": "/user/trust/#what-is-trust", 
            "text": "The Trust product is a tool that allows journalistic organizations to filter through and create metrics based on individual comment behavior, and also add qualitative information. This information can be used to help journalistic organizations take next steps to better utilize and strengthen their communities.  The  tutorials page  will help guide you through accomplishing goals like the following:   I would like to find the most liked comments based on keyword/topic searches, so that I can do a round up (for instance,  best comments written about the Zika virus\u201d).  I would like to identify commenters who leave high-quality comments that appear to be expert, so that potential sources can be identified.  I would like to identify new commenters who leave comments that get a lot of likes, so I can welcome them personally.  I would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.", 
            "title": "What is Trust?"
        }, 
        {
            "location": "/user/trust/#trust-sections", 
            "text": "Trust is comprised of the following sections:   Dashboard  Community Explorer  Lists  Settings  Login/Authentication", 
            "title": "Trust sections"
        }, 
        {
            "location": "/user/trust/#dashboard", 
            "text": "", 
            "title": "Dashboard"
        }, 
        {
            "location": "/user/trust/#community-explorer", 
            "text": "", 
            "title": "Community Explorer"
        }, 
        {
            "location": "/user/trust/#lists", 
            "text": "", 
            "title": "Lists"
        }, 
        {
            "location": "/user/trust/#settings", 
            "text": "", 
            "title": "Settings"
        }, 
        {
            "location": "/user/trust_tutorials/", 
            "text": "Trust tutorials\n\n\nThis is where you can find tutorials on how to best utilize the Trust product.\n\n\nDo you have a tutorial you\nd like to see here? Please \nget in touch and let us know about it\n, or better still, \nadd it yourself!\n\n\nWhat would you like to do?\n\n\n\n\nIdentify the most liked comments\n: I would like to find the most liked comments based on keyword/topic searches, so that I can do a round up (for instance, \nbest comments written about the Zika virus\u201d).\n\n\nIdentify high quality comments\n: I would like to identify commenters who leave high-quality comments that appear to be expert, so that potential sources can be identified.\n\n\nIdentify high quality new commenters\n: I would like to identify new commenters who leave comments that get a lot of likes, so I can welcome them personally.\n\n\nIdentify trolls\n: I would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.\n\n\n\n\nIdentify most liked comments\n\n\nSpecifically, we\nd like to identify the most liked comments based on keyword/topic searches, so that we can do a round up (for instance, \nbest comments written about the Zika virus\u201d).\n\n\nIdentify high quality new commenters\n\n\nWe would like to identify new commenters who leave comments that get a lot of likes, so we can welcome them personally.\n\n\nIdentify trolls\n\n\nWe would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.\n\n\nWhat are some ways that can we identify trolls?\n\n\n\n\nA user with a high percentage of moderator deleted comments.\n\n\n\n\nWhat might we be able to do about users like this?\n\n\n\n\nIt\ns possible that a user may not exhibit troll behavior in all sections or for all authors. We can identify the sections in which they havea  high percentage of moderator deleted comments and ban them only for those sections/authors, so that they can continue to contribute to the community elsewhere.\n\n\nWe can automatically move that user\ns comments into pre-moderation.\n\n\n\n\nHow to identify trolls on certain topics or authors\n\n\nWe are going to create and save a list of commenters who have a high percentage of moderated deleted comments for a particular section or author. For the purposes of this tutorial, we\nll assume we are looking for trolls in the \nNational\n section.\n\n\n1) Open the \nCreate a Search\n page by clicking the wrench symbol on the side navigation bar.\n\n\n\n\n2) In the \nFilters\n section, choose \nSection\n in the drop down. This will trigger the display of a second drop down, which will let you choose which section you want to filter in (in this case, the \nnational\n section).\n\n\n \n\n\n3) Scroll down to the \nPercent moderator deleted\n filter.\n\n\n\n\n4) Fill in \n50\n and \n100\n: you\nre now filtering out all of the users in the \nNational\n section who have had 50% or more of their comments moderator deleted.\n\n\n\n\n5) You now have a filter that shows you all of the users who have had over 50% of their comments in the National section deleted by moderators. You can now save that search to refer back to later, or to allow your colleagues to have access to the search as well.\n\n\nClick the \nSave Search\n button in the upper right to save.\n\n\n\n\n6) You can now fill in the name of the search and a brief description. The \ntag\n field will create a tag that will attach itself to each user in the \nTrolls in National section\n list.\n\n\nClick \nConfirm\n to save your search.\n\n\n\n\n7) You (and your colleagues) can now access this saved search via the \nSaved Search\n button in the side navigation bar.", 
            "title": "Tutorials"
        }, 
        {
            "location": "/user/trust_tutorials/#trust-tutorials", 
            "text": "This is where you can find tutorials on how to best utilize the Trust product.  Do you have a tutorial you d like to see here? Please  get in touch and let us know about it , or better still,  add it yourself!", 
            "title": "Trust tutorials"
        }, 
        {
            "location": "/user/trust_tutorials/#what-would-you-like-to-do", 
            "text": "Identify the most liked comments : I would like to find the most liked comments based on keyword/topic searches, so that I can do a round up (for instance,  best comments written about the Zika virus\u201d).  Identify high quality comments : I would like to identify commenters who leave high-quality comments that appear to be expert, so that potential sources can be identified.  Identify high quality new commenters : I would like to identify new commenters who leave comments that get a lot of likes, so I can welcome them personally.  Identify trolls : I would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.", 
            "title": "What would you like to do?"
        }, 
        {
            "location": "/user/trust_tutorials/#identify-most-liked-comments", 
            "text": "Specifically, we d like to identify the most liked comments based on keyword/topic searches, so that we can do a round up (for instance,  best comments written about the Zika virus\u201d).", 
            "title": "Identify most liked comments"
        }, 
        {
            "location": "/user/trust_tutorials/#identify-high-quality-new-commenters", 
            "text": "We would like to identify new commenters who leave comments that get a lot of likes, so we can welcome them personally.", 
            "title": "Identify high quality new commenters"
        }, 
        {
            "location": "/user/trust_tutorials/#identify-trolls", 
            "text": "We would like to identify trolls on certain topics or authors, so that their comments on these subjects can automatically be moved to pre-moderation/create notifications for moderators to pay attention.  What are some ways that can we identify trolls?   A user with a high percentage of moderator deleted comments.   What might we be able to do about users like this?   It s possible that a user may not exhibit troll behavior in all sections or for all authors. We can identify the sections in which they havea  high percentage of moderator deleted comments and ban them only for those sections/authors, so that they can continue to contribute to the community elsewhere.  We can automatically move that user s comments into pre-moderation.", 
            "title": "Identify trolls"
        }, 
        {
            "location": "/user/trust_tutorials/#how-to-identify-trolls-on-certain-topics-or-authors", 
            "text": "We are going to create and save a list of commenters who have a high percentage of moderated deleted comments for a particular section or author. For the purposes of this tutorial, we ll assume we are looking for trolls in the  National  section.  1) Open the  Create a Search  page by clicking the wrench symbol on the side navigation bar.   2) In the  Filters  section, choose  Section  in the drop down. This will trigger the display of a second drop down, which will let you choose which section you want to filter in (in this case, the  national  section).     3) Scroll down to the  Percent moderator deleted  filter.   4) Fill in  50  and  100 : you re now filtering out all of the users in the  National  section who have had 50% or more of their comments moderator deleted.   5) You now have a filter that shows you all of the users who have had over 50% of their comments in the National section deleted by moderators. You can now save that search to refer back to later, or to allow your colleagues to have access to the search as well.  Click the  Save Search  button in the upper right to save.   6) You can now fill in the name of the search and a brief description. The  tag  field will create a tag that will attach itself to each user in the  Trolls in National section  list.  Click  Confirm  to save your search.   7) You (and your colleagues) can now access this saved search via the  Saved Search  button in the side navigation bar.", 
            "title": "How to identify trolls on certain topics or authors"
        }, 
        {
            "location": "/user/ask/", 
            "text": "Ask\n\n\nThis page will get filled in as we unroll the Ask product. In the meantime, you can find out more on the Ask product on \nour website\n.", 
            "title": "Overview"
        }, 
        {
            "location": "/user/ask/#ask", 
            "text": "This page will get filled in as we unroll the Ask product. In the meantime, you can find out more on the Ask product on  our website .", 
            "title": "Ask"
        }, 
        {
            "location": "/user/ask_tutorials/", 
            "text": "Ask tutorials\n\n\nThis page will get filled in as we unroll the Ask product. In the meantime, you can find out more on the Ask product on \nour website\n.", 
            "title": "Tutorials"
        }, 
        {
            "location": "/user/ask_tutorials/#ask-tutorials", 
            "text": "This page will get filled in as we unroll the Ask product. In the meantime, you can find out more on the Ask product on  our website .", 
            "title": "Ask tutorials"
        }, 
        {
            "location": "/user/talk/", 
            "text": "Talk\n\n\nThis page will get filled in as we unroll the Talk product. In the meantime, you can find out more on the Talk product on \nour website\n.", 
            "title": "Overview"
        }, 
        {
            "location": "/user/talk/#talk", 
            "text": "This page will get filled in as we unroll the Talk product. In the meantime, you can find out more on the Talk product on  our website .", 
            "title": "Talk"
        }, 
        {
            "location": "/user/talk_tutorials/", 
            "text": "Talk tutorials\n\n\nThis page will get filled in as we unroll the Talk product. In the meantime, you can find out more on the Talk product on \nour website\n.", 
            "title": "Tutorials"
        }, 
        {
            "location": "/user/talk_tutorials/#talk-tutorials", 
            "text": "This page will get filled in as we unroll the Talk product. In the meantime, you can find out more on the Talk product on  our website .", 
            "title": "Talk tutorials"
        }, 
        {
            "location": "/contribute/", 
            "text": "Contributing to the Coral Project\n\n\nWelcome! We\nre delighted to have you contribute to the Coral Project. Before you get started, be sure to review our \nCode of Conduct\n, which governs all development and project contributions.\n\n\nThere are a number of ways that you can contribute to the Coral Project: you don\nt have to be a developer to help out.\n\n\nContributing without programming\n\n\nWe need help with a number of non-programming tasks:\n\n\n\n\nReport bugs\n\n\nRequest features\n\n\nWrite and edit documentation\n\n\n\n\nContributing by coding\n\n\nIf you are a developer, especially if you know Go or Node.js, we would love your help in fixing bugs and developing new features and plug-ins.\n\n\n\n\nWrite code\n\n\n\n\nContributing to the community\n\n\n\n\nJoin us in our community forum\n to discuss online communities, comment sections, and journalism. Offer suggestions, ask questions!\n\n\nSign up to our newsletter\n.\n\n\nWe are also on \nTwitter\n.\n\n\nPlay our \nCards Against Community\n card game!", 
            "title": "Introduction"
        }, 
        {
            "location": "/contribute/#contributing-to-the-coral-project", 
            "text": "Welcome! We re delighted to have you contribute to the Coral Project. Before you get started, be sure to review our  Code of Conduct , which governs all development and project contributions.  There are a number of ways that you can contribute to the Coral Project: you don t have to be a developer to help out.", 
            "title": "Contributing to the Coral Project"
        }, 
        {
            "location": "/contribute/#contributing-without-programming", 
            "text": "We need help with a number of non-programming tasks:   Report bugs  Request features  Write and edit documentation", 
            "title": "Contributing without programming"
        }, 
        {
            "location": "/contribute/#contributing-by-coding", 
            "text": "If you are a developer, especially if you know Go or Node.js, we would love your help in fixing bugs and developing new features and plug-ins.   Write code", 
            "title": "Contributing by coding"
        }, 
        {
            "location": "/contribute/#contributing-to-the-community", 
            "text": "Join us in our community forum  to discuss online communities, comment sections, and journalism. Offer suggestions, ask questions!  Sign up to our newsletter .  We are also on  Twitter .  Play our  Cards Against Community  card game!", 
            "title": "Contributing to the community"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/", 
            "text": "Writing Documentation\n\n\nThis section explains how the community can contribute to the Coral Project documentation.\n\n\nYou can contribute to the documentation by editing existing documents for clarity or correcting errors. Additionally, any new features or changes to the software should be thoroughly documented. We value clear, consistent, thorough, readable documentation!\n\n\nHere is, briefly, how our documentation works:\n\n\n\n\nThe source documentation lives in GitHub at \nhttps://github.com/coralproject/docs/\n.\n\n\nThe documentation is hosted on \nGitHub pages\n.\n\n\nThe documentation is built using \nMkDocs\n, a Markdown-based static site generator (geared towards building project documentation).\n\n\nThe document is deployed using a simple Mkdocs command that builds the documentation and deploys it to GitHub pages.\n\n\n\n\nStyle Guide\n\n\nThere is a separate page for the \ndocumentation style guide\n, that covers guidelines for how to organize and write instructions and tutorials, how to format text for consistency, and terminology.\n\n\nHow the documentation is organized\n\n\nThe documentation is organized into several categories:\n\n\n\n\nIntroduction\n: This offers a general overview of the Coral Project and its different components.\n\n\nDeveloper Guide\n: This provides information for technical users of the Coral Project. It offers installation instructions for the Coral Ecosystem as a whole, as well as installation instructions for each individual component.\n\n\nRelease Notes\n also live within the Developer Guide section.\n\n\n\n\n\n\nUser Guide\n: This provides information for end users (publishers, journalists, moderators, readers) on how to use the features of Coral. It includes tutorials and how-to guides.\n\n\nContribute\n: This provides information on how to contribute to the Coral Project through open source. There are sections for the developers (how to work with GitHub, etc.), as well as sections for those who want to contribute to other pieces of the Coral Project (such as the documentation!).\n\n\nFAQ\n\n\n\n\nHow to obtain, write, and deploy documentation\n\n\nOur documentation is hosted and deployed through GitHub. This guide will take you step by step through the process of getting the documentation on to your local machine, editing the documentation, and submitting your changes. If you\nve never worked with Git before, it might seem a little intimidating, but we\nve broken it down for you into manageable chunks.\n\n\nBriefly, the process is as follows:\n\n\n\n\nFirst, you will get the documentation source code, using Git.\n\n\nThen, you will work on the documentation. You will use Mkdocs and Markdown to write the documentation.\n\n\nThen, you will push your changes to GitHub.\n\n\nFinally, you will deploy the documentation. This is done using a simple Mkdocs commands that builds the documentation and deploys it to GitHub pages.\n\n\n\n\nInstall and set up Git\n\n\nIf you don\nt already have Git installed, you\nll want to get that set up first. You\nll have to \ndownload and install Git\n. You can read more about Git on \ntheir website\n.\n\n\nYou will also have to \ncreate a GitHub account\n, which is a very straightforward process.\n\n\nAfter installing Git, the first thing you should do is setup your name and email using the following commands:\n\n\ngit config --global user.name \nYour Real Name\n\ngit config --global user.email \nyou@email.com\n\n\n\n\n\nNote that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.\n\n\nInstall MkDocs\n\n\nThe Coral Project\ns documentation uses the \nMkDocs\n documentation system, which uses \nMarkdown\n to format text. Before you can get started on writing and editing the documentation, you will need to have MkDocs installed.\n\n\nYou can \ndownload and install MkDocs\n using the instructions on their website. The \nMkDocs website\n also contains a lot of good information on writing documentation in MkDocs, and there are plenty of decent Markdown cheatsheets floating around, \nlike this one\n.\n\n\nGetting the documentation\n\n\nAll of the documentation for the Coral Project \nresides in GitHub\n in the \ndocs\n repository.\n\n\nTo get a local version of the documentation, clone the repository using this command:\n\n\ngit clone https://github.com/coralproject/docs.git\n\n\n\n\nYou now have a local copy of the documentation on your local machine, that you can modify and add to.\n\n\nNote\n: If you already have a local copy of the documentation repository on your computer, be sure to perform a \ngit pull\n before you start editing. This will ensure that you are working on the most recent available version of the documentation, which will prevent potential merge conflicts when you\nre ready to commit your changes.\n\n\nWriting and editing the documentation\n\n\nAs you are writing the documentation, refer to the \nDocumentation Style Guide\n to make sure you are remaining consistent with our current documentation standards, and writing the best and clearest documentation possible.\n\n\nCommit your changes\n\n\nOnce you\nve finished your edits, it\ns time to commit your changes back up to the remote repository on GitHub.\n\n\nFirst, you\nll add your changes, where \nfilename\n is the name of the file or files that you have changed.\n\n\ngit add \nfilename\n\n\n\n\n\nThen, you\nll commit your changes. Be sure to add a commit message (the portion within the single quotations) to let everyone know what it is that you\nve changed. The \n-m\n flag is what tells Git that you\nre adding a commit message.\n\n\ngit commit -m 'Updated the Ask tutorial'\n\n\n\n\nFinally, push your changes up to the remote repository:\n\n\ngit push origin master\n\n\n\n\nDeploy the documentation\n\n\nNow that the documentation has been updated and committed to the repository, you can deploy the documentation. The documentation is hosted on Heroku, so in order to deploy it, we need to first build the files that make up the site, and then push those files up to Heroku.\n\n\nFirst ensure that you have the latest version of the documentation on your local machine:\n\n\ngit pull\n\n\n\n\nThen, run the following command:\n\n\nmkdocs build --clean\n\n\n\n\nThe \nbuild\n command builds the documentation, creating the HTML pages that make up the site, and places those files in the \nsite\n directory.\n\n\nNow you\nll push the \nsite\n directory, containing the pages that make up the website, to Heroku. You can do this with the following command:\n\n\ngit subtree push --prefix site heroku master\n\n\n\n\nTranslating documentation\n\n\nTo come.", 
            "title": "Writing documentation"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#writing-documentation", 
            "text": "This section explains how the community can contribute to the Coral Project documentation.  You can contribute to the documentation by editing existing documents for clarity or correcting errors. Additionally, any new features or changes to the software should be thoroughly documented. We value clear, consistent, thorough, readable documentation!  Here is, briefly, how our documentation works:   The source documentation lives in GitHub at  https://github.com/coralproject/docs/ .  The documentation is hosted on  GitHub pages .  The documentation is built using  MkDocs , a Markdown-based static site generator (geared towards building project documentation).  The document is deployed using a simple Mkdocs command that builds the documentation and deploys it to GitHub pages.", 
            "title": "Writing Documentation"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#style-guide", 
            "text": "There is a separate page for the  documentation style guide , that covers guidelines for how to organize and write instructions and tutorials, how to format text for consistency, and terminology.", 
            "title": "Style Guide"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#how-the-documentation-is-organized", 
            "text": "The documentation is organized into several categories:   Introduction : This offers a general overview of the Coral Project and its different components.  Developer Guide : This provides information for technical users of the Coral Project. It offers installation instructions for the Coral Ecosystem as a whole, as well as installation instructions for each individual component.  Release Notes  also live within the Developer Guide section.    User Guide : This provides information for end users (publishers, journalists, moderators, readers) on how to use the features of Coral. It includes tutorials and how-to guides.  Contribute : This provides information on how to contribute to the Coral Project through open source. There are sections for the developers (how to work with GitHub, etc.), as well as sections for those who want to contribute to other pieces of the Coral Project (such as the documentation!).  FAQ", 
            "title": "How the documentation is organized"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#how-to-obtain-write-and-deploy-documentation", 
            "text": "Our documentation is hosted and deployed through GitHub. This guide will take you step by step through the process of getting the documentation on to your local machine, editing the documentation, and submitting your changes. If you ve never worked with Git before, it might seem a little intimidating, but we ve broken it down for you into manageable chunks.  Briefly, the process is as follows:   First, you will get the documentation source code, using Git.  Then, you will work on the documentation. You will use Mkdocs and Markdown to write the documentation.  Then, you will push your changes to GitHub.  Finally, you will deploy the documentation. This is done using a simple Mkdocs commands that builds the documentation and deploys it to GitHub pages.", 
            "title": "How to obtain, write, and deploy documentation"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#install-and-set-up-git", 
            "text": "If you don t already have Git installed, you ll want to get that set up first. You ll have to  download and install Git . You can read more about Git on  their website .  You will also have to  create a GitHub account , which is a very straightforward process.  After installing Git, the first thing you should do is setup your name and email using the following commands:  git config --global user.name  Your Real Name \ngit config --global user.email  you@email.com   Note that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.", 
            "title": "Install and set up Git"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#install-mkdocs", 
            "text": "The Coral Project s documentation uses the  MkDocs  documentation system, which uses  Markdown  to format text. Before you can get started on writing and editing the documentation, you will need to have MkDocs installed.  You can  download and install MkDocs  using the instructions on their website. The  MkDocs website  also contains a lot of good information on writing documentation in MkDocs, and there are plenty of decent Markdown cheatsheets floating around,  like this one .", 
            "title": "Install MkDocs"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#getting-the-documentation", 
            "text": "All of the documentation for the Coral Project  resides in GitHub  in the  docs  repository.  To get a local version of the documentation, clone the repository using this command:  git clone https://github.com/coralproject/docs.git  You now have a local copy of the documentation on your local machine, that you can modify and add to.  Note : If you already have a local copy of the documentation repository on your computer, be sure to perform a  git pull  before you start editing. This will ensure that you are working on the most recent available version of the documentation, which will prevent potential merge conflicts when you re ready to commit your changes.", 
            "title": "Getting the documentation"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#writing-and-editing-the-documentation", 
            "text": "As you are writing the documentation, refer to the  Documentation Style Guide  to make sure you are remaining consistent with our current documentation standards, and writing the best and clearest documentation possible.", 
            "title": "Writing and editing the documentation"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#commit-your-changes", 
            "text": "Once you ve finished your edits, it s time to commit your changes back up to the remote repository on GitHub.  First, you ll add your changes, where  filename  is the name of the file or files that you have changed.  git add  filename   Then, you ll commit your changes. Be sure to add a commit message (the portion within the single quotations) to let everyone know what it is that you ve changed. The  -m  flag is what tells Git that you re adding a commit message.  git commit -m 'Updated the Ask tutorial'  Finally, push your changes up to the remote repository:  git push origin master", 
            "title": "Commit your changes"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#deploy-the-documentation", 
            "text": "Now that the documentation has been updated and committed to the repository, you can deploy the documentation. The documentation is hosted on Heroku, so in order to deploy it, we need to first build the files that make up the site, and then push those files up to Heroku.  First ensure that you have the latest version of the documentation on your local machine:  git pull  Then, run the following command:  mkdocs build --clean  The  build  command builds the documentation, creating the HTML pages that make up the site, and places those files in the  site  directory.  Now you ll push the  site  directory, containing the pages that make up the website, to Heroku. You can do this with the following command:  git subtree push --prefix site heroku master", 
            "title": "Deploy the documentation"
        }, 
        {
            "location": "/contribute/documentation/writing_documentation/#translating-documentation", 
            "text": "To come.", 
            "title": "Translating documentation"
        }, 
        {
            "location": "/contribute/documentation/style_guide/", 
            "text": "Documentation style guide\n\n\nThe key thing to remember when writing documentation is to be extremely explicit and detailed. Do not assume knowledge!\n\n\nWriting style\n\n\n\n\nWhen in doubt about a grammatical or syntactical point, refer to the \nAssociated Press\ns (AP) Style Guide\n.\n\n\nThough we value good style, please don\u2019t get too hung up on using correct style. We\u2019d rather have you submit good information that doesn\u2019t conform to the guide than no information at all.\n\n\nIn general, try to write simple, declarative prose. We prefer short, single-clause sentences and brief three-to-five sentence paragraphs. Try to choose vocabulary that is straightforward and precise.\n\n\nPronouns\n:\n\n\nUse gender-neutral pronouns (they/their/them) rather than \nhe or she\n.\n\n\nFirst and second person pronouns are fine. Always use \u201cwe\u201d to refer to Coral and \u201cyou\u201d to refer to the user.\n\n\n\n\n\n\nAvoid excessive use of \ni.e.\n.\n\n\nSection headers and page headers should follow sentence case formatting (first word capitalized, following words uncapitalized) rather than title case (each word in the header capitalized).\n\n\nWhenever possible, include a section at the beginning of the page that describes what is contained within that page (with hyperlinks to the relevant sections). Sure, usually this will also appear on the Table of Contents in the side navigation section, but it\ns also useful to have it displayed within the text itself.\n\n\n\n\nDo not assume knowledge\n\n\n\n\nDon\nt be afraid to explain something that might seem very basic or self-explanatory to you; it may not be so basic to someone else.\n\n\nWhenever possible, include an actual, specific instruction and (if required) command.\n\n\nBad: \nClone the repository to your machine.\n\n\nGood: \nClone the docs repository to your local machine, using the command \ngit clone https://github.com/coralproject/docs.git\n\n\n\n\n\n\nIf there are command line instructions involved, include the precise command line instruction. Instructions that users can copy/paste into the command line are great!\n\n\nShow \nexpected results\n wherever possible. If a command line instruction should return a certain result, show that expected result. If there is a URL you can visit to test whether or not something is working, provide that URL as a link.\n\n\nIf there are variables to configure, explicitly state the purpose of the variables. This should be explained in a comment in the configuration file, but you should also provide an explanation in your instructions.\n\n\nDo not merely explain HOW to do something, but also, whenever possible, WHY you are doing it in that way. This makes it easier for users to troubleshoot issues.\n\n\n\n\nThird-party components\n\n\nIs there a third-party component the user needs to set up (for instance, MongoDB)?\n\n\n\n\nYou don\nt have to include all setup instructions, but do link to the setup instructions on the website of the third-party app in question (hopefully the third-party app is well-documented; if not, you may have to fill in the gaps).\n\n\nBe sure to detail any specific instructions they will need to integrate this third-party component into the system.\n\n\nCurrently, much of this \nthird party setup\n information resides in the \nDeveloper Setup\n document. This reduces duplication if there is a component that needs to be set up for multiple items.\n\n\n\n\nWriting installation instructions\n\n\n\n\nBe sure to include \nevery single step\n.\n\n\nInclude screenshots when it makes sense to do so.\n\n\nIf there are command line instructions, include the exact instruction in a code block so that users can copy/paste.\n\n\n\n\nWriting API documentation\n\n\nWhen documenting a REST-style API, such as the \nPillar API\n, there are certain pieces of information to include. The \nPillar API documentation\n is a useful template.\n\n\n\n\nCreate an initial table that lists endpoints, which contains:\n\n\nThe endpoint URL.\n\n\nThe HTTP verb for that endpoint (GET, POST).\n\n\nThe basic functionality description for that endpoint. Make this into a targeted link that jumps to the full description for that endpoint.\n\n\n\n\n\n\nCreate a full description for each endpoint. You can see the \nGet Users\n Pillar endpoint for an example). Each description should include:\n\n\nThe parameters for the endpoint (include the parameter name, whether it is required or optional, the type, and the description).\n\n\nAn example call.\n\n\nThe response for the example call (whether that is a JSON object, or simply a status response).\n\n\n\n\n\n\n\n\nUser Guide documentation\n\n\nWhen documenting \nUser Guides\n, it is important to remember that the people reading them may not have in-depth technical knowledge. Keep your audience in mind.\n\n\nWriting User Guide tutorials\n\n\n\n\nTutorials take the reader by the hand through a series of steps to create or achieve something.\n\n\nTutorials should be \nresults oriented\n: by the end of the tutorial, the user will have achieved something.\n\n\nThe important thing in a tutorial is to help the reader achieve something useful, preferably as early as possible, in order to give them confidence.\n\n\nExplain the nature of the problem we\u2019re solving, so that the reader understands what we\u2019re trying to achieve. Don\u2019t feel that you need to begin with explanations of how things work - what matters is what the reader does, not what you explain. It can be helpful to refer back to what you\u2019ve done and explain afterwards.\n\n\n\n\nStructure\n\n\n\n\nThe tutorials for each product are all contained on a single page. View the \nTrust tutorial page\n for an example.\n\n\nAt the top of the tutorial page is a list of the tutorials available on that page. Each has a description in the form of a user story (i.e., \nI would like to\n).\n\n\nA tutorial is not a general overview of the functionality of the product, but a specific how-to that fulfills a user story. The general overview of the product\ns functionality belows on the Overview page for that product.\n\n\nThe goal of a tutorial is to walk the user through a scenario (such as \nidentify trolls within the Business section\n), that they can then tailor to their own needs (\nidentify trolls within the Health section\n).\n\n\n\n\nFormat\n\n\n\n\nTutorials follow a numbered step-by-step format.\n\n\nYou do not have to use the Markdown \nnumbered list\n formatting (in which the numbered list is written \n1.\n for auto-formatting). In fact, it is probably better if you don\nt: things get a bit wonky when you start inserting images in between the numbered steps.\n\n\n\n\n\n\n\n\nImages\n\n\n\n\nEach step (or very nearly each step) should have an image illustrating that step, and potentially showing the location of a button or field. If you do not have an image illustrating that step, you should have a pretty good reason not to have it.\n\n\n\n\nTerminology\n\n\n\n\nGit is capitalized.\n\n\nGitHub capitalizes both the G and the H.\n\n\n\n\nHere are some commonly used terms:\n\n\nSoftware specific\n\n\n\n\nCoral\n: Refers to the Coral product, which includes the three components Trust, Ask, and Talk.\n\n\nCoral Project\n: Refers to the project of building and crafting the Coral product.\n\n\nCoral Ecosystem\n: Refers to all of the pieces that make up Coral from a more technical or development perspective: includes all the technical components such as Pillar, Sponge, and Cay.\n\n\n\n\nUsers\n\n\n\n\nDevelopers\n: Refers to the technical users of Coral who will be installing Coral and working with the backend. Also refers to open-source contributors.\n\n\nEnd Users\n: Refers to anyone who will be interacting with the Coral front end. Examples of end users are publishers, moderators, journalists, and readers.\n\n\n\n\nMarkup specific style\n\n\nGraphics\n\n\nWhen you need to add a graphic, try to make the file-size as small as possible. If you need help reducing file-size of a high-resolution image, feel free to contact us for help. Usually, graphics should go in the same directory as the .md file that references them, or in a subdirectory for images if one already exists.\n\n\nThe preferred file format for graphics is PNG, but GIF and JPG are also acceptable.\n\n\nIf you are referring to a specific part of the UI in an image, use call-outs (circles and arrows or lines) to highlight what you\u2019re referring to. Line width for call-outs should not exceed five pixels. The preferred color for call-outs is red.\n\n\nBe sure to include descriptive alt-text for the graphic. This greatly helps users with accessibility issues.\n\n\n\n\nThe color used for highlighting rectangles and arrows is Hex Color #00C7FC. This offers a good contrast with the Coral theme colors.\n\n\nWhen taking screenshots to use as illustrative images, include a decent amount of \nsurrounding area\n to provide context and geography for the feature you\nre discussing. A screenshot of a button, for instance, isn\nt very useful when you can\nt figure out where the button is located.\n\n\n\n\nCommands and code blocks\n\n\n\n\nEnclose commands and code blocks in triple-tick blocks (```). Yes, Markdown supports indentation to delineate code blocks, but the triple-ticks make things more explicit.\n\n\nBe sure you are using universal command line commands, not shortcuts available in some shells.\n\n\nGood: \nmkdir exampledirectory\n\n\nBad: \nmd exampledirectory\n\n\n\n\n\n\n\n\nHeaders\n\n\n\n\nWhen adding headlines and section dividers, keep in mind that the Table of Contents displayed in the side navigation bar to the left is only two levels deep. So, H1 (#) and H2 (##) text will show up in the Table of Contents. H3 (###) and below will not.\n\n\nTo avoid making the Table of Contents too cluttered, try to only use H2 (##) for key large sections.", 
            "title": "Documentation style guide"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#documentation-style-guide", 
            "text": "The key thing to remember when writing documentation is to be extremely explicit and detailed. Do not assume knowledge!", 
            "title": "Documentation style guide"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#writing-style", 
            "text": "When in doubt about a grammatical or syntactical point, refer to the  Associated Press s (AP) Style Guide .  Though we value good style, please don\u2019t get too hung up on using correct style. We\u2019d rather have you submit good information that doesn\u2019t conform to the guide than no information at all.  In general, try to write simple, declarative prose. We prefer short, single-clause sentences and brief three-to-five sentence paragraphs. Try to choose vocabulary that is straightforward and precise.  Pronouns :  Use gender-neutral pronouns (they/their/them) rather than  he or she .  First and second person pronouns are fine. Always use \u201cwe\u201d to refer to Coral and \u201cyou\u201d to refer to the user.    Avoid excessive use of  i.e. .  Section headers and page headers should follow sentence case formatting (first word capitalized, following words uncapitalized) rather than title case (each word in the header capitalized).  Whenever possible, include a section at the beginning of the page that describes what is contained within that page (with hyperlinks to the relevant sections). Sure, usually this will also appear on the Table of Contents in the side navigation section, but it s also useful to have it displayed within the text itself.", 
            "title": "Writing style"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#do-not-assume-knowledge", 
            "text": "Don t be afraid to explain something that might seem very basic or self-explanatory to you; it may not be so basic to someone else.  Whenever possible, include an actual, specific instruction and (if required) command.  Bad:  Clone the repository to your machine.  Good:  Clone the docs repository to your local machine, using the command  git clone https://github.com/coralproject/docs.git    If there are command line instructions involved, include the precise command line instruction. Instructions that users can copy/paste into the command line are great!  Show  expected results  wherever possible. If a command line instruction should return a certain result, show that expected result. If there is a URL you can visit to test whether or not something is working, provide that URL as a link.  If there are variables to configure, explicitly state the purpose of the variables. This should be explained in a comment in the configuration file, but you should also provide an explanation in your instructions.  Do not merely explain HOW to do something, but also, whenever possible, WHY you are doing it in that way. This makes it easier for users to troubleshoot issues.", 
            "title": "Do not assume knowledge"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#third-party-components", 
            "text": "Is there a third-party component the user needs to set up (for instance, MongoDB)?   You don t have to include all setup instructions, but do link to the setup instructions on the website of the third-party app in question (hopefully the third-party app is well-documented; if not, you may have to fill in the gaps).  Be sure to detail any specific instructions they will need to integrate this third-party component into the system.  Currently, much of this  third party setup  information resides in the  Developer Setup  document. This reduces duplication if there is a component that needs to be set up for multiple items.", 
            "title": "Third-party components"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#writing-installation-instructions", 
            "text": "Be sure to include  every single step .  Include screenshots when it makes sense to do so.  If there are command line instructions, include the exact instruction in a code block so that users can copy/paste.", 
            "title": "Writing installation instructions"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#writing-api-documentation", 
            "text": "When documenting a REST-style API, such as the  Pillar API , there are certain pieces of information to include. The  Pillar API documentation  is a useful template.   Create an initial table that lists endpoints, which contains:  The endpoint URL.  The HTTP verb for that endpoint (GET, POST).  The basic functionality description for that endpoint. Make this into a targeted link that jumps to the full description for that endpoint.    Create a full description for each endpoint. You can see the  Get Users  Pillar endpoint for an example). Each description should include:  The parameters for the endpoint (include the parameter name, whether it is required or optional, the type, and the description).  An example call.  The response for the example call (whether that is a JSON object, or simply a status response).", 
            "title": "Writing API documentation"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#user-guide-documentation", 
            "text": "When documenting  User Guides , it is important to remember that the people reading them may not have in-depth technical knowledge. Keep your audience in mind.", 
            "title": "User Guide documentation"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#writing-user-guide-tutorials", 
            "text": "Tutorials take the reader by the hand through a series of steps to create or achieve something.  Tutorials should be  results oriented : by the end of the tutorial, the user will have achieved something.  The important thing in a tutorial is to help the reader achieve something useful, preferably as early as possible, in order to give them confidence.  Explain the nature of the problem we\u2019re solving, so that the reader understands what we\u2019re trying to achieve. Don\u2019t feel that you need to begin with explanations of how things work - what matters is what the reader does, not what you explain. It can be helpful to refer back to what you\u2019ve done and explain afterwards.", 
            "title": "Writing User Guide tutorials"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#structure", 
            "text": "The tutorials for each product are all contained on a single page. View the  Trust tutorial page  for an example.  At the top of the tutorial page is a list of the tutorials available on that page. Each has a description in the form of a user story (i.e.,  I would like to ).  A tutorial is not a general overview of the functionality of the product, but a specific how-to that fulfills a user story. The general overview of the product s functionality belows on the Overview page for that product.  The goal of a tutorial is to walk the user through a scenario (such as  identify trolls within the Business section ), that they can then tailor to their own needs ( identify trolls within the Health section ).", 
            "title": "Structure"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#format", 
            "text": "Tutorials follow a numbered step-by-step format.  You do not have to use the Markdown  numbered list  formatting (in which the numbered list is written  1.  for auto-formatting). In fact, it is probably better if you don t: things get a bit wonky when you start inserting images in between the numbered steps.", 
            "title": "Format"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#images", 
            "text": "Each step (or very nearly each step) should have an image illustrating that step, and potentially showing the location of a button or field. If you do not have an image illustrating that step, you should have a pretty good reason not to have it.", 
            "title": "Images"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#terminology", 
            "text": "Git is capitalized.  GitHub capitalizes both the G and the H.   Here are some commonly used terms:", 
            "title": "Terminology"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#software-specific", 
            "text": "Coral : Refers to the Coral product, which includes the three components Trust, Ask, and Talk.  Coral Project : Refers to the project of building and crafting the Coral product.  Coral Ecosystem : Refers to all of the pieces that make up Coral from a more technical or development perspective: includes all the technical components such as Pillar, Sponge, and Cay.", 
            "title": "Software specific"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#users", 
            "text": "Developers : Refers to the technical users of Coral who will be installing Coral and working with the backend. Also refers to open-source contributors.  End Users : Refers to anyone who will be interacting with the Coral front end. Examples of end users are publishers, moderators, journalists, and readers.", 
            "title": "Users"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#markup-specific-style", 
            "text": "", 
            "title": "Markup specific style"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#graphics", 
            "text": "When you need to add a graphic, try to make the file-size as small as possible. If you need help reducing file-size of a high-resolution image, feel free to contact us for help. Usually, graphics should go in the same directory as the .md file that references them, or in a subdirectory for images if one already exists.  The preferred file format for graphics is PNG, but GIF and JPG are also acceptable.  If you are referring to a specific part of the UI in an image, use call-outs (circles and arrows or lines) to highlight what you\u2019re referring to. Line width for call-outs should not exceed five pixels. The preferred color for call-outs is red.  Be sure to include descriptive alt-text for the graphic. This greatly helps users with accessibility issues.   The color used for highlighting rectangles and arrows is Hex Color #00C7FC. This offers a good contrast with the Coral theme colors.  When taking screenshots to use as illustrative images, include a decent amount of  surrounding area  to provide context and geography for the feature you re discussing. A screenshot of a button, for instance, isn t very useful when you can t figure out where the button is located.", 
            "title": "Graphics"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#commands-and-code-blocks", 
            "text": "Enclose commands and code blocks in triple-tick blocks (```). Yes, Markdown supports indentation to delineate code blocks, but the triple-ticks make things more explicit.  Be sure you are using universal command line commands, not shortcuts available in some shells.  Good:  mkdir exampledirectory  Bad:  md exampledirectory", 
            "title": "Commands and code blocks"
        }, 
        {
            "location": "/contribute/documentation/style_guide/#headers", 
            "text": "When adding headlines and section dividers, keep in mind that the Table of Contents displayed in the side navigation bar to the left is only two levels deep. So, H1 (#) and H2 (##) text will show up in the Table of Contents. H3 (###) and below will not.  To avoid making the Table of Contents too cluttered, try to only use H2 (##) for key large sections.", 
            "title": "Headers"
        }, 
        {
            "location": "/contribute/reporting_bugs/", 
            "text": "Reporting bugs and requesting features\n\n\nBefore reporting a bug or requesting a new feature, please consider these general points:\n\n\n\n\nCheck that someone hasn\u2019t already filed the bug or feature request by searching the \nIssues\n for the repo in question.\n\n\nDon\u2019t reopen issues that have been marked \u201cwontfix\u201d by a core developer. This mark means that the decision has been made that we can\u2019t or won\u2019t fix this particular issue.\n\n\n\n\nReporting bugs\n\n\nWe use GitHub Issues to track bugs. Each Coral component app has its own repository, but since it may not be clear precisely which component the bug is originating from, we use the Reef repository to track bugs.\n\n\nComplete, reproducible, specific bug reports are very helpful. When writing a bug report, be sure to include the following:\n\n\n\n\nA clear, concise description of the problem.\n\n\nA set of instructions for replicating it.\n\n\n\n\nAdd as much additional debug information as you can, such as: code snippets, test cases, exception backtraces, screenshots, etc. A nice small test case is the best way to report a bug, as it gives us an easy way to confirm the bug quickly.\n\n\nReporting user interface bugs and features\n\n\nIf your bug or feature request touches on anything visual in nature, there are a few additional guidelines to follow:\n\n\n\n\nInclude screenshots in your ticket which are the visual equivalent of a minimal testcase.\n\n\nIf the issue is difficult to show off using a still image, consider capturing a brief screencast. If possible, capture only the relevant area of the screen.\n\n\n\n\nRequesting features\n\n\nHere are some tips on how to make a request most effectively:\n\n\n\n\nDescribe clearly and concisely what the missing feature is and how you\u2019d like to see it implemented. Include example code (non-functional is OK) if possible.\n\n\nExplain why you\u2019d like the feature. In some cases this is obvious, but an explanation can help determine why and how the feature will be useful.", 
            "title": "Reporting bugs and requesting features"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-bugs-and-requesting-features", 
            "text": "Before reporting a bug or requesting a new feature, please consider these general points:   Check that someone hasn\u2019t already filed the bug or feature request by searching the  Issues  for the repo in question.  Don\u2019t reopen issues that have been marked \u201cwontfix\u201d by a core developer. This mark means that the decision has been made that we can\u2019t or won\u2019t fix this particular issue.", 
            "title": "Reporting bugs and requesting features"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-bugs", 
            "text": "We use GitHub Issues to track bugs. Each Coral component app has its own repository, but since it may not be clear precisely which component the bug is originating from, we use the Reef repository to track bugs.  Complete, reproducible, specific bug reports are very helpful. When writing a bug report, be sure to include the following:   A clear, concise description of the problem.  A set of instructions for replicating it.   Add as much additional debug information as you can, such as: code snippets, test cases, exception backtraces, screenshots, etc. A nice small test case is the best way to report a bug, as it gives us an easy way to confirm the bug quickly.", 
            "title": "Reporting bugs"
        }, 
        {
            "location": "/contribute/reporting_bugs/#reporting-user-interface-bugs-and-features", 
            "text": "If your bug or feature request touches on anything visual in nature, there are a few additional guidelines to follow:   Include screenshots in your ticket which are the visual equivalent of a minimal testcase.  If the issue is difficult to show off using a still image, consider capturing a brief screencast. If possible, capture only the relevant area of the screen.", 
            "title": "Reporting user interface bugs and features"
        }, 
        {
            "location": "/contribute/reporting_bugs/#requesting-features", 
            "text": "Here are some tips on how to make a request most effectively:   Describe clearly and concisely what the missing feature is and how you\u2019d like to see it implemented. Include example code (non-functional is OK) if possible.  Explain why you\u2019d like the feature. In some cases this is obvious, but an explanation can help determine why and how the feature will be useful.", 
            "title": "Requesting features"
        }, 
        {
            "location": "/contribute/development/writing_code/", 
            "text": "Writing Code\n\n\nSo you\u2019d like to write some code to improve the Coral Project? Great!\n\n\n\n\nBug fixing\n\n\nNew features\n\n\nPlugins\n\n\n\n\nBefore you begin\n\n\nBefore writing any code with the intention of merging into master, ensure the work you\nre doing has an GitHub issue and try in good faith to engage the community in conversation in the issue feed. Here is a checklist to follow before starting:\n\n\n\n\nCheck the FAQ to see if your issue has already been addressed.\n\n\nCheck the GitHub issues to see if an issue already exists for the work you want to do, and to make sure that there isn\nt already someone working on it.\n\n\nIf there isn\nt already someone working on it, then leave a comment to let everyone know that you are starting work on it.\n\n\nIf someone is already working on it, consider collaborating with them.\n\n\n\n\n\n\nIf no issue exists, then create an issue for it before getting started. You can find more information on writing a detailed issue \nhere\n.\n\n\n\n\n\n\nWriting code\n\n\nOnce you\nve followed the checklist above, browse the following sections to find out how to give your code the best chance of being included in the Coral Project.\n\n\n\n\nCoding style\n\n\nWorking with Git and GitHub", 
            "title": "Writing code"
        }, 
        {
            "location": "/contribute/development/writing_code/#writing-code", 
            "text": "So you\u2019d like to write some code to improve the Coral Project? Great!   Bug fixing  New features  Plugins", 
            "title": "Writing Code"
        }, 
        {
            "location": "/contribute/development/writing_code/#before-you-begin", 
            "text": "Before writing any code with the intention of merging into master, ensure the work you re doing has an GitHub issue and try in good faith to engage the community in conversation in the issue feed. Here is a checklist to follow before starting:   Check the FAQ to see if your issue has already been addressed.  Check the GitHub issues to see if an issue already exists for the work you want to do, and to make sure that there isn t already someone working on it.  If there isn t already someone working on it, then leave a comment to let everyone know that you are starting work on it.  If someone is already working on it, consider collaborating with them.    If no issue exists, then create an issue for it before getting started. You can find more information on writing a detailed issue  here .", 
            "title": "Before you begin"
        }, 
        {
            "location": "/contribute/development/writing_code/#writing-code_1", 
            "text": "Once you ve followed the checklist above, browse the following sections to find out how to give your code the best chance of being included in the Coral Project.   Coding style  Working with Git and GitHub", 
            "title": "Writing code"
        }, 
        {
            "location": "/contribute/development/working_with_github/", 
            "text": "Working With GitHub\n\n\nThis section explains how open source contributors can contribute code to the Coral Project via pull requests.\n\n\nFor a general primer on contributing to open source projects, GitHub has created \na nice guide to contributing to open source\n.\n\n\nThe fundamentals (which are expanded on below) are:\n\n\n\n\nFork the project \n clone locally.\n\n\nCreate an upstream remote and sync your local copy before you branch.\n\n\nBranch for each separate piece of work.\n\n\nDo the work, and write good commit messages.\n\n\nPush to your origin repository.\n\n\nCreate a new PR in GitHub.\n\n\nRespond to any code review feedback.\n\n\n\n\nInstalling Git\n\n\nFirst, \ndownload and install Git\n. You can read more about Git on \ntheir website\n.\n\n\nAfter installing Git, the first thing you should do is setup your name and email:\n\n\ngit config --global user.name \nYour Real Name\n\ngit config --global user.email \nyou@email.com\n\n\n\n\n\nNote that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.\n\n\nSetting up local repository\n\n\nFirst, you need to fork the project: navigate to to the repo in GitHub you want to contribute to and press the \nFork\n button. This will create a copy of the repository in your own GitHub account and you\nll see a note that it\ns been forked underneath the project name.\n\n\nNow create a local copy of that fork (in this example, the \ndocs\n repository is the one being cloned):\n\n\ngit clone https://github.com/coralproject/docs.git\n\n\n\n\nThis will create a new directory \ndocs\n, containing a clone of your forked GitHub repository. Switch to the project\ns new directory:\n\n\ncd docs\n\n\n\n\nYou will now need to setup coralproject/docs as an \nupstream\n remote. This connects your local repository to the original \nupstream\n source repository (essentially, telling Git that the original reference repository is the source of your local forked copy).\n\n\ngit remote add upstream https://github.com/coralproject/docs.git\ngit fetch upstream\n\n\n\n\nIt\ns a good idea to regularly pull in changes from \nupstream\n so that when you submit your pull request, merge conflicts will be less likely. You can find more detailed instructions on \nsyncing a fork from GitHub\n.    \n\n\nWork on an issue\n\n\nWhen working on an issue, create a new branch for the work. Name the branch for the issue you are working on, capitalizing the word \nIssue\n (for example, \nIssue#82\n).\n\n\ngit checkout master\ngit pull upstream master \n git push origin master\ngit checkout -b Issue#82\n\n\n\n\nWhat this does: First, we ensure we\nre on the master branch. Then, the git pull command will sync our local copy with the upstream project and the git push syncs it to our forked GitHub project. Finally, we create our new branch.\n\n\nNow you can start coding! Ensure that you only fix the thing you\nre working on (don\nt get sidetracked into fixing other little things you see along the way).\n\n\nCommitting\n\n\nWhen committing, be sure to commit in logical blocks and add meaningful commit messages.\n\n\ngit commit -m 'Added instructions for commit messages'\n\n\n\n\nSome guidelines to follow:\n\n\n\n\nNever force-push your changes.\n\n\nWrite your commit messages in the past tense, not present tense.\n\n\nGood: \nAdded instructions for commit messages\n\n\nBad: \nAdd instructions for commit messages\n\n\n\n\n\n\nFor commits to a branch, prefix the commit message with the branch name. For example: \u201cIssue#82 Added instructions for commit messages.\u201d\n\n\n\n\nCreate the pull request\n\n\nTo create a PR you first need to push your branch to the origin remote.\n\n\nTo push a new branch:\n\n\ngit push origin Issue#82\n\n\n\n\nWhen you go to your GitHub page, you will notice that a new branch has been created, along with a button that says \nCompare and Pull Request.\n When you feel ready to create a pull request, go ahead and push the button.\n\n\nOn the \nOpen a pull request\n page, ensure that the \nbase fork\n points to the correct repository and branch. Then ensure that you provide a good, succinct title for your pull request and explain why you have created it in the description box.\n\n\nScroll down to see the diff of your changes. Double check that it contains what you expect.\n\n\nOnce you are happy, press the \nCreate pull request\n button.\n\n\nReview by the maintainers\n\n\nOnce you\nve created your pull request, recruit a code reviewer to take a look.\n\n\nThe reviewer will review and potentially offer suggestions. If that happens, make the suggested changes, commit, and push your changes. You may go through several cycles of reviews, changes, and updates.\n\n\nOnce both of you agree that the code is done, it\ns time to merge.\n\n\nMerging\n\n\nThe code reviewer will merge the pull request. If conflicts emerge, TODO.\n\n\nTODO: Add information about tagging.\n\n\nOnce the merge is complete, the branch can be deleted.\n\n!\n\n\nExceptions\n\n\n\n\nUpdates to documentation may be merged directly into master (instead of going through a branch).\n\n\nSmall bugs or tweaks caught by the maintainer post-merge may be merged directly into master.\n\n\nThese commits should include the issue number in the commit message for reference.", 
            "title": "Development workflow"
        }, 
        {
            "location": "/contribute/development/working_with_github/#working-with-github", 
            "text": "This section explains how open source contributors can contribute code to the Coral Project via pull requests.  For a general primer on contributing to open source projects, GitHub has created  a nice guide to contributing to open source .  The fundamentals (which are expanded on below) are:   Fork the project   clone locally.  Create an upstream remote and sync your local copy before you branch.  Branch for each separate piece of work.  Do the work, and write good commit messages.  Push to your origin repository.  Create a new PR in GitHub.  Respond to any code review feedback.", 
            "title": "Working With GitHub"
        }, 
        {
            "location": "/contribute/development/working_with_github/#installing-git", 
            "text": "First,  download and install Git . You can read more about Git on  their website .  After installing Git, the first thing you should do is setup your name and email:  git config --global user.name  Your Real Name \ngit config --global user.email  you@email.com   Note that user.name should be your real name, not your GitHub username. The email you use in the user.email field will be used to associate your commits with your GitHub account.", 
            "title": "Installing Git"
        }, 
        {
            "location": "/contribute/development/working_with_github/#setting-up-local-repository", 
            "text": "First, you need to fork the project: navigate to to the repo in GitHub you want to contribute to and press the  Fork  button. This will create a copy of the repository in your own GitHub account and you ll see a note that it s been forked underneath the project name.  Now create a local copy of that fork (in this example, the  docs  repository is the one being cloned):  git clone https://github.com/coralproject/docs.git  This will create a new directory  docs , containing a clone of your forked GitHub repository. Switch to the project s new directory:  cd docs  You will now need to setup coralproject/docs as an  upstream  remote. This connects your local repository to the original  upstream  source repository (essentially, telling Git that the original reference repository is the source of your local forked copy).  git remote add upstream https://github.com/coralproject/docs.git\ngit fetch upstream  It s a good idea to regularly pull in changes from  upstream  so that when you submit your pull request, merge conflicts will be less likely. You can find more detailed instructions on  syncing a fork from GitHub .", 
            "title": "Setting up local repository"
        }, 
        {
            "location": "/contribute/development/working_with_github/#work-on-an-issue", 
            "text": "When working on an issue, create a new branch for the work. Name the branch for the issue you are working on, capitalizing the word  Issue  (for example,  Issue#82 ).  git checkout master\ngit pull upstream master   git push origin master\ngit checkout -b Issue#82  What this does: First, we ensure we re on the master branch. Then, the git pull command will sync our local copy with the upstream project and the git push syncs it to our forked GitHub project. Finally, we create our new branch.  Now you can start coding! Ensure that you only fix the thing you re working on (don t get sidetracked into fixing other little things you see along the way).", 
            "title": "Work on an issue"
        }, 
        {
            "location": "/contribute/development/working_with_github/#committing", 
            "text": "When committing, be sure to commit in logical blocks and add meaningful commit messages.  git commit -m 'Added instructions for commit messages'  Some guidelines to follow:   Never force-push your changes.  Write your commit messages in the past tense, not present tense.  Good:  Added instructions for commit messages  Bad:  Add instructions for commit messages    For commits to a branch, prefix the commit message with the branch name. For example: \u201cIssue#82 Added instructions for commit messages.\u201d", 
            "title": "Committing"
        }, 
        {
            "location": "/contribute/development/working_with_github/#create-the-pull-request", 
            "text": "To create a PR you first need to push your branch to the origin remote.  To push a new branch:  git push origin Issue#82  When you go to your GitHub page, you will notice that a new branch has been created, along with a button that says  Compare and Pull Request.  When you feel ready to create a pull request, go ahead and push the button.  On the  Open a pull request  page, ensure that the  base fork  points to the correct repository and branch. Then ensure that you provide a good, succinct title for your pull request and explain why you have created it in the description box.  Scroll down to see the diff of your changes. Double check that it contains what you expect.  Once you are happy, press the  Create pull request  button.", 
            "title": "Create the pull request"
        }, 
        {
            "location": "/contribute/development/working_with_github/#review-by-the-maintainers", 
            "text": "Once you ve created your pull request, recruit a code reviewer to take a look.  The reviewer will review and potentially offer suggestions. If that happens, make the suggested changes, commit, and push your changes. You may go through several cycles of reviews, changes, and updates.  Once both of you agree that the code is done, it s time to merge.", 
            "title": "Review by the maintainers"
        }, 
        {
            "location": "/contribute/development/working_with_github/#merging", 
            "text": "The code reviewer will merge the pull request. If conflicts emerge, TODO.  TODO: Add information about tagging.  Once the merge is complete, the branch can be deleted. !", 
            "title": "Merging"
        }, 
        {
            "location": "/contribute/development/working_with_github/#exceptions", 
            "text": "Updates to documentation may be merged directly into master (instead of going through a branch).  Small bugs or tweaks caught by the maintainer post-merge may be merged directly into master.  These commits should include the issue number in the commit message for reference.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/contribute/development/style_guide/", 
            "text": "Coding style guide\n\n\nIf you are planning to contribute to the Coral code base, you should familiarize yourself with our coding standards. This helps to avoid common errors, improves code readability, and ensures that your PRs have a better chance of getting accepted and merged.\n\n\nThe coding style guide consists of the following sections:\n\n\n\n\nCore code principles\n\n\nWorking with repositories (naming, describing, etc.)\n\n\nWorking with Git (creating good commit messages)\n\n\nGo coding style\n\n\nNode.js / Javascript coding style\n\n\nAdditional resources\n\n\n\n\nCore code principles\n\n\nThese are the four basic principles that guide how we shape and build our code. All Coral Project software is conceived from the ground up to be:\n\n\n\n\nConfigurable\n: We strive to use configuration to deliver as much business logic, data modeling, and other aspects of our systems as \nis practical.\n Doing so gives us the ability to quickly configure precise UI experiences, data structures, and data science analysis with minimal need for coding, upgrades, server work, etc. Ultimately, we want the community managers who run our software to feel like they are designing their own house. This means trying things to see how they feel, looking at the results, and quickly making changes based on what they learn. We take our inspiration from the ever-changing, adaptable ecosystems of coral reefs.\n\n\nModular\n: Coral products can be used together to form a fully functioning community platform, or be used in pieces to complement existing software. In order to accomplish this, we are building core API features, message passing and import/export strategies in everything we do. We are also refining, documenting, and publishing deployment strategies for each of our products both in isolation as well as together as groups of our products configured to work in concert.\n\n\nPrivacy Minded\n: There is an implicit act of trust involved in registration for and engagement in an online community. Maintaining that trust is a top priority for us. Privacy for us begins with security concerns, and stretches deep into our product thinking. Whenever information is entered into our systems, we want to make it clear who will be able to see that information and how it will be used. We want to build safe, comfortable places that allow for conversations of varying levels of exposure, without false expectations or nasty surprises.\n\n\nSecure, Stable and Scalable\n: Our deployment recommendations, if followed, provide usable and secure environments. Each piece of our software has internal checks to catch any error states and trigger alarms, as well as external restart mechanisms. All of our platforms have proven records for stability and well-known upgrade paths. We will publish auto-scaling deployment workflows where appropriate for large sites with varying loads.\n\n\n\n\nWorking with repositories\n\n\nRepository naming\n\n\nAs you may have guessed, each component of Coral is named after a different type of coral. We like to match up some traits of the particular type of coral with the functionality of the component, but that\ns not always possible.\n\n\nChoose a variety of coral to name your repo. Make sure that there isn\nt already a repo named something similar.\n\n\nRepository descriptions\n\n\nThe description of a repo tells the public what is contained in the repo itself. If you have multiple repositories for the same project, it\ns better to describe what is contained in the repo itself instead of describing the project.\n\n\nRepo descriptions should be clear, concise, and descriptive. Descriptions are listed under each repository title on an organization\u2019s GitHub page. Anyone who scans the GitHub page should be able to determine what a repo does, just by looking at the description.\n\n\nIf your repo is not in active development, it\u2019s helpful to let users know this so they don\u2019t make contributions to a non-active repository. We suggest adding the word DEPRECATED before your repo description.\n\n\nGo coding style\n\n\nFor our Go code, we follow all coding guidelines laid out by the Go community, as detailed in their \nEffective Go\n guide. This helps us to maintain a consistent code base. We also use the \nGo Code Review Comments\n as a guide.\n\n\nAlthough not all of our code may comply 100% with the \nEffective Go\n guidelines, we\nre not looking for an overhaul of our code to make everything comply. Rather, all new contributions should comply with the guidelines. The ultimate goal is to make the code base easier for humans to navigate and understand.\n\n\nA few specific rules we follow\n\n\n\n\nAll code should be formatted with \ngofmt -s\n. (Read more about \ngofmt here\n.)\n\n\nAll code should pass the default levels of\n   \ngolint\n.\n\n\nComment the code. Tell us the why, the history and the context.\n\n\nDocument \nall\n declarations and methods, even private ones. Declare expectations, caveats and anything else that may be important. If a type gets exported, having the comments already there will ensure it\ns ready.\n\n\nThe length of a variable names should be proportional to its context, and preferably relatively short. In practice, short methods will have short variable names and globals will have longer names.\n\n\nBad: \nnoCommaALongVariableNameLikeThisIsNotMoreClearWhenASimpleCommentWouldDo\n.\n\n\n\n\n\n\nNo underscores in package names. If you need a compound name, step back, and re-examine why you need a compound name. If you still think you need a compound name, lose the underscore.\n\n\nNo utils or helper packages. If a function is not general enough to warrant its own package, it has not been written generally enough to be a part of a util package. Just leave it unexported and well-documented.\n\n\nAll tests should run with \ngo test\n and outside tooling should not be required. No, we don\nt need another unit testing framework. Assertion packages are acceptable if they provide \nreal\n incremental value.\n\n\nEven though we call these \nrules\n above, they are actually just guidelines. Since you\nve read all the rules, you now know that.\n\n\n\n\nUseful tools when developing in Go\n\n\n\n\ngolint\n: a linter for Go code.\n\n\ngofmt\n: a command that formats Go programs.\n\n\ngoimports\n: a command that updates your Go import lines.\n\n\nvet\n: a tool that examines Go code and reports suspicious constructs.\n\n\nerrcheck\n: a tool that checks for unchecked errors in Go programs.\n\n\n\n\nNode.js / Javascript coding style\n\n\nWe use the \nAirbnb React/JSX Style Guide\n when working with Javascript.\n\n\nCommenting\n\n\nCode commenting is crucial to maintaining a readable code base that future developers can understand and build upon. You can find a nice \nprimer on good commenting practice here\n.\n\n\n\n\nProvide the why, the history, and context.\n\n\nWhy: Why are you writing the code in exactly the way that you are?\n\n\nHistory: What historical decisions or factors went into writing the code in this way?\n\n\nContext: Are there any other factors we should know about that went into writing or developing this piece of code?\n\n\n\n\n\n\nDocument \nall\n declarations and methods, even private ones. Declare expectations, caveats and anything else that may be important. If a type gets exported, having the comments already there will ensure it\ns ready.\n\n\nKeep everything readable:\n Remember that the comments will be read by humans. Keep it simple, brief, and clear.\n\n\nWhitespace is important:\n\n\nComment while coding:\n\n\n\n\nResources\n\n\nSome further reading, particularly on the subject of Go:\n\n\n\n\nGo Code Review Comments\n\n\nBest Practices for Production Environments\n\n\n12 Factor App\n\n\nTools for working with Go Code\n\n\n\n\nAttribution: Go Coding Style adopted from the Docker project.", 
            "title": "Coding style guide"
        }, 
        {
            "location": "/contribute/development/style_guide/#coding-style-guide", 
            "text": "If you are planning to contribute to the Coral code base, you should familiarize yourself with our coding standards. This helps to avoid common errors, improves code readability, and ensures that your PRs have a better chance of getting accepted and merged.  The coding style guide consists of the following sections:   Core code principles  Working with repositories (naming, describing, etc.)  Working with Git (creating good commit messages)  Go coding style  Node.js / Javascript coding style  Additional resources", 
            "title": "Coding style guide"
        }, 
        {
            "location": "/contribute/development/style_guide/#core-code-principles", 
            "text": "These are the four basic principles that guide how we shape and build our code. All Coral Project software is conceived from the ground up to be:   Configurable : We strive to use configuration to deliver as much business logic, data modeling, and other aspects of our systems as  is practical.  Doing so gives us the ability to quickly configure precise UI experiences, data structures, and data science analysis with minimal need for coding, upgrades, server work, etc. Ultimately, we want the community managers who run our software to feel like they are designing their own house. This means trying things to see how they feel, looking at the results, and quickly making changes based on what they learn. We take our inspiration from the ever-changing, adaptable ecosystems of coral reefs.  Modular : Coral products can be used together to form a fully functioning community platform, or be used in pieces to complement existing software. In order to accomplish this, we are building core API features, message passing and import/export strategies in everything we do. We are also refining, documenting, and publishing deployment strategies for each of our products both in isolation as well as together as groups of our products configured to work in concert.  Privacy Minded : There is an implicit act of trust involved in registration for and engagement in an online community. Maintaining that trust is a top priority for us. Privacy for us begins with security concerns, and stretches deep into our product thinking. Whenever information is entered into our systems, we want to make it clear who will be able to see that information and how it will be used. We want to build safe, comfortable places that allow for conversations of varying levels of exposure, without false expectations or nasty surprises.  Secure, Stable and Scalable : Our deployment recommendations, if followed, provide usable and secure environments. Each piece of our software has internal checks to catch any error states and trigger alarms, as well as external restart mechanisms. All of our platforms have proven records for stability and well-known upgrade paths. We will publish auto-scaling deployment workflows where appropriate for large sites with varying loads.", 
            "title": "Core code principles"
        }, 
        {
            "location": "/contribute/development/style_guide/#working-with-repositories", 
            "text": "", 
            "title": "Working with repositories"
        }, 
        {
            "location": "/contribute/development/style_guide/#repository-naming", 
            "text": "As you may have guessed, each component of Coral is named after a different type of coral. We like to match up some traits of the particular type of coral with the functionality of the component, but that s not always possible.  Choose a variety of coral to name your repo. Make sure that there isn t already a repo named something similar.", 
            "title": "Repository naming"
        }, 
        {
            "location": "/contribute/development/style_guide/#repository-descriptions", 
            "text": "The description of a repo tells the public what is contained in the repo itself. If you have multiple repositories for the same project, it s better to describe what is contained in the repo itself instead of describing the project.  Repo descriptions should be clear, concise, and descriptive. Descriptions are listed under each repository title on an organization\u2019s GitHub page. Anyone who scans the GitHub page should be able to determine what a repo does, just by looking at the description.  If your repo is not in active development, it\u2019s helpful to let users know this so they don\u2019t make contributions to a non-active repository. We suggest adding the word DEPRECATED before your repo description.", 
            "title": "Repository descriptions"
        }, 
        {
            "location": "/contribute/development/style_guide/#go-coding-style", 
            "text": "For our Go code, we follow all coding guidelines laid out by the Go community, as detailed in their  Effective Go  guide. This helps us to maintain a consistent code base. We also use the  Go Code Review Comments  as a guide.  Although not all of our code may comply 100% with the  Effective Go  guidelines, we re not looking for an overhaul of our code to make everything comply. Rather, all new contributions should comply with the guidelines. The ultimate goal is to make the code base easier for humans to navigate and understand.", 
            "title": "Go coding style"
        }, 
        {
            "location": "/contribute/development/style_guide/#a-few-specific-rules-we-follow", 
            "text": "All code should be formatted with  gofmt -s . (Read more about  gofmt here .)  All code should pass the default levels of\n    golint .  Comment the code. Tell us the why, the history and the context.  Document  all  declarations and methods, even private ones. Declare expectations, caveats and anything else that may be important. If a type gets exported, having the comments already there will ensure it s ready.  The length of a variable names should be proportional to its context, and preferably relatively short. In practice, short methods will have short variable names and globals will have longer names.  Bad:  noCommaALongVariableNameLikeThisIsNotMoreClearWhenASimpleCommentWouldDo .    No underscores in package names. If you need a compound name, step back, and re-examine why you need a compound name. If you still think you need a compound name, lose the underscore.  No utils or helper packages. If a function is not general enough to warrant its own package, it has not been written generally enough to be a part of a util package. Just leave it unexported and well-documented.  All tests should run with  go test  and outside tooling should not be required. No, we don t need another unit testing framework. Assertion packages are acceptable if they provide  real  incremental value.  Even though we call these  rules  above, they are actually just guidelines. Since you ve read all the rules, you now know that.", 
            "title": "A few specific rules we follow"
        }, 
        {
            "location": "/contribute/development/style_guide/#useful-tools-when-developing-in-go", 
            "text": "golint : a linter for Go code.  gofmt : a command that formats Go programs.  goimports : a command that updates your Go import lines.  vet : a tool that examines Go code and reports suspicious constructs.  errcheck : a tool that checks for unchecked errors in Go programs.", 
            "title": "Useful tools when developing in Go"
        }, 
        {
            "location": "/contribute/development/style_guide/#nodejs-javascript-coding-style", 
            "text": "We use the  Airbnb React/JSX Style Guide  when working with Javascript.", 
            "title": "Node.js / Javascript coding style"
        }, 
        {
            "location": "/contribute/development/style_guide/#commenting", 
            "text": "Code commenting is crucial to maintaining a readable code base that future developers can understand and build upon. You can find a nice  primer on good commenting practice here .   Provide the why, the history, and context.  Why: Why are you writing the code in exactly the way that you are?  History: What historical decisions or factors went into writing the code in this way?  Context: Are there any other factors we should know about that went into writing or developing this piece of code?    Document  all  declarations and methods, even private ones. Declare expectations, caveats and anything else that may be important. If a type gets exported, having the comments already there will ensure it s ready.  Keep everything readable:  Remember that the comments will be read by humans. Keep it simple, brief, and clear.  Whitespace is important:  Comment while coding:", 
            "title": "Commenting"
        }, 
        {
            "location": "/contribute/development/style_guide/#resources", 
            "text": "Some further reading, particularly on the subject of Go:   Go Code Review Comments  Best Practices for Production Environments  12 Factor App  Tools for working with Go Code   Attribution: Go Coding Style adopted from the Docker project.", 
            "title": "Resources"
        }, 
        {
            "location": "/contribute/supporting_the_community/", 
            "text": "Organizing Events\n\n\nGoals\n\n\n\n\nFire up discussion on community\n\n\nShare our research/discussion on healthy community\n\n\nShare tools we are building\n\n\n\n\nActivities\n\n\nBreak the Ice Activity\n\n\nDiscuss:\n\n\n\n\nname / any organization\n\n\nwhat community you participate in?\n\n\n\n\nWrite down sticky notes:\n\n\n\n\nwhat makes that a healthy community\n\n\n\n\nSpectogram\n\n\nBrainstorm group\n\n\nLighting Talks", 
            "title": "Supporting the community"
        }, 
        {
            "location": "/contribute/supporting_the_community/#organizing-events", 
            "text": "", 
            "title": "Organizing Events"
        }, 
        {
            "location": "/contribute/supporting_the_community/#goals", 
            "text": "Fire up discussion on community  Share our research/discussion on healthy community  Share tools we are building", 
            "title": "Goals"
        }, 
        {
            "location": "/contribute/supporting_the_community/#activities", 
            "text": "", 
            "title": "Activities"
        }, 
        {
            "location": "/contribute/supporting_the_community/#break-the-ice-activity", 
            "text": "Discuss:   name / any organization  what community you participate in?   Write down sticky notes:   what makes that a healthy community", 
            "title": "Break the Ice Activity"
        }, 
        {
            "location": "/contribute/supporting_the_community/#spectogram", 
            "text": "", 
            "title": "Spectogram"
        }, 
        {
            "location": "/contribute/supporting_the_community/#brainstorm-group", 
            "text": "", 
            "title": "Brainstorm group"
        }, 
        {
            "location": "/contribute/supporting_the_community/#lighting-talks", 
            "text": "", 
            "title": "Lighting Talks"
        }, 
        {
            "location": "/contribute/contributor_license_agreement/", 
            "text": "To Be Determined", 
            "title": "Contributor License Agreement"
        }, 
        {
            "location": "/contribute/contributor_license_agreement/#to-be-determined", 
            "text": "", 
            "title": "To Be Determined"
        }, 
        {
            "location": "/contribute/coral_naming/", 
            "text": "Coral naming\n\n\nAre you curious about why we\nve named things the way that we have? As you may have guessed, each component of Coral is named after a different type of coral. We like to match up some traits of the particular type of coral with the functionality of the component, but that\ns not always possible.\n\n\nIf you\n\n\nCay\n\n\nCay is our front-end app, which makes sense because a cay is a small, low-elevation, sandy island on the surface of a coral reef. https://en.wikipedia.org/wiki/Cay\n\n\nElkhorn\n\n\nElkhorn coral is a coral species that builds large branches. These branches create habitats for other species.\n\n\nThis makes sense because Elkhorn is an form composer and embeddable builder: it, too, creates habitats for other species to come into the Coral ecosystem. https://en.wikipedia.org/wiki/Elkhorn_coral\n\n\nPillar\n\n\nPillar coral is a digitate coral, which means it resembles fingers or pillars rising up.\n\n\nREST API\n\n\nhttps://en.wikipedia.org/wiki/Pillar_coral\n\n\nSponge\n\n\nSponge is a porous organism that water can circulate through (and where it can then filter out food particles as the water circulates through). In the same way, the Sponge component of Coral takes in data and extracts it before passing it along.\n\n\nhttps://en.wikipedia.org/wiki/Sponge\n\n\nXenia\n\n\nXenia is a soft marine coral with \narms\n and \nhands\n that can pulse or push water around.\n\n\nhttps://en.wikipedia.org/wiki/Xenia_(genus)", 
            "title": "Coral naming"
        }, 
        {
            "location": "/contribute/coral_naming/#coral-naming", 
            "text": "Are you curious about why we ve named things the way that we have? As you may have guessed, each component of Coral is named after a different type of coral. We like to match up some traits of the particular type of coral with the functionality of the component, but that s not always possible.  If you", 
            "title": "Coral naming"
        }, 
        {
            "location": "/contribute/coral_naming/#cay", 
            "text": "Cay is our front-end app, which makes sense because a cay is a small, low-elevation, sandy island on the surface of a coral reef. https://en.wikipedia.org/wiki/Cay", 
            "title": "Cay"
        }, 
        {
            "location": "/contribute/coral_naming/#elkhorn", 
            "text": "Elkhorn coral is a coral species that builds large branches. These branches create habitats for other species.  This makes sense because Elkhorn is an form composer and embeddable builder: it, too, creates habitats for other species to come into the Coral ecosystem. https://en.wikipedia.org/wiki/Elkhorn_coral", 
            "title": "Elkhorn"
        }, 
        {
            "location": "/contribute/coral_naming/#pillar", 
            "text": "Pillar coral is a digitate coral, which means it resembles fingers or pillars rising up.  REST API  https://en.wikipedia.org/wiki/Pillar_coral", 
            "title": "Pillar"
        }, 
        {
            "location": "/contribute/coral_naming/#sponge", 
            "text": "Sponge is a porous organism that water can circulate through (and where it can then filter out food particles as the water circulates through). In the same way, the Sponge component of Coral takes in data and extracts it before passing it along.  https://en.wikipedia.org/wiki/Sponge", 
            "title": "Sponge"
        }, 
        {
            "location": "/contribute/coral_naming/#xenia", 
            "text": "Xenia is a soft marine coral with  arms  and  hands  that can pulse or push water around.  https://en.wikipedia.org/wiki/Xenia_(genus)", 
            "title": "Xenia"
        }, 
        {
            "location": "/faq/", 
            "text": "FAQ\n\n\nProject background\n\n\nWhat is the Coral Project?\n\n\nThe Coral Project is a collaborative effort to improve community on news sites through open-source software. You can read more about it on \nour website\n.\n\n\nWhat do you do?\n\n\nWe\u2019re creating open-source software to facilitate the importing, storage, moderation, and display of contributions to news websites. That includes images, video, and text such as comments, annotations, and blog posts.\n\n\nWho\u2019s behind the project?\n\n\nIt\u2019s led by a team from Mozilla, The New York Times, and The Washington Post. It\u2019s funded by a two-year grant by the John S. and James L. Knight Foundation. The ideas guiding it are coming from readers, contributors, journalists, community managers, researchers, and developers. \nAnd you, if the mood strikes you\n.\n\n\nThis is that comment system that Mozilla is building for the Times and the Post, right?\n\n\nNot exactly. All three organizations are working together, and we\u2019re focusing on many kinds of text contributions, as well as images and video. We\u2019ll be creating software that publishers \u2014 or anyone, really \u2014 can use to better connect with their community. And that contributors can use to better connect with publishers.\n\n\nWhat about digital community do you want to improve?\n\n\nWe want to give publishers the ability to better understand their contributors and control the level of discourse on their sites; empower contributors to manage their identities and data; and provide readers with a more productive discussion about current events.\n\n\nDevelopment process\n\n\nSo you\u2019ll release your software in two years?\n\n\nNo, we\u2019ll be creating software throughout our grant period and working with contributors, publishers, academics, and readers to iterate on it.\n\n\nHow long has the project been going?\n\n\nWe had a research phase in early 2014, our grant was approved in June 2014, and we\u2019ve been planning and building our team in the time since.\n\n\nHow will the software work?\n\n\nWe\u2019ll be building a flexible core system and a series of plugins, all connected through APIs. Publishers \u2014 or anyone, really \u2014 can choose to use everything we deploy or pick and choose plugins that fit specific needs.\n\n\nWill it work on mobile?\n\n\nWe\u2019re developing for all browsers and devices.\n\n\nIs this for me?\n\n\nI\u2019m a regular commenter on news sites. What\u2019s in it for me?\n\n\nWe want to give you tools to own and manage your identity and contributions across websites and analytics that allow you to understand who\u2019s interacting with the content you create.\n\n\nI work at a news site that\u2019s smaller than The Post and The Times. Will this work for us?\n\n\nOur aim is to make the software we create easy to manage for publishers large and small. If you\u2019ve got specific needs you\u2019d like to talk about, please [email link]get in touch with us[/email link].\n\n\nHow can I keep up with what you\u2019re doing?\n\n\nWatch this website. We\u2019ll be posting updates regularly once our development begins in earnest.\n\n\nI\u2019ve got a few ideas to share with you. How can I get in touch?\n\n\nPlease get in touch with us here\n. We\u2019re eager to hear from you.\n\n\nData sources\n\n\nWhich external data sources are supported?\n\n\nWe currently support mySQL, PostgreSQL, MondoDB, and REST APIs.\n\n\nWe use Elasticsearch. Can we connect to that?\n\n\nNot yet. Our currently supported external data sources are mySQL, PostgreSQL, MongoDB, and REST APIs. However, you can write your own driver to connect to Elasticsearch. The drivers are part of the \nSponge\n app, and you can find out more about the driver components \nhere\n.\n\n\nHow often does the data refresh in the Trust app?\n\n\nThe data in the Trust app refreshes every 24 hours.\n\n\nInstallation\n\n\nHow would we get started?\n\n\nYou can learn more about the different installation options on our \ndeveloper overview page\n. The quickest and easiest way to get started is probably the \nAll-in-One Docker installation\n, but you can read about each available option (and whether it is likely to be the best option for you) on the \ndeveloper overview page\n.\n\n\nDo you have dummy data that we can use?\n\n\nYes. Our dummy data consists of thoroughly scrubbed and anonymized comments data from the Washington Post commenting database.\n\n\nIf you install Coral through the \nAll-in-One Docker installation\n, you should automatically have the dummy data set up for you in your MongoDB.\n\n\nIf you want to manually import sample data (for example, if you\nve installed Coral from source code), you can read more about how to do that \non the developer setup page\n.", 
            "title": "FAQ"
        }, 
        {
            "location": "/faq/#faq", 
            "text": "", 
            "title": "FAQ"
        }, 
        {
            "location": "/faq/#project-background", 
            "text": "", 
            "title": "Project background"
        }, 
        {
            "location": "/faq/#what-is-the-coral-project", 
            "text": "The Coral Project is a collaborative effort to improve community on news sites through open-source software. You can read more about it on  our website .", 
            "title": "What is the Coral Project?"
        }, 
        {
            "location": "/faq/#what-do-you-do", 
            "text": "We\u2019re creating open-source software to facilitate the importing, storage, moderation, and display of contributions to news websites. That includes images, video, and text such as comments, annotations, and blog posts.", 
            "title": "What do you do?"
        }, 
        {
            "location": "/faq/#whos-behind-the-project", 
            "text": "It\u2019s led by a team from Mozilla, The New York Times, and The Washington Post. It\u2019s funded by a two-year grant by the John S. and James L. Knight Foundation. The ideas guiding it are coming from readers, contributors, journalists, community managers, researchers, and developers.  And you, if the mood strikes you .", 
            "title": "Who\u2019s behind the project?"
        }, 
        {
            "location": "/faq/#this-is-that-comment-system-that-mozilla-is-building-for-the-times-and-the-post-right", 
            "text": "Not exactly. All three organizations are working together, and we\u2019re focusing on many kinds of text contributions, as well as images and video. We\u2019ll be creating software that publishers \u2014 or anyone, really \u2014 can use to better connect with their community. And that contributors can use to better connect with publishers.", 
            "title": "This is that comment system that Mozilla is building for the Times and the Post, right?"
        }, 
        {
            "location": "/faq/#what-about-digital-community-do-you-want-to-improve", 
            "text": "We want to give publishers the ability to better understand their contributors and control the level of discourse on their sites; empower contributors to manage their identities and data; and provide readers with a more productive discussion about current events.", 
            "title": "What about digital community do you want to improve?"
        }, 
        {
            "location": "/faq/#development-process", 
            "text": "", 
            "title": "Development process"
        }, 
        {
            "location": "/faq/#so-youll-release-your-software-in-two-years", 
            "text": "No, we\u2019ll be creating software throughout our grant period and working with contributors, publishers, academics, and readers to iterate on it.", 
            "title": "So you\u2019ll release your software in two years?"
        }, 
        {
            "location": "/faq/#how-long-has-the-project-been-going", 
            "text": "We had a research phase in early 2014, our grant was approved in June 2014, and we\u2019ve been planning and building our team in the time since.", 
            "title": "How long has the project been going?"
        }, 
        {
            "location": "/faq/#how-will-the-software-work", 
            "text": "We\u2019ll be building a flexible core system and a series of plugins, all connected through APIs. Publishers \u2014 or anyone, really \u2014 can choose to use everything we deploy or pick and choose plugins that fit specific needs.", 
            "title": "How will the software work?"
        }, 
        {
            "location": "/faq/#will-it-work-on-mobile", 
            "text": "We\u2019re developing for all browsers and devices.", 
            "title": "Will it work on mobile?"
        }, 
        {
            "location": "/faq/#is-this-for-me", 
            "text": "", 
            "title": "Is this for me?"
        }, 
        {
            "location": "/faq/#im-a-regular-commenter-on-news-sites-whats-in-it-for-me", 
            "text": "We want to give you tools to own and manage your identity and contributions across websites and analytics that allow you to understand who\u2019s interacting with the content you create.", 
            "title": "I\u2019m a regular commenter on news sites. What\u2019s in it for me?"
        }, 
        {
            "location": "/faq/#i-work-at-a-news-site-thats-smaller-than-the-post-and-the-times-will-this-work-for-us", 
            "text": "Our aim is to make the software we create easy to manage for publishers large and small. If you\u2019ve got specific needs you\u2019d like to talk about, please [email link]get in touch with us[/email link].", 
            "title": "I work at a news site that\u2019s smaller than The Post and The Times. Will this work for us?"
        }, 
        {
            "location": "/faq/#how-can-i-keep-up-with-what-youre-doing", 
            "text": "Watch this website. We\u2019ll be posting updates regularly once our development begins in earnest.", 
            "title": "How can I keep up with what you\u2019re doing?"
        }, 
        {
            "location": "/faq/#ive-got-a-few-ideas-to-share-with-you-how-can-i-get-in-touch", 
            "text": "Please get in touch with us here . We\u2019re eager to hear from you.", 
            "title": "I\u2019ve got a few ideas to share with you. How can I get in touch?"
        }, 
        {
            "location": "/faq/#data-sources", 
            "text": "", 
            "title": "Data sources"
        }, 
        {
            "location": "/faq/#which-external-data-sources-are-supported", 
            "text": "We currently support mySQL, PostgreSQL, MondoDB, and REST APIs.", 
            "title": "Which external data sources are supported?"
        }, 
        {
            "location": "/faq/#we-use-elasticsearch-can-we-connect-to-that", 
            "text": "Not yet. Our currently supported external data sources are mySQL, PostgreSQL, MongoDB, and REST APIs. However, you can write your own driver to connect to Elasticsearch. The drivers are part of the  Sponge  app, and you can find out more about the driver components  here .", 
            "title": "We use Elasticsearch. Can we connect to that?"
        }, 
        {
            "location": "/faq/#how-often-does-the-data-refresh-in-the-trust-app", 
            "text": "The data in the Trust app refreshes every 24 hours.", 
            "title": "How often does the data refresh in the Trust app?"
        }, 
        {
            "location": "/faq/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/faq/#how-would-we-get-started", 
            "text": "You can learn more about the different installation options on our  developer overview page . The quickest and easiest way to get started is probably the  All-in-One Docker installation , but you can read about each available option (and whether it is likely to be the best option for you) on the  developer overview page .", 
            "title": "How would we get started?"
        }, 
        {
            "location": "/faq/#do-you-have-dummy-data-that-we-can-use", 
            "text": "Yes. Our dummy data consists of thoroughly scrubbed and anonymized comments data from the Washington Post commenting database.  If you install Coral through the  All-in-One Docker installation , you should automatically have the dummy data set up for you in your MongoDB.  If you want to manually import sample data (for example, if you ve installed Coral from source code), you can read more about how to do that  on the developer setup page .", 
            "title": "Do you have dummy data that we can use?"
        }
    ]
}